{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import assets.helper as b3\n",
    "import assets.functions as run\n",
    "\n",
    "from typing import Dict, Union, List, Optional, Any\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import os\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "import plotly.graph_objects as go\n",
    "from plotly.graph_objs import Figure\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge Mix and Match all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    math = run.load_pkl(f'{b3.app_folder}math')\n",
    "except Exception as e:\n",
    "    math = run.get_math()\n",
    "    math = run.save_pkl(math, f'{b3.app_folder}math')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    setorial = run.load_pkl(f'{b3.app_folder}setorial')\n",
    "except Exception as e:\n",
    "    setorial = run.get_classificacao_setorial(setorial='')\n",
    "    setorial = run.save_pkl(setorial, f'{b3.app_folder}setorial')\n",
    "# setorial.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    b3_cvm = run.load_pkl(f'{b3.app_folder}b3_cvm')\n",
    "except Exception as e:\n",
    "    b3_cvm = run.b3_grab(b3.search_url)\n",
    "    b3_cvm = run.save_pkl(b3_cvm, f'{b3.app_folder}b3_cvm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETOR: O setor econômico mais amplo ao qual a empresa pertence.\n",
    "# SUBSETOR: Uma categorização mais específica dentro do setor mais amplo.\n",
    "# SEGMENTO: Uma classificação ainda mais granular do negócio da empresa.\n",
    "# DENOM_CIA: Esta é a denominação ou nome da empresa.\n",
    "# COMPANHIA: Nome ou denominação oficial da empresa listada.\n",
    "# PREGAO: Refere-se ao nome pelo qual a empresa é conhecida no pregão da bolsa de valores.\n",
    "# LISTAGEM: Categoria ou segmento de listagem da empresa na bolsa de valores, que pode indicar o nível de governança corporativa ou outros critérios.\n",
    "# TICK: Abreviação ou símbolo da empresa usada no mercado de ações.\n",
    "# TICKERS: Símbolos de negociação da empresa em diferentes mercados ou plataformas.\n",
    "# CD_CVM: Este poderia ser um código ou identificador único relacionado à empresa, possivelmente relacionado à Comissão de Valores Mobiliários do Brasil (CVM).\n",
    "# CVM: Código ou identificador relacionado à empresa na Comissão de Valores Mobiliários, o órgão regulador do mercado de capitais no Brasil.\n",
    "# ISIN: Número de Identificação Internacional de Valores Mobiliários – um identificador único para valores mobiliários.\n",
    "# CNPJ_CIA: Este é o número do Cadastro Nacional da Pessoa Jurídica (CNPJ) da empresa, um identificador único para empresas no Brasil.\n",
    "# CNPJ: Cadastro Nacional da Pessoa Jurídica – é o número de identificação das empresas brasileiras.\n",
    "# SITE: Site oficial ou página relevante da empresa.\n",
    "# ATIVIDADE: Descreve a principal atividade de negócios da empresa.\n",
    "\n",
    "# ANO: Este é o ano ao qual os dados se referem.\n",
    "# DT_REFER: Esta é a data de referência para a entrada de dados.\n",
    "# DT_FIM_EXERC: Esta é a data final para o exercício ou período de relato financeiro.\n",
    "# DT_INI_EXERC: Esta poderia ser a data inicial para o exercício ou período de relato financeiro.\n",
    "\n",
    "# AGRUPAMENTO: Isso descreve o nível de agregação dos dados. Por exemplo, 'con' pode indicar dados consolidados.\n",
    "# BALANCE_SHEET: Isso indica a seção específica da demonstração financeira, como Balanço Patrimonial ('BPA').\n",
    "# GRUPO_DFP: Isso representa o tipo de grupo de demonstração financeira. Por exemplo, 'DF Consolidado - Balanço Patrimonial Ativo' sugere que é um balanço patrimonial consolidado focado em ativos.\n",
    "# CD_CONTA: Este poderia ser um código ou identificador único relacionado a uma conta específica ou item de linha na demonstração financeira.\n",
    "# DS_CONTA: Descreve a conta específica ou item de linha na demonstração financeira, como 'Ativo Total'.\n",
    "\n",
    "# VL_CONTA: Representa o valor associado à conta específica ou item de linha.\n",
    "# MOEDA: Isso indica a moeda na qual os valores são representados. 'REAL' sugere Real Brasileiro.\n",
    "# ESCALA_MOEDA: Isso fornece a escala ou unidade para os valores monetários. 'MIL' pode indicar que os valores estão em milhares.\n",
    "\n",
    "# ST_CONTA_FIXA: Pode indicar o status ou tipo de conta. O significado de valores como 'S' dependeria do contexto dos dados.\n",
    "# COLUNA_DF: O propósito desta coluna não é imediatamente claro a partir da amostra. Pode representar algum tipo de classificação ou categorização relacionada aos dados financeiros.\n",
    "\n",
    "# ESCRITURADOR: Entidade ou empresa responsável por registrar ou gerenciar os valores mobiliários da empresa.\n",
    "# ACIONISTAS: Informações ou identificadores relacionados aos acionistas da empresa.\n",
    "\n",
    "# FILENAME: Este é o arquivo de onde os dados são originados. Ele fornece o nome do arquivo que contém a respectiva entrada de dados.\n",
    "# DEMONSTRATIVO: Este representa o tipo de demonstração financeira. Pode indicar se os dados são de um relatório intermediário (como 'itr') ou de outro tipo de relatório financeiro.\n",
    "# VERSAO: Isso pode representar a versão ou iteração dos dados/relatórios financeiros.\n",
    "\n",
    "columns = [\n",
    "    'SETOR_x',\n",
    "    'SUBSETOR_x',\n",
    "    'SEGMENTO_x',\n",
    "    'DENOM_CIA',\n",
    "        # 'COMPANHIA',\n",
    "    'PREGAO',\n",
    "    'LISTAGEM',\n",
    "    'TICK',\n",
    "    'TICKERS',\n",
    "    'CD_CVM',\n",
    "        # 'CVM',\n",
    "        # 'ISIN',\n",
    "    'CNPJ_CIA',\n",
    "        # 'CNPJ',\n",
    "    'SITE',\n",
    "    'ATIVIDADE',\n",
    "        # 'ANO',\n",
    "    'DT_REFER',\n",
    "        # 'DT_FIM_EXERC',\n",
    "        # 'DT_INI_EXERC',\n",
    "    'AGRUPAMENTO',\n",
    "    'BALANCE_SHEET',\n",
    "    # 'GRUPO_DFP',\n",
    "    'CD_CONTA',\n",
    "    'DS_CONTA',\n",
    "    'VL_CONTA',\n",
    "    # 'MOEDA',\n",
    "    # 'ESCALA_MOEDA',\n",
    "    # 'ST_CONTA_FIXA',\n",
    "    # 'COLUNA_DF',\n",
    "    'ESCRITURADOR',\n",
    "    'ACIONISTAS', \n",
    "    # 'FILENAME', \n",
    "    # 'DEMONSTRATIVO', \n",
    "    # 'VERSAO',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b3_cvm.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['FILENAME', 'DEMONSTRATIVO', 'BALANCE_SHEET', 'ANO', 'AGRUPAMENTO',\n",
    "       'CNPJ_CIA', 'DT_REFER', 'VERSAO', 'DENOM_CIA', 'CD_CVM', 'GRUPO_DFP',\n",
    "       'MOEDA', 'ESCALA_MOEDA', 'DT_FIM_EXERC', 'CD_CONTA', 'DS_CONTA',\n",
    "       'VL_CONTA', 'ST_CONTA_FIXA', 'DT_INI_EXERC', 'COLUNA_DF', 'COMPANHIA',\n",
    "       'PREGAO', 'TICK', 'LISTAGEM', 'TICKERS', 'ISIN', \n",
    "       'ATIVIDADE', 'SETOR', 'SUBSETOR', 'SEGMENTO', 'SITE', 'ESCRITURADOR',]\n",
    "df = b3_cvm['CONSUMO CICLICO'][columns].set_index('DT_REFER')\n",
    "df = convert_columns(df)\n",
    "df['DENOM_CIA'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acoes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acoes = run.load_pkl(f'{b3.app_folder}acoes')\n",
    "# Process the data and return the result\n",
    "acoes['Trimestre'] = pd.to_datetime(acoes['Trimestre'], errors='coerce', dayfirst=True)\n",
    "acoes['BALANCE_SHEET'] = 'STK'\n",
    "column_mapping = {\n",
    "    'Ações ON': '00.01.01',\n",
    "    'Ações PN': '00.02.01',\n",
    "    'Ações ON em Tesouraria': '00.01.02',\n",
    "    'Ações PN em Tesouraria': '00.02.02'\n",
    "}\n",
    "acoes = acoes.rename(columns={\"Companhia\": \"DENOM_CIA\", \"Trimestre\": \"DT_REFER\"})\n",
    "\n",
    "acoes = acoes.melt(id_vars=['DENOM_CIA', 'DT_REFER', 'BALANCE_SHEET'], \n",
    "                        value_vars=['Ações ON', 'Ações PN', 'Ações ON em Tesouraria', 'Ações PN em Tesouraria'],\n",
    "                        var_name='DS_CONTA', value_name='VL_CONTA').sort_values(by=['DENOM_CIA', 'DT_REFER', 'DS_CONTA'])\n",
    "\n",
    "acoes['CD_CONTA'] = acoes['DS_CONTA'].map(column_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intel_b3 = run.load_pkl(f'{b3.app_folder}intel_b3')\n",
    "df = intel_b3['BENS INDUSTRIAIS']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company = 'ARMAC LOCACAO LOGISTICA E SERVICOS SA'\n",
    "quarter = '2019-12-31'\n",
    "mc = acoes['DENOM_CIA'] == company\n",
    "mc &= acoes['DT_REFER'] == quarter\n",
    "acoesc = acoes[mc]\n",
    "\n",
    "mc = df['DENOM_CIA'] == company\n",
    "mc &= df['DT_REFER'] == quarter\n",
    "dfc = df[mc]\n",
    "\n",
    "df_ffill = pd.concat([dfc, acoesc], ignore_index=True).ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_stock_data(group):\n",
    "    company, quarter = group.name\n",
    "    \n",
    "    # Filter acoes based on company and quarter\n",
    "    mc = acoes['DENOM_CIA'] == company\n",
    "    mc &= acoes['DT_REFER'] == quarter\n",
    "    acoesc = acoes[mc]\n",
    "\n",
    "    # Concatenate and ffill\n",
    "    return pd.concat([group, acoesc], ignore_index=True).ffill()\n",
    "\n",
    "result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_ffill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intelacoes = {}\n",
    "for setor, df in intel_b3.items():\n",
    "    print(setor)\n",
    "    df_concat = pd.concat([df.set_index(['DENOM_CIA', 'DT_REFER']), acoes.set_index(['DENOM_CIA', 'DT_REFER'])], axis=0, sort=False).reset_index()\n",
    "    filled_df = df_concat.groupby(['DENOM_CIA', 'DT_REFER'], group_keys=False).apply(lambda group: group.ffill().bfill()).reset_index()\n",
    "    intelacoes[setor] = filled_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate them vertically\n",
    "df_concat = pd.concat([df.set_index(['DENOM_CIA', 'DT_REFER']), acoes.set_index(['DENOM_CIA', 'DT_REFER'])], axis=0, sort=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_df = df_concat.groupby(['DENOM_CIA', 'DT_REFER'], group_keys=False).apply(lambda group: group.ffill().bfill()).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = filled_df['DENOM_CIA'] == 'ARMAC LOCACAO LOGISTICA E SERVICOS SA'\n",
    "m &= filled_df['DT_REFER'] == '2019-12-31'\n",
    "m &= filled_df['BALANCE_SHEET'] == 'STK'\n",
    "\n",
    "filled_df[m][cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b3_cvm = run.load_pkl(f'{b3.app_folder}b3_cvm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_types = {'index': 'int',\n",
    " 'FILENAME': 'category',\n",
    " 'DEMONSTRATIVO': 'category',\n",
    " 'BALANCE_SHEET': 'category',\n",
    " 'ANO': 'category',\n",
    " 'AGRUPAMENTO': 'category',\n",
    " 'CNPJ_CIA': 'category',\n",
    " 'DT_REFER': 'object',\n",
    " 'VERSAO': 'category',\n",
    " 'DENOM_CIA': 'category',\n",
    " 'CD_CVM': 'category',\n",
    " 'GRUPO_DFP': 'category',\n",
    " 'MOEDA': 'category',\n",
    " 'ESCALA_MOEDA': 'category',\n",
    " 'DT_FIM_EXERC': 'object',\n",
    " 'CD_CONTA': 'category',\n",
    " 'DS_CONTA': 'category',\n",
    " 'VL_CONTA': 'float',\n",
    " 'ST_CONTA_FIXA': 'category',\n",
    " 'DT_INI_EXERC': 'object',\n",
    " 'COLUNA_DF': 'category',\n",
    " 'COMPANHIA': 'category',\n",
    " 'PREGAO': 'category',\n",
    " 'TICK': 'category',\n",
    " 'LISTAGEM': 'category',\n",
    " 'CVM': 'category',\n",
    " 'TICKERS': 'category',\n",
    " 'ISIN': 'category',\n",
    " 'CNPJ': 'category',\n",
    " 'ATIVIDADE': 'category',\n",
    " 'SETOR': 'category',\n",
    " 'SUBSETOR': 'category',\n",
    " 'SEGMENTO': 'category',\n",
    " 'SITE': 'category',\n",
    " 'ESCRITURADOR': 'category',\n",
    " 'CD_CONTA_original': 'category',\n",
    " 'DS_CONTA_original': 'category'}\n",
    "date_columns = ['DT_REFER', 'DT_FIM_EXERC', 'DT_INI_EXERC']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('BENS INDUSTRIAIS_intel.csv', dtype=column_types, index_col='Unnamed: 0', parse_dates=True)\n",
    "# df = pd.read_csv('COMUNICACOES_df.csv')\n",
    "# df_typed = pd.read_csv(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um dicionário onde as chaves são os nomes das colunas e os valores são os valores únicos para cada coluna\n",
    "col_dict = {col: df[col].unique().tolist() for col in df.columns}\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_dict['BALANCE_SHEET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['CNPJ_CIA', 'DENOM_CIA', 'DT_REFER', 'CD_CONTA', 'DS_CONTA', 'VL_CONTA', 'SETOR', 'SUBSETOR', 'SEGMENTO', 'DT_INI_EXERC', 'ATIVIDADE', 'SITE', 'ESCRITURADOR', 'FILENAME', 'DEMONSTRATIVO', 'BALANCE_SHEET', 'ANO', 'AGRUPAMENTO', 'VERSAO', 'GRUPO_DFP', 'MOEDA', 'ESCALA_MOEDA', 'ST_CONTA_FIXA', 'COLUNA_DF', 'COMPANHIA', 'TICKERS', 'CVM', 'ISIN', 'DT_FIM_EXERC', ]]\n",
    "# 'PREGAO', 'TICK', 'CD_CVM', 'LISTAGEM', # 'CD_CONTA_original', 'DS_CONTA_original', \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formulas_old = [\n",
    "    # Relações Entre Ativos e Passivos\n",
    "    ('_020302_reservas_de_capital', '_020303_reservas_de_reavaliacao', '_020304_reservas_de_lucros'),\n",
    "    # Dívida\n",
    "    ('_0201040101_emprestimos_e_financiamentos_em_moeda_nacional', '_0201040102_emprestimos_e_financiamentos_em_moeda_estrangeira', '_02010402_debentures', '_02010403_arrendamentos', '_02010409_outros_emprestimos_financiamentos_e_debentures'),\n",
    "    ('_0202010101_emprestimos_e_financiamentos_em_moeda_nacional', '_0202010102_emprestimos_e_financiamentos_em_moeda_estrangeira', '_02020102_debentures', '_02020103_arrendamentos', '_02020209_outros_emprestimos_financiamentos_e_debentures'),\n",
    "    ('_0201040102_emprestimos_e_financiamentos_em_moeda_estrangeira', '_0202010102_emprestimos_e_financiamentos_em_moeda_estrangeira'),\n",
    "    ('_010101_caixa_e_disponibilidades_de_caixa',),\n",
    "    ('_010202_investimentos_nao_capex', '_010203_imobilizados', '_010204_intangivel'),\n",
    "    ('_0305_lajir_ebit_resultado_antes_do_resultado_financeiro_e_dos_tributos', '_070401_depreciacao_e_amortizacao'),\n",
    "    # Resultados Fundamentalistas\n",
    "    ('_0203_patrimonio_liquido',),\n",
    "    ('_010101_caixa_e_disponibilidades_de_caixa',),\n",
    "    ('_070803_remuneracao_de_capital_de_terceiros', '_070804_remuneracao_de_capital_proprio'),\n",
    "    # Análise do Fluxo de Caixa\n",
    "    ('_0601_caixa_das_operacoes', '_0602_caixa_de_investimentos_capex'),\n",
    "    ('_0603_caixa_de_financiamento',),\n",
    "    ('_060201_investimentos', '_060202_imobilizado_e_intangivel'),\n",
    "]\n",
    "\n",
    "def de_transform_corrected(key):\n",
    "    # Strip the leading underscore and split at the first underscore\n",
    "    parts = key[1:].split('_', 1)\n",
    "\n",
    "    # Adjust code by inserting periods every two characters\n",
    "    code = '.'.join([parts[0][i:i+2] for i in range(0, len(parts[0]), 2)])\n",
    "    \n",
    "    # Adjust description capitalization\n",
    "    description = ' '.join([word.capitalize() if word not in ['e', 'de', 'do', 'dos', 'da', 'das', 'em'] else word.lower() for word in parts[1].split('_')])\n",
    "    \n",
    "    return code, description\n",
    "\n",
    "# De-transform the formulas using the corrected function\n",
    "formulas = []\n",
    "for group in formulas_old:\n",
    "    new_group = []\n",
    "    for key in group:\n",
    "        new_group.append(de_transform_corrected(key))\n",
    "    formulas.append(tuple(new_group))\n",
    "\n",
    "formulas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_sheet = df.groupby(['CNPJ_CIA', 'DT_REFER'], group_keys=True)\n",
    "balance_sheet.groups.keys()\n",
    "df_ = balance_sheet.get_group(('00.242.184/0001-04', '2019-12-31'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (, 'Emprestimos e Financiamentos em Moeda Estrangeira'),\n",
    "m = df['CD_CONTA'] == '07.08.04'\n",
    "df[m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dados Abertos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(file):\n",
    "    path = \"C:\\\\Users\\\\faust\\\\OneDrive\\\\Área de Trabalho\\\\dados abertos\\\\\"\n",
    "    df = pd.read_csv(path+file+\".csv\", sep=';', encoding='latin1')\n",
    "    return df.head(25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fca_cia_aberta_2010\"\n",
    "fca_cia_aberta_2010 = read(file)\n",
    "# link para o NSD do formulário cadastral\n",
    "fca_cia_aberta_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fca_cia_aberta_auditor_2010\"\n",
    "fca_cia_aberta_auditor_2010 = read(file)\n",
    "# informações dos auditores CNPJ e CPF, datas dos auditores CPF\n",
    "fca_cia_aberta_auditor_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fca_cia_aberta_canal_divulgacao_2010\"\n",
    "fca_cia_aberta_canal_divulgacao_2010 = read(file)\n",
    "# Onde as DRE são divulgadas\n",
    "fca_cia_aberta_canal_divulgacao_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fca_cia_aberta_departamento_acionistas_2010\"\n",
    "fca_cia_aberta_departamento_acionistas_2010 = read(file)\n",
    "# Endereços dos DRI\n",
    "fca_cia_aberta_departamento_acionistas_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fca_cia_aberta_dri_2010\"\n",
    "fca_cia_aberta_dri_2010 = read(file)\n",
    "# NOMES e endereços dos DRI\n",
    "fca_cia_aberta_dri_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fca_cia_aberta_endereco_2010\"\n",
    "fca_cia_aberta_endereco_2010 = read(file)\n",
    "# Endereço completo do DRI\n",
    "fca_cia_aberta_endereco_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fca_cia_aberta_geral_2010\"\n",
    "fca_cia_aberta_geral_2010 = read(file)\n",
    "# Cadastro CVM, Atividade, Descrição e Controle Acionário\n",
    "fca_cia_aberta_geral_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fca_cia_aberta_pais_estrangeiro_negociacao_2010\"\n",
    "fca_cia_aberta_pais_estrangeiro_negociacao_2010 = read(file)\n",
    "# País estrangeiro... ?\n",
    "fca_cia_aberta_pais_estrangeiro_negociacao_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fca_cia_aberta_valor_mobiliario_2010\"\n",
    "fca_cia_aberta_valor_mobiliario_2010 = read(file)\n",
    "# Valor mobiliário, Mercado e Segmento\n",
    "fca_cia_aberta_valor_mobiliario_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_2023\"\n",
    "fre_cia_aberta_2023 = read(file)\n",
    "# Link do Documento\n",
    "fre_cia_aberta_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_acao_entregue_2023\"\n",
    "fre_cia_aberta_acao_entregue_2023 = read(file)\n",
    "# Remuneração da Diretoria\n",
    "fre_cia_aberta_acao_entregue_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_administrador_declaracao_genero_2023\"\n",
    "fre_cia_aberta_administrador_declaracao_genero_2023 = read(file)\n",
    "# Gênero dos administradores\n",
    "fre_cia_aberta_administrador_declaracao_genero_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_administrador_declaracao_raca_2023\"\n",
    "fre_cia_aberta_administrador_declaracao_raca_2023 = read(file)\n",
    "# Raça dos administradores\n",
    "fre_cia_aberta_administrador_declaracao_raca_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_administrador_membro_conselho_fiscal_2023\"\n",
    "fre_cia_aberta_administrador_membro_conselho_fiscal_2023 = read(file)\n",
    "# Membros do Conselho Fiscal\n",
    "fre_cia_aberta_administrador_membro_conselho_fiscal_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_ativo_imobilizado_2023\"\n",
    "fre_cia_aberta_ativo_imobilizado_2023 = read(file)\n",
    "# Ativos e Propriedades por empresa\n",
    "fre_cia_aberta_ativo_imobilizado_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_ativo_intangivel_2023\"\n",
    "fre_cia_aberta_ativo_intangivel_2023 = read(file)\n",
    "# Ativos e Propriedades por empresa\n",
    "fre_cia_aberta_ativo_intangivel_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_auditor_2023\"\n",
    "fre_cia_aberta_auditor_2023 = read(file)\n",
    "# Remuneração por auditor\n",
    "fre_cia_aberta_auditor_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_auditor_responsavel_2023\"\n",
    "fre_cia_aberta_auditor_responsavel_2023 = read(file)\n",
    "# Endereço do Auditor\n",
    "fre_cia_aberta_auditor_responsavel_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_capital_social_2023\"\n",
    "fre_cia_aberta_capital_social_2023 = read(file)\n",
    "# Modificações no Capital Social e Ações\n",
    "fre_cia_aberta_capital_social_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_capital_social_aumento_2023\"\n",
    "fre_cia_aberta_capital_social_aumento_2023 = read(file)\n",
    "# Idem\n",
    "fre_cia_aberta_capital_social_aumento_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_capital_social_aumento_classe_acao_2023\"\n",
    "fre_cia_aberta_capital_social_aumento_classe_acao_2023 = read(file)\n",
    "# Em branco\n",
    "fre_cia_aberta_capital_social_aumento_classe_acao_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_capital_social_classe_acao_2023\"\n",
    "fre_cia_aberta_capital_social_classe_acao_2023 = read(file)\n",
    "# Preferencial Classe A, B e C\n",
    "fre_cia_aberta_capital_social_classe_acao_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_capital_social_desdobramento_2023\"\n",
    "fre_cia_aberta_capital_social_desdobramento_2023 = read(file)\n",
    "# Desdobramentos de Ações\n",
    "fre_cia_aberta_capital_social_desdobramento_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_capital_social_desdobramento_classe_acao_2023\"\n",
    "fre_cia_aberta_capital_social_desdobramento_classe_acao_2023 = read(file)\n",
    "# em branco\n",
    "fre_cia_aberta_capital_social_desdobramento_classe_acao_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_capital_social_reducao_2023\"\n",
    "fre_cia_aberta_capital_social_reducao_2023 = read(file)\n",
    "# Redução de capital\n",
    "fre_cia_aberta_capital_social_reducao_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_capital_social_titulo_conversivel_2023\"\n",
    "fre_cia_aberta_capital_social_titulo_conversivel_2023 = read(file)\n",
    "# Redução de capital\n",
    "fre_cia_aberta_capital_social_titulo_conversivel_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_direito_acao_2023\"\n",
    "fre_cia_aberta_direito_acao_2023 = read(file)\n",
    "# ?\n",
    "fre_cia_aberta_direito_acao_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_historico_emissor_2023\"\n",
    "fre_cia_aberta_historico_emissor_2023 = read(file)\n",
    "# Constituição do emissor e local\n",
    "fre_cia_aberta_historico_emissor_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_informacao_financeira_2023\"\n",
    "fre_cia_aberta_informacao_financeira_2023 = read(file)\n",
    "# DRE Resumido\n",
    "fre_cia_aberta_informacao_financeira_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_membro_comite_2023\"\n",
    "fre_cia_aberta_membro_comite_2023 = read(file)\n",
    "# CPF e Remuneração\n",
    "fre_cia_aberta_membro_comite_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_obrigacao_2023\"\n",
    "fre_cia_aberta_obrigacao_2023 = read(file)\n",
    "# Obrigações e Dívidas\n",
    "fre_cia_aberta_obrigacao_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_outro_valor_mobiliario_2023\"\n",
    "fre_cia_aberta_outro_valor_mobiliario_2023 = read(file)\n",
    "# ?\n",
    "fre_cia_aberta_outro_valor_mobiliario_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_participacao_sociedade_2023\"\n",
    "fre_cia_aberta_participacao_sociedade_2023 = read(file)\n",
    "# Participações em outras empresas\n",
    "fre_cia_aberta_participacao_sociedade_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_participacao_sociedade_valorizacao_acao_2023\"\n",
    "fre_cia_aberta_participacao_sociedade_valorizacao_acao_2023 = read(file)\n",
    "# ?\n",
    "fre_cia_aberta_participacao_sociedade_valorizacao_acao_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_posicao_acionaria_2023\"\n",
    "fre_cia_aberta_posicao_acionaria_2023 = read(file)\n",
    "# Composição acionária por acionista majoritário\n",
    "fre_cia_aberta_posicao_acionaria_2023[['CNPJ_Companhia', 'Data_Referencia', 'Versao', 'ID_Documento',\n",
    "       'ID_Acionista', 'Acionista', 'Tipo_Pessoa_Acionista',\n",
    "       'CPF_CNPJ_Acionista', 'ID_Acionista_Relacionado',\n",
    "       'Acionista_Relacionado', 'Tipo_Pessoa_Acionista_Relacionado',\n",
    "       'CPF_CNPJ_Acionista_Relacionado',\n",
    "       'Quantidade_Acao_Ordinaria_Circulacao',\n",
    "       'Percentual_Acao_Ordinaria_Circulacao',\n",
    "       'Quantidade_Acao_Preferencial_Circulacao',\n",
    "       'Percentual_Acao_Preferencial_Circulacao',\n",
    "       'Quantidade_Total_Acoes_Circulacao',\n",
    "       'Percentual_Total_Acoes_Circulacao', ]]\n",
    "# fre_cia_aberta_posicao_acionaria_2023.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_relacao_familiar_2023\"\n",
    "fre_cia_aberta_relacao_familiar_2023 = read(file)\n",
    "# Parentescos\n",
    "fre_cia_aberta_relacao_familiar_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_relacao_subordinacao_2023\"\n",
    "fre_cia_aberta_relacao_subordinacao_2023 = read(file)\n",
    "# Subordnicação \n",
    "fre_cia_aberta_relacao_subordinacao_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_transacao_parte_relacionada_2023\"\n",
    "fre_cia_aberta_transacao_parte_relacionada_2023 = read(file)\n",
    "# Partes relacionadas\n",
    "fre_cia_aberta_transacao_parte_relacionada_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_2023\"\n",
    "fre_cia_aberta_2023 = read(file)\n",
    "# Link do Documento\n",
    "fre_cia_aberta_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_group(cias_por_setor, window):\n",
    "    for company, group_df in cias_por_setor:\n",
    "        try:\n",
    "            # Calculate the moving average for the last 4 periods\n",
    "            group_df['MA'] = group_df['VL_CONTA'].rolling(window=window).mean()\n",
    "            \n",
    "            # Calculate the rolling sum for the last 4 periods\n",
    "            group_df['Rolling_Sum'] = group_df['VL_CONTA'].rolling(window=window).sum()\n",
    "            \n",
    "            # Calculate the lifelong cumulative sum\n",
    "            group_df['Cumulative_Sum'] = group_df['VL_CONTA'].cumsum()\n",
    "            \n",
    "            # Plot raw data\n",
    "            # group_df['VL_CONTA'].plot(label='Raw Data', legend=True)\n",
    "\n",
    "            # Plot moving average\n",
    "            group_df['MA'].plot(label=f'{window} Quarters Moving Average', legend=True, linestyle='--')\n",
    "            \n",
    "            # Plot rolling sum\n",
    "            group_df['Rolling_Sum'].plot(label=f'{window} Quarters Sum', legend=True, linestyle='-.')\n",
    "            \n",
    "            # Plot lifelong cumulative sum\n",
    "            group_df['Cumulative_Sum'].plot(label='Lifelong Cumulative Sum', legend=True, linestyle='-.')\n",
    "\n",
    "            plt.title(f\"{group_df['CD_CVM'].iloc[-1]} {group_df['DENOM_CIA'].iloc[-1]}\")\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"Error plotting for {company}: {e}\")\n",
    "    return True\n",
    "\n",
    "cias_por_setor = df[(df['AGRUPAMENTO'] == 'con') & (df['CD_CONTA'] == '3.11')].groupby('CD_CVM')\n",
    "plot_group(cias_por_setor, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cias_por_setor = df[(df['AGRUPAMENTO'] == 'con') & (df['CD_CONTA'] == '2.03')].groupby('DENOM_CIA')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "for company, group_df in cias_por_setor:\n",
    "    try:\n",
    "        group_df[['VL_CONTA']].plot(ax=ax, label=company)\n",
    "    except:\n",
    "        print(company)\n",
    "\n",
    "ax.set_title(\"VL_CONTA by Company\")\n",
    "ax.set_ylabel(\"VL_CONTA\")\n",
    "ax.set_xlabel(\"Index\")\n",
    "ax.legend(loc=\"best\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intelacoes Fundamentalista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intelacoes = run.load_pkl(f'{b3.app_folder}intelacoes')\n",
    "intelacoes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('BENS INDUSTRIAIS_intelacoes.pkl')\n",
    "# df.to_csv('BENS INDUSTRIAIS_intelacoes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Unnamed: 0', 'FILENAME', 'DEMONSTRATIVO', 'BALANCE_SHEET', 'ANO',\n",
    "       'AGRUPAMENTO', 'CNPJ_CIA', 'DT_REFER', 'VERSAO', 'DENOM_CIA', 'CD_CVM',\n",
    "       'GRUPO_DFP', 'MOEDA', 'ESCALA_MOEDA', 'DT_FIM_EXERC', 'CD_CONTA',\n",
    "       'DS_CONTA', 'VL_CONTA', 'ST_CONTA_FIXA', 'DT_INI_EXERC', 'COLUNA_DF',\n",
    "       'COMPANHIA', 'PREGAO', 'TICK', 'LISTAGEM', 'CVM', 'TICKERS', 'ISIN',\n",
    "       'CNPJ', 'ATIVIDADE', 'SETOR', 'SUBSETOR', 'SEGMENTO', 'SITE',\n",
    "       'ESCRITURADOR', 'CD_CONTA_original', 'DS_CONTA_original', 'Companhia',\n",
    "       'Trimestre', 'Ações ON', 'Ações PN', 'Ações ON em Tesouraria',\n",
    "       'Ações PN em Tesouraria', 'URL']\n",
    "cols = ['SETOR', 'SUBSETOR', 'SEGMENTO', 'CNPJ_CIA', 'DENOM_CIA', 'CD_CVM',  'PREGAO', 'TICK', 'LISTAGEM', 'TICKERS', 'DT_REFER', 'BALANCE_SHEET', 'CD_CONTA', 'DS_CONTA', 'VL_CONTA', ]\n",
    "datetime_cols = ['DT_REFER', 'DT_FIM_EXERC', 'DT_INI_EXERC', 'Trimestre']\n",
    "company_cols = ['SETOR', 'SUBSETOR', 'SEGMENTO', 'CNPJ_CIA', 'DENOM_CIA', 'CD_CVM']\n",
    "dateseries_col = ['DT_REFER']\n",
    "sheet_cols = ['BALANCE_SHEET', 'CD_CONTA', 'DS_CONTA', 'VL_CONTA']\n",
    "stocks_cols = ['Ações ON', 'Ações PN', 'Ações ON em Tesouraria', 'Ações PN em Tesouraria']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by 'SETOR', 'SUBSETOR', and 'SEGMENTO' to count unique companies and aggregate their TICK values\n",
    "ticks_by_setor = df.groupby(['SETOR', 'SUBSETOR', 'SEGMENTO']).agg({\n",
    "    'DENOM_CIA': 'nunique',\n",
    "    'TICK': lambda x: list(set(x.dropna()))\n",
    "}).reset_index()\n",
    "\n",
    "# Renaming columns for clarity\n",
    "ticks_by_setor.rename(columns={'DENOM_CIA': 'TOTAL DE COMPANHIAS'}, inplace=True)\n",
    "\n",
    "ticks_by_setor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conta = '02.03'\n",
    "\n",
    "# Filtering the data for the account 'CD_CONTA' with value '02.03' and the latest quarter\n",
    "conta_by_setor = df[df['DT_REFER'] == df['DT_REFER'].max()]\n",
    "conta_by_setor = conta_by_setor[conta_by_setor['CD_CONTA'] == conta]\n",
    "\n",
    "# Grouping by 'SETOR', 'SUBSETOR', and 'SEGMENTO' to aggregate 'VL_CONTA' values\n",
    "conta_by_setor = conta_by_setor.groupby(['SETOR', 'SUBSETOR', 'SEGMENTO', ]).agg({\n",
    "    'VL_CONTA': ['nunique', 'sum', 'max', 'min', 'mean', 'std', 'skew', lambda x: x.kurt()]\n",
    "}).reset_index()\n",
    "\n",
    "conta_by_setor.rename(columns={'VL_CONTA': conta}, inplace=True)\n",
    "\n",
    "conta_by_setor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = df\n",
    "# dfc = dfc.set_index('DT_REFER')\n",
    "company = 'WEG SA'\n",
    "quarter = '2020-12-31'\n",
    "conta = '01.01.01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = dfc['DENOM_CIA'] != 'nothing'\n",
    "mask &= dfc['DT_REFER'] == quarter\n",
    "mask &= dfc['DENOM_CIA'] == company\n",
    "# mask &= dfc['PREGAO'] == ''\n",
    "# mask &= dfc['TICK'] == ''\n",
    "# mask &= dfc['BALANCE_SHEET'] == ''\n",
    "mask &= dfc['CD_CONTA'] == conta\n",
    "# mask &= dfc['DS_CONTA'] == ''\n",
    "\n",
    "# dfc[mask][cols]\n",
    "data = dfc[mask][['DENOM_CIA', 'DT_REFER', 'CD_CONTA', 'DS_CONTA', 'VL_CONTA']].set_index('DT_REFER')\n",
    "sheet = df[(df['DENOM_CIA'] == company) & (df['DT_REFER'] == quarter)]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = pd.concat([dfc, rows], ignore_index=True).ffill().drop_duplicates()\n",
    "m = dfc['BALANCE_SHEET'].isin(sh)\n",
    "dfc[m][cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fund"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund = load_pkl(f'{b3.app_folder}fund')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('BENS INDUSTRIAIS_fund.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('BENS INDUSTRIAIS_fund.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TICKERS'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Macro Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install yfinance -q -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baixando Cotações do Índice Bovespa\n",
    "ibov = yf.download('^BVSP')\n",
    "df = yf.download(['WEGE3.SA','BBDC4.SA', 'PETR4.SA'], group_by='ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df['WEGE3.SA']['Adj Close']))\n",
    "tickers = df.columns.get_level_values(0).unique().tolist()\n",
    "tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tick in tickers:\n",
    "    df[tick]['Adj Close'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q alpha_vantage\n",
    "# Importando a classe Timeseries de alpha_vantage.timeseries\n",
    "from alpha_vantage.timeseries import TimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHAVANTAGE_API_KEY = 'KR3OMFL1CLANZUXP'\n",
    "# Criando o objeto ts\n",
    "ts = TimeSeries(key=ALPHAVANTAGE_API_KEY, output_format='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados, meta_dados = ts.get_symbol_search('alphabet')\n",
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtendo os dados semanais do IBOV usando get_weekly\n",
    "dados, meta_dados = ts.get_daily(symbol='AAPL', )\n",
    "dados['4. close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install quandl -q -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quandl\n",
    "mydata = quandl.get(\"FRED/GDP\")\n",
    "api = 'LpAz8JCUosdwhHqnWnA4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = quandl.get_table('ZACKS/FC', ticker='AAPL',)\n",
    "mydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas datareader\n",
    "import os\n",
    "import pandas_datareader as pdr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIINGO_API_KEY = '591375a6e5852ca48f778902fec322581511c89a'\n",
    "import tiingo\n",
    "\n",
    "config = {}\n",
    "config['session'] = True\n",
    "config['api_key'] = TIINGO_API_KEY\n",
    "client = tiingo.TiingoClient(config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "TIINGO_API_KEY = '591375a6e5852ca48f778902fec322581511c89a'\n",
    "url = 'https://api.tiingo.com/tiingo/fundamentals/definitions'\n",
    "url = 'https://api.tiingo.com/tiingo/daily/AAPL/prices?startDate=2012-1-1'\n",
    "# url = 'https://api.tiingo.com/tiingo/daily/AAPL/prices'\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': 'Token ' + TIINGO_API_KEY\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "data = response.json()\n",
    "data = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['close'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pdr.DataReader('GE', 'yahoo')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Yahoo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iterrow in fund and get same key from both dict to concat both and remove duplicates\n",
    "\n",
    "save quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get BCB Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.alert import Alert\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromedriver_path = \"D:\\\\Fausto Stangler\\\\Documentos\\\\Python\\\\DSH\\\\chromedriver-win64\\\\chromedriver.exe\"\n",
    "driver_wait_time = 5\n",
    "\n",
    "driver, wait = run.load_browser(chromedriver_path, driver_wait_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_bcb = 'https://www3.bcb.gov.br/sgspub/'\n",
    "url_bcb = 'https://www3.bcb.gov.br/sgspub/localizarseries/localizarSeries.do?method=prepararTelaPesquisaAvancada'\n",
    "\n",
    "driver.get(url_bcb)\n",
    "\n",
    "try:\n",
    "    alert = Alert(driver)\n",
    "    alert.accept()\n",
    "except Exception as e:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 384)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "element_xpath = '/html/body/table[1]/tbody/tr/td[3]/a'\n",
    "element = wait.until(EC.presence_of_element_located((By.XPATH, element_xpath)))\n",
    "# Get elements in Português\n",
    "if 'Português' in element.text.splitlines():\n",
    "    element.click()\n",
    "# # Get elements in English\n",
    "# if 'English' in element.text.splitlines():\n",
    "#     element.click()\n",
    "\n",
    "# Click on the first element\n",
    "element = wait.until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"tabLCS\"]/tbody/tr/td[1]/table/tbody/tr[12]/td')))\n",
    "element.click()\n",
    "\n",
    "# Switch to the iframe\n",
    "iframe_id = 'iCorpo'\n",
    "wait.until(EC.frame_to_be_available_and_switch_to_it((By.ID, iframe_id)))\n",
    "\n",
    "# Click on the second element\n",
    "element = wait.until(EC.element_to_be_clickable((By.XPATH, '/html/body/center/form/table[1]/tbody/tr[5]/td[2]/input')))\n",
    "element.click()\n",
    "\n",
    "# Click on the third element\n",
    "element = wait.until(EC.element_to_be_clickable((By.XPATH, '/html/body/center/form/input[9]')))\n",
    "element.click()\n",
    "\n",
    "# Grab the number of items for pagination\n",
    "pagination_xpath = '/html/body/form/span[1]/span[1]/b'\n",
    "num_items = int(wait.until(EC.presence_of_element_located((By.XPATH, pagination_xpath))).text)\n",
    "\n",
    "# Read the table\n",
    "table_xpath = '//*[@id=\"tabelaSeries\"]'  # or '//*[@id=\"tabelaConjunto\"]'\n",
    "table_html = wait.until(EC.presence_of_element_located((By.XPATH, table_xpath))).get_attribute('outerHTML')\n",
    "df = pd.read_html(table_html)[0]\n",
    "\n",
    "# Determine the number of pages for pagination (assuming 10 items per page)\n",
    "items_per_page = len(df)  # Adjust as per actual items per page\n",
    "num_pages = -(-num_items // items_per_page)  # Ceiling division\n",
    "items_per_page, num_pages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the pages and extract data\n",
    "start_time = run.time.time()\n",
    "for i, page_number in enumerate(range(num_pages - 1)):  # Already have data for first page\n",
    "        # Execute the JavaScript function for pagination\n",
    "    driver.execute_script(f'getPagina({page_number})')\n",
    "    \n",
    "    # Read the table on the new page\n",
    "    table_html = wait.until(EC.presence_of_element_located((By.XPATH, table_xpath))).get_attribute('outerHTML')\n",
    "    new_df = pd.read_html(table_html)[0]\n",
    "    \n",
    "    # Loop through each row of the new data\n",
    "    for _, row in new_df.iterrows():\n",
    "        # Extract the relevant parameter for JavaScript function from the row\n",
    "        series = row['Cód.']  # replace 'YourColumnName' with the actual column name\n",
    "        \n",
    "        # Execute the JavaScript function\n",
    "        driver.execute_script(f\"parent.pesquisarPorDocn('../localizarseries/localizarSeries.do?method=recuperarMetadadosPorDocn', '{series}', 'Dados básicos/Metadados');\")\n",
    "        print('grab the table xpath and save into new_df')\n",
    "        # Grab the data you need after executing the JavaScript\n",
    "        # Your code for grabbing data goes here...\n",
    "        \n",
    "        # NOTE: Be sure to implement appropriate waiting and checking for elements to ensure data is loaded before you try to grab it.\n",
    "\n",
    "    # Append the new data to the existing dataframe\n",
    "    df = pd.concat([df, new_df], ignore_index=True)\n",
    "    print(run.remaining_time(start_time, (num_pages - 1), i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sel.</th>\n",
       "      <th>Cód.</th>\n",
       "      <th>Nome completo</th>\n",
       "      <th>Unid.</th>\n",
       "      <th>Per.</th>\n",
       "      <th>Início  dd/MM/aaaa</th>\n",
       "      <th>Últ. valor</th>\n",
       "      <th>Fonte</th>\n",
       "      <th>Esp.</th>\n",
       "      <th>Met.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4271</td>\n",
       "      <td>Exportações (Kg) - Pneumáticos</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>ago/2019</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4272</td>\n",
       "      <td>Exportações (Kg) - Polímeros de etileno, propi...</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>ago/2019</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4274</td>\n",
       "      <td>Exportações (Kg) - Produtos laminados planos d...</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>ago/2019</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4275</td>\n",
       "      <td>Exportações (Kg) - Rolamentos e engrenagens, p...</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>ago/2019</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4276</td>\n",
       "      <td>Exportações (Kg) - Suco de laranja</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>ago/2019</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4277</td>\n",
       "      <td>Exportações (Kg) - Tubos de ferro fundido, fer...</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>ago/2019</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4278</td>\n",
       "      <td>Exportações (Kg) - Veículos de carga</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>ago/2019</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4279</td>\n",
       "      <td>Exportações (Kg) - Demais produtos manufaturados</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>ago/2019</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4280</td>\n",
       "      <td>Exportações (Kg) - Operações especiais</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>ago/2019</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4281</td>\n",
       "      <td>Importações (Kg) - Total (MDIC)</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1971</td>\n",
       "      <td>ago/2019</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4282</td>\n",
       "      <td>Importações (Kg) - Bens de consumo duráveis</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>jan/2017</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4283</td>\n",
       "      <td>Importações (Kg) - Máquinas e aparelhos de uso...</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>jan/2017</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4284</td>\n",
       "      <td>Importações (Kg) - Móveis e outros equipamento...</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>jan/2017</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4285</td>\n",
       "      <td>Importações (Kg) - Objetos de adorno, de uso p...</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>jan/2017</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4286</td>\n",
       "      <td>Importações (Kg) - Partes e peças para bens de...</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>jan/2017</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4287</td>\n",
       "      <td>Importações (Kg) - Utensílios domésticos</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>jan/2017</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4288</td>\n",
       "      <td>Importações (Kg) - Veículos automóveis de pass...</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>jan/2017</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4289</td>\n",
       "      <td>Importações (Kg) - Outros bens de consumo durá...</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>jan/2017</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4290</td>\n",
       "      <td>Importações (Kg) - Bens de consumo não duráveis</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>jan/2017</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4291</td>\n",
       "      <td>Importações (Kg) - Bebidas e tabacos</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>jan/2017</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4292</td>\n",
       "      <td>Importações (Kg) - Produtos alimentícios - 4292</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>jan/2017</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4293</td>\n",
       "      <td>Importações (Kg) - Produtos farmacêuticos</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>jan/2017</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4294</td>\n",
       "      <td>Importações (Kg) - Produtos de toucador</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>jan/2017</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4295</td>\n",
       "      <td>Importações (Kg) - Vestuário e outras confecçõ...</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>jan/2017</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4296</td>\n",
       "      <td>Importações (Kg) - Outros bens de consumo não-...</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>jan/2017</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4297</td>\n",
       "      <td>Importações (Kg) - Matérias-primas e produtos ...</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>jan/2017</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4298</td>\n",
       "      <td>Importações (Kg) - Acessórios de equipamento d...</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>jan/2017</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4299</td>\n",
       "      <td>Importações (Kg) - Alimentos para animais</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>jan/2017</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4300</td>\n",
       "      <td>Importações (Kg) - Materiais de construção</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>jan/2017</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4301</td>\n",
       "      <td>Importações (Kg) - Outras matérias-primas para...</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>jan/2017</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4302</td>\n",
       "      <td>Importações (Kg) - Partes e peças para equipam...</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>jan/2017</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4303</td>\n",
       "      <td>Importações (Kg) - Produtos agropecuários não-...</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>jan/2017</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4304</td>\n",
       "      <td>Importações (Kg) - Produtos alimentícios - 4304</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>jan/2017</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4305</td>\n",
       "      <td>Importações (Kg) - Produtos intermediários Par...</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>jan/2017</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4306</td>\n",
       "      <td>Importações (Kg) - Produtos minerais</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>jan/2017</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4307</td>\n",
       "      <td>Importações (Kg) - Produtos químicos e farmacê...</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>jan/2017</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4308</td>\n",
       "      <td>Importações (Kg) - Outras matérias-primas e pr...</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>jan/2017</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4309</td>\n",
       "      <td>Importações (Kg) - Bens de capital</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>jan/2017</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4310</td>\n",
       "      <td>Importações (Kg) - Acessórios de maquinaria in...</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>jan/2017</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4311</td>\n",
       "      <td>Importações (Kg) - Equipamento fixo de transporte</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>jan/2017</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4312</td>\n",
       "      <td>Importações (Kg) - Equipamento móvel de transp...</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>jan/2017</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4313</td>\n",
       "      <td>Importações (Kg) - Ferramentas</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>jan/2017</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4314</td>\n",
       "      <td>Importações (Kg) - Máquinas e aparelhos de esc...</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>jan/2017</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4315</td>\n",
       "      <td>Importações (Kg) - Máquinas e ferramentas</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>jan/2017</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4316</td>\n",
       "      <td>Importações (Kg) - Maquinaria industrial</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>jan/2017</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4318</td>\n",
       "      <td>Importações (Kg) - Outros bens ou equipamentos...</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>jan/2017</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4320</td>\n",
       "      <td>Importações (Kg) - Partes e peças para bens de...</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>jan/2017</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4321</td>\n",
       "      <td>Importações (Kg) - Partes e peças para bens de...</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>jan/2017</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4322</td>\n",
       "      <td>Importações (Kg) - Outros bens de capital</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>jan/2017</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4323</td>\n",
       "      <td>Importações (Kg) - Combustíveis e lubrificantes</td>\n",
       "      <td>kg</td>\n",
       "      <td>M</td>\n",
       "      <td>31/01/1989</td>\n",
       "      <td>jan/2017</td>\n",
       "      <td>MDIC/Secex</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sel.  Cód.                                      Nome completo Unid. Per.  \\\n",
       "0    NaN  4271                     Exportações (Kg) - Pneumáticos    kg    M   \n",
       "1    NaN  4272  Exportações (Kg) - Polímeros de etileno, propi...    kg    M   \n",
       "2    NaN  4274  Exportações (Kg) - Produtos laminados planos d...    kg    M   \n",
       "3    NaN  4275  Exportações (Kg) - Rolamentos e engrenagens, p...    kg    M   \n",
       "4    NaN  4276                 Exportações (Kg) - Suco de laranja    kg    M   \n",
       "5    NaN  4277  Exportações (Kg) - Tubos de ferro fundido, fer...    kg    M   \n",
       "6    NaN  4278               Exportações (Kg) - Veículos de carga    kg    M   \n",
       "7    NaN  4279   Exportações (Kg) - Demais produtos manufaturados    kg    M   \n",
       "8    NaN  4280             Exportações (Kg) - Operações especiais    kg    M   \n",
       "9    NaN  4281                    Importações (Kg) - Total (MDIC)    kg    M   \n",
       "10   NaN  4282        Importações (Kg) - Bens de consumo duráveis    kg    M   \n",
       "11   NaN  4283  Importações (Kg) - Máquinas e aparelhos de uso...    kg    M   \n",
       "12   NaN  4284  Importações (Kg) - Móveis e outros equipamento...    kg    M   \n",
       "13   NaN  4285  Importações (Kg) - Objetos de adorno, de uso p...    kg    M   \n",
       "14   NaN  4286  Importações (Kg) - Partes e peças para bens de...    kg    M   \n",
       "15   NaN  4287           Importações (Kg) - Utensílios domésticos    kg    M   \n",
       "16   NaN  4288  Importações (Kg) - Veículos automóveis de pass...    kg    M   \n",
       "17   NaN  4289  Importações (Kg) - Outros bens de consumo durá...    kg    M   \n",
       "18   NaN  4290    Importações (Kg) - Bens de consumo não duráveis    kg    M   \n",
       "19   NaN  4291               Importações (Kg) - Bebidas e tabacos    kg    M   \n",
       "20   NaN  4292    Importações (Kg) - Produtos alimentícios - 4292    kg    M   \n",
       "21   NaN  4293          Importações (Kg) - Produtos farmacêuticos    kg    M   \n",
       "22   NaN  4294            Importações (Kg) - Produtos de toucador    kg    M   \n",
       "23   NaN  4295  Importações (Kg) - Vestuário e outras confecçõ...    kg    M   \n",
       "24   NaN  4296  Importações (Kg) - Outros bens de consumo não-...    kg    M   \n",
       "25   NaN  4297  Importações (Kg) - Matérias-primas e produtos ...    kg    M   \n",
       "26   NaN  4298  Importações (Kg) - Acessórios de equipamento d...    kg    M   \n",
       "27   NaN  4299          Importações (Kg) - Alimentos para animais    kg    M   \n",
       "28   NaN  4300         Importações (Kg) - Materiais de construção    kg    M   \n",
       "29   NaN  4301  Importações (Kg) - Outras matérias-primas para...    kg    M   \n",
       "30   NaN  4302  Importações (Kg) - Partes e peças para equipam...    kg    M   \n",
       "31   NaN  4303  Importações (Kg) - Produtos agropecuários não-...    kg    M   \n",
       "32   NaN  4304    Importações (Kg) - Produtos alimentícios - 4304    kg    M   \n",
       "33   NaN  4305  Importações (Kg) - Produtos intermediários Par...    kg    M   \n",
       "34   NaN  4306               Importações (Kg) - Produtos minerais    kg    M   \n",
       "35   NaN  4307  Importações (Kg) - Produtos químicos e farmacê...    kg    M   \n",
       "36   NaN  4308  Importações (Kg) - Outras matérias-primas e pr...    kg    M   \n",
       "37   NaN  4309                 Importações (Kg) - Bens de capital    kg    M   \n",
       "38   NaN  4310  Importações (Kg) - Acessórios de maquinaria in...    kg    M   \n",
       "39   NaN  4311  Importações (Kg) - Equipamento fixo de transporte    kg    M   \n",
       "40   NaN  4312  Importações (Kg) - Equipamento móvel de transp...    kg    M   \n",
       "41   NaN  4313                     Importações (Kg) - Ferramentas    kg    M   \n",
       "42   NaN  4314  Importações (Kg) - Máquinas e aparelhos de esc...    kg    M   \n",
       "43   NaN  4315          Importações (Kg) - Máquinas e ferramentas    kg    M   \n",
       "44   NaN  4316           Importações (Kg) - Maquinaria industrial    kg    M   \n",
       "45   NaN  4318  Importações (Kg) - Outros bens ou equipamentos...    kg    M   \n",
       "46   NaN  4320  Importações (Kg) - Partes e peças para bens de...    kg    M   \n",
       "47   NaN  4321  Importações (Kg) - Partes e peças para bens de...    kg    M   \n",
       "48   NaN  4322          Importações (Kg) - Outros bens de capital    kg    M   \n",
       "49   NaN  4323    Importações (Kg) - Combustíveis e lubrificantes    kg    M   \n",
       "\n",
       "   Início  dd/MM/aaaa Últ. valor       Fonte Esp.  Met.  \n",
       "0          31/01/1989   ago/2019  MDIC/Secex    N   NaN  \n",
       "1          31/01/1989   ago/2019  MDIC/Secex    N   NaN  \n",
       "2          31/01/1989   ago/2019  MDIC/Secex    N   NaN  \n",
       "3          31/01/1989   ago/2019  MDIC/Secex    N   NaN  \n",
       "4          31/01/1989   ago/2019  MDIC/Secex    N   NaN  \n",
       "5          31/01/1989   ago/2019  MDIC/Secex    N   NaN  \n",
       "6          31/01/1989   ago/2019  MDIC/Secex    N   NaN  \n",
       "7          31/01/1989   ago/2019  MDIC/Secex    N   NaN  \n",
       "8          31/01/1989   ago/2019  MDIC/Secex    N   NaN  \n",
       "9          31/01/1971   ago/2019  MDIC/Secex    N   NaN  \n",
       "10         31/01/1989   jan/2017  MDIC/Secex    N   NaN  \n",
       "11         31/01/1989   jan/2017  MDIC/Secex    N   NaN  \n",
       "12         31/01/1989   jan/2017  MDIC/Secex    N   NaN  \n",
       "13         31/01/1989   jan/2017  MDIC/Secex    N   NaN  \n",
       "14         31/01/1989   jan/2017  MDIC/Secex    N   NaN  \n",
       "15         31/01/1989   jan/2017  MDIC/Secex    N   NaN  \n",
       "16         31/01/1989   jan/2017  MDIC/Secex    N   NaN  \n",
       "17         31/01/1989   jan/2017  MDIC/Secex    N   NaN  \n",
       "18         31/01/1989   jan/2017  MDIC/Secex    N   NaN  \n",
       "19         31/01/1989   jan/2017  MDIC/Secex    N   NaN  \n",
       "20         31/01/1989   jan/2017  MDIC/Secex    N   NaN  \n",
       "21         31/01/1989   jan/2017  MDIC/Secex    N   NaN  \n",
       "22         31/01/1989   jan/2017  MDIC/Secex    N   NaN  \n",
       "23         31/01/1989   jan/2017  MDIC/Secex    N   NaN  \n",
       "24         31/01/1989   jan/2017  MDIC/Secex    N   NaN  \n",
       "25         31/01/1989   jan/2017  MDIC/Secex    N   NaN  \n",
       "26         31/01/1989   jan/2017  MDIC/Secex    N   NaN  \n",
       "27         31/01/1989   jan/2017  MDIC/Secex    N   NaN  \n",
       "28         31/01/1989   jan/2017  MDIC/Secex    N   NaN  \n",
       "29         31/01/1989   jan/2017  MDIC/Secex    N   NaN  \n",
       "30         31/01/1989   jan/2017  MDIC/Secex    N   NaN  \n",
       "31         31/01/1989   jan/2017  MDIC/Secex    N   NaN  \n",
       "32         31/01/1989   jan/2017  MDIC/Secex    N   NaN  \n",
       "33         31/01/1989   jan/2017  MDIC/Secex    N   NaN  \n",
       "34         31/01/1989   jan/2017  MDIC/Secex    N   NaN  \n",
       "35         31/01/1989   jan/2017  MDIC/Secex    N   NaN  \n",
       "36         31/01/1989   jan/2017  MDIC/Secex    N   NaN  \n",
       "37         31/01/1989   jan/2017  MDIC/Secex    N   NaN  \n",
       "38         31/01/1989   jan/2017  MDIC/Secex    N   NaN  \n",
       "39         31/01/1989   jan/2017  MDIC/Secex    N   NaN  \n",
       "40         31/01/1989   jan/2017  MDIC/Secex    N   NaN  \n",
       "41         31/01/1989   jan/2017  MDIC/Secex    N   NaN  \n",
       "42         31/01/1989   jan/2017  MDIC/Secex    N   NaN  \n",
       "43         31/01/1989   jan/2017  MDIC/Secex    N   NaN  \n",
       "44         31/01/1989   jan/2017  MDIC/Secex    N   NaN  \n",
       "45         31/01/1989   jan/2017  MDIC/Secex    N   NaN  \n",
       "46         31/01/1989   jan/2017  MDIC/Secex    N   NaN  \n",
       "47         31/01/1989   jan/2017  MDIC/Secex    N   NaN  \n",
       "48         31/01/1989   jan/2017  MDIC/Secex    N   NaN  \n",
       "49         31/01/1989   jan/2017  MDIC/Secex    N   NaN  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_number = 3397\n",
    "driver.execute_script(f\"parent.pesquisarPorDocn('../localizarseries/localizarSeries.do?method=recuperarMetadadosPorDocn', '{series_number}', 'Dados básicos/Metadados');\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integrate fund to quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrate funds to quotes, so each TICK contains quotes and also also all financial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = run.load_pkl(f'{b3.app_folder}quotes')\n",
    "fund = run.load_pkl(f'{b3.app_folder}fund')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes.keys(), quotes['AERIS'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdata = []\n",
    "for pregao, d in quotes.items():\n",
    "    for ticker, df in d.items():\n",
    "        try:\n",
    "            df.insert(0, 'PREGAO', pregao)\n",
    "        except Exception as e:\n",
    "            df['PREGAO'] = pregao  # Update 'PREGAO' column\n",
    "        \n",
    "        try:\n",
    "            df['TICKER'] = ticker  # Update 'TICKER' column\n",
    "        except Exception as e:\n",
    "            df.insert(1, 'TICKER', ticker)\n",
    "\n",
    "        bigdata.append(df)\n",
    "bigdata = pd.concat(bigdata, ignore_index=False)\n",
    "bigdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data subset\n",
    "df_fund = fund['BENS INDUSTRIAIS']\n",
    "\n",
    "# Data preprocessing\n",
    "# Convert specific columns to object type\n",
    "df_fund[['VERSAO', 'CD_CVM']] = df_fund[['VERSAO', 'CD_CVM']].astype('object')\n",
    "\n",
    "# Convert 'DT_REFER' to datetime format\n",
    "df_fund['DT_REFER'] = pd.to_datetime(df_fund['DT_REFER'])\n",
    "\n",
    "# Pivot for CD_CONTA\n",
    "df_cd_conta = df_fund.pivot_table(index=['DT_REFER', 'PREGAO'], \n",
    "                                  columns=['CD_CONTA', 'DS_CONTA'], \n",
    "                                  values='VL_CONTA', \n",
    "                                  aggfunc='sum').reset_index()\n",
    "\n",
    "# Flatten the multi-level columns after pivot\n",
    "df_cd_conta.columns = [' - '.join(col).strip(' - ') for col in df_cd_conta.columns.values]\n",
    "\n",
    "# Extract unique combinations of DT_REFER and PREGAO without the account details and get an unique mapping between the dates, PREGAO, and the pivoted account data.\n",
    "df_unique = df_fund.reset_index(drop=True).drop_duplicates(subset=['DT_REFER', 'PREGAO']).drop(['CD_CONTA', 'DS_CONTA', 'VL_CONTA'], axis=1)\n",
    "df_merged = pd.merge(df_unique, df_cd_conta, on=['DT_REFER', 'PREGAO'])\n",
    "\n",
    "# Set index and handle missing values\n",
    "df_merged = df_merged.set_index(['DT_REFER', 'PREGAO'], drop=True)\n",
    "\n",
    "# Group by 'PREGAO' and apply resampling\n",
    "df_resampled = (\n",
    "    df_merged\n",
    "    .reset_index()\n",
    "    .groupby('PREGAO')\n",
    "    .apply(lambda group: group.set_index('DT_REFER').resample('D').asfreq().ffill().bfill().fillna(0))\n",
    "    .drop('PREGAO', axis=1)  # Drop the redundant 'PREGAO' column introduced by `groupby`\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdata = bigdata.reset_index()\n",
    "bigdata['Date'] = pd.to_datetime(bigdata['Date'])\n",
    "df_resampled = df_resampled.reset_index()\n",
    "df_resampled['DT_REFER'] = pd.to_datetime(df_resampled['DT_REFER'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Get unique PREGAO values from df_resampled\n",
    "companies = df_resampled['PREGAO'].unique()\n",
    "\n",
    "# Step 2: Filter bigdata\n",
    "filtered_bigdata = bigdata[bigdata['PREGAO'].isin(companies)]\n",
    "\n",
    "df_merged = pd.merge(filtered_bigdata, df_resampled, left_on=['Date', 'PREGAO'], right_on=['DT_REFER', 'PREGAO'], how='outer')\n",
    "\n",
    "# Sort the dataframe by 'PREGAO' and 'Date'\n",
    "df_merged = df_merged.sort_values(by=['PREGAO', 'Date'])\n",
    "\n",
    "# Group by 'PREGAO', then apply the fill methods within each group\n",
    "df_merged = df_merged.groupby('PREGAO', group_keys=False).apply(lambda group: group.ffill().bfill()).fillna(0).reset_index(drop=True)\n",
    "\n",
    "# Fill any remaining NaN values in the entire dataframe (outside of groups)\n",
    "df_merged = df_merged.set_index('Date', drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_metrics(df):\n",
    "    # Ensure no division by zero for all columns\n",
    "    df.replace(0, np.nan, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged.groupby('PREGAO', group_keys=False).apply(add_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company = companies[0]\n",
    "company = 'WEG'\n",
    "df = df_merged[df_merged['PREGAO'] == company]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setor, subsetor, segmento = df[['SETOR', 'SUBSETOR', 'SEGMENTO']].iloc[0]\n",
    "setor, subsetor, segmento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_cia = df_merged['PREGAO'] != company\n",
    "m_segmento = df_merged['SEGMENTO'] == segmento\n",
    "m_subsetor = df_merged['SUBSETOR'] == subsetor\n",
    "m_setor = df_merged['SETOR'] == setor\n",
    "\n",
    "cias_segmento = [cia for cia in df_merged[m_cia & m_segmento]['PREGAO'].unique().tolist()]\n",
    "cias_subsetor = [cia for cia in df_merged[m_cia & m_subsetor]['PREGAO'].unique().tolist() if cia not in cias_segmento]\n",
    "cias_setor = [cia for cia in df_merged[m_cia & m_setor]['PREGAO'].unique().tolist() if cia not in cias_subsetor and cia not in cias_segmento]\n",
    "cias_segmento, cias_subsetor, cias_setor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = np.sort(df['TICKER'].unique())\n",
    "df_ticker = []\n",
    "for ticker in tickers:\n",
    "    df_ticker.append(df[df['TICKER'] == ticker])\n",
    "df = df_ticker[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(df, subcolumns):\n",
    "    \"\"\"\n",
    "    Normalize data columns in a dataframe to their percentage of row-wise total.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Dataframe containing data to be normalized.\n",
    "    subcolumns : list of str\n",
    "        List of column names to be normalized.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    normalized_df : pd.DataFrame\n",
    "        Dataframe with normalized columns.\n",
    "    \"\"\"\n",
    "    # Filter subcolumns to include only columns that actually exist in df\n",
    "    subcolumns = [col for col in subcolumns if col in df.columns]\n",
    "\n",
    "    # Make a copy of the specified columns to prevent modifying the original dataframe\n",
    "    temp_df = df[subcolumns].copy()\n",
    "    \n",
    "    # Ensure there are no NaN values at the start of the columns\n",
    "    # [You might adapt this as per your requirement]\n",
    "    temp_df = temp_df.dropna(subset=subcolumns, how='all')\n",
    "    \n",
    "    # Calculate the total of the specified columns row-wise\n",
    "    temp_df['total'] = temp_df.sum(axis=1)\n",
    "\n",
    "    # Normalize each specified column by its percentage of the row-wise total\n",
    "    for column in subcolumns:\n",
    "        temp_df[column] = temp_df.apply(\n",
    "            lambda row: round(row[column] / row['total'] * 100, 2) if row['total'] != 0 else 0, \n",
    "            axis=1\n",
    "        )\n",
    "    \n",
    "    # Drop the total column and return the normalized dataframe\n",
    "    normalized_df = temp_df.drop(columns=['total'])\n",
    "    \n",
    "    return normalized_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclude_outliers(item, multiplier=1.5):\n",
    "    \"\"\"\n",
    "    Exclude outliers from a data series using \n",
    "    the Interquartile Range (IQR) method and a personalized multiplier.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_series : pd.Series\n",
    "        The original data series from which outliers will be excluded.\n",
    "    multiplier : float\n",
    "        The multiplier for the IQR. Outliers are defined as values below \n",
    "        Q1 - (multiplier * IQR) or above Q3 + (multiplier * IQR).\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    inliers : pd.Series\n",
    "        The data series with outliers excluded.\n",
    "    \"\"\"\n",
    "    data_series = df[item] if isinstance(item, str) else item\n",
    "\n",
    "    # Calculate the first (Q1) and third (Q3) quartiles\n",
    "    Q1 = data_series.quantile(0.25)\n",
    "    Q3 = data_series.quantile(0.75)\n",
    "    \n",
    "    # Calculate the Interquartile Range (IQR)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Define lower and upper bounds for inliers\n",
    "    lower_bound = Q1 - multiplier * IQR\n",
    "    upper_bound = Q3 + multiplier * IQR\n",
    "    \n",
    "    # Identify and return inliers\n",
    "    inliers = data_series[(data_series > lower_bound) & (data_series < upper_bound)]\n",
    "    \n",
    "    return inliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cagr(item, years=3):\n",
    "    \"\"\"\n",
    "    Calculate the Compound Annual Growth Rate (CAGR) for a given data series.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    item : str or pd.Series\n",
    "        The actual values for which the CAGR will be calculated. \n",
    "        Can be a string (column name) or a pandas Series.\n",
    "    years : int\n",
    "        The number of years over which the CAGR will be calculated.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    data_series : pd.Series\n",
    "        The CAGR values.\n",
    "    \"\"\"\n",
    "    # Retrieve the data series from the dataframe if item is a string (column name)\n",
    "    data_series = df[item] if isinstance(item, str) else item\n",
    "    \n",
    "    # Calculate the CAGR: [ (Ending Value / Beginning Value) ^ (1 / Number of Years) ] - 1\n",
    "    # Shift the original data series by the number of periods to calculate the growth rate\n",
    "    data_series = ((data_series / data_series.shift(periods=round(21*12*years))) ** (1/years)) - 1\n",
    "    \n",
    "    # Convert CAGR to percentage and smooth (accordingly to year) the series by taking a moving average, and round the series to two decimal places\n",
    "    data_series = data_series * 100\n",
    "    data_series = data_series.rolling(window=int(years*4)).mean()\n",
    "    data_series = data_series.round(2)\n",
    "    \n",
    "    # Name it appropriately\n",
    "    data_series.name = f'CAGR {years}a - {data_series.name.split(\" - \")[1]}'\n",
    "    \n",
    "    return data_series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ofs(item, years=3):\n",
    "    \"\"\"\n",
    "    Calculate the Oscillator Following the Stock (OFS) for a given data series.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_serie : pd.Series\n",
    "        The actual values for which the OFS oscillator will be calculated.\n",
    "    window : int\n",
    "        The window size for calculating the moving average and standard deviation.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    ofs : pd.Series\n",
    "        The OFS oscillator values, smoothed with a moving average.\n",
    "    \"\"\"\n",
    "    data_series = df[item] if isinstance(item, str) else item\n",
    "\n",
    "    # Calculate the moving average (mma) and standard deviation (std)\n",
    "    mma = data_series.rolling(window=int(21*12*years)).mean()\n",
    "    std = data_series.rolling(window=int(21*12*years)).std()\n",
    "    \n",
    "    # Define the high and low levels\n",
    "    high_level = mma + 2 * std\n",
    "    low_level = mma - 2 * std\n",
    "    \n",
    "    # Calculate the OFS oscillator, where +2 std=100 and -2 std=-100\n",
    "    data_series = ((data_series - low_level) / (high_level - low_level)) * 20 - 10\n",
    "    \n",
    "    # Smooth the OFS oscillator with a moving average\n",
    "    data_series = data_series.rolling(window=int(years*4)).mean()\n",
    "\n",
    "    # Name the series appropriately\n",
    "    data_series.name = f'OFS {years}a - {data_series.name.split(\" - \")[1]}'\n",
    "\n",
    "    return data_series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tweak(df: pd.DataFrame, data: Dict[str, Any], \n",
    "               options: Optional[Dict[str, Dict[str, Any]]] = {}) -> go.Figure:\n",
    "    \"\"\"\n",
    "    Generates a custom Plotly figure based on the provided data and visualization options.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The primary data source containing the columns to be plotted.\n",
    "        \n",
    "    data : dict\n",
    "        Contains metadata and column names/series for plotting. The dictionary should have the keys:\n",
    "        - 'title' : List containing the main title, left y-axis title, and right y-axis title.\n",
    "        - 'left' : List containing columns or series to be plotted on the left y-axis.\n",
    "        - 'right' : List containing columns or series to be plotted on the right y-axis.\n",
    "        \n",
    "    options : dict, optional\n",
    "        Contains visualization options for left and right data. Each side (left/right) can have:\n",
    "        - 'shape' : str, optional (default is 'line')\n",
    "            Shape of the plot, either 'line' or 'area'.\n",
    "        - 'mode' : str, optional (default is 'standalone')\n",
    "            Data representation mode, either 'standalone' or 'cumulative'.\n",
    "        - 'legendgroup' : str, optional\n",
    "            String to combine legend items into a group.\n",
    "        - 'normalization' : bool, optional (default is False)\n",
    "            Indicates if the data should be normalized.\n",
    "        - 'mma': tuple of (float, float), optional\n",
    "            Contains values for a moving average and its multiplier for standard deviation. \n",
    "            Format is (moving_average_period, standard_deviation_multiplier). None by default.\n",
    "        - 'outliers': bool, optional (default is False)\n",
    "            Indicates if outliers should be excluded.\n",
    "        - 'flexible_range': bool, optional (default is False)\n",
    "            If True, the max_min range logic is not applied. If False, it is applied.\n",
    "            \n",
    "    Returns:\n",
    "    -------\n",
    "    plotly.graph_objs.Figure\n",
    "        The generated Plotly figure.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the figure object and variables\n",
    "    company, ticker = df[['PREGAO', 'TICKER']].iloc[0]\n",
    "    fig = go.Figure()\n",
    "\n",
    "    def get_data_from_item(item, normalize=False, columns_for_normalization=None, \n",
    "                        exclude_outliers_multiplier=None, ofs=None):\n",
    "        \"\"\"\n",
    "        Retrieve data from either dataframe columns or directly from a pandas Series, \n",
    "        with optional outlier exclusion and z-score calculation.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            data_series = df[item] if isinstance(item, str) else item\n",
    "        \n",
    "            if normalize:\n",
    "                if isinstance(item, str):\n",
    "                    # If item is a string (column name), normalize using other columns if provided\n",
    "                    data_series = normalize_data(df, columns_for_normalization or [item])[item]\n",
    "                else:\n",
    "                    # If item is a Series, normalize only the series\n",
    "                    data_series = (data_series - data_series.min()) / (data_series.max() - data_series.min())\n",
    "\n",
    "            if exclude_outliers_multiplier is not None:\n",
    "                data_series = exclude_outliers(data_series, exclude_outliers_multiplier)\n",
    "\n",
    "        except Exception as e:\n",
    "            return pd.DataFrame(index=df.index)\n",
    "\n",
    "        return data_series\n",
    "\n",
    "    def get_trace(item, group, shape, mode, normalization, \n",
    "                columns_for_normalization=None, mma=None, \n",
    "                exclude_outliers_multiplier=None):\n",
    "        \"\"\"\n",
    "        Get trace(s) for the provided item with specified configurations.\n",
    "        \"\"\"\n",
    "        column_data = get_data_from_item(\n",
    "            item, normalization, columns_for_normalization, \n",
    "            exclude_outliers_multiplier\n",
    "        )\n",
    "        # Basic trace\n",
    "        try:\n",
    "            trace = {\n",
    "                'x': column_data.index,\n",
    "                'y': column_data,\n",
    "                'name': item.split(' - ')[1] if isinstance(item, str) else item.name,\n",
    "                'fill': 'tonexty' if shape == 'area' and mode == 'cumulative' else \n",
    "                        'tozeroy' if shape == 'area' else 'none',\n",
    "                'stackgroup': group if mode == 'cumulative' else None\n",
    "            }\n",
    "\n",
    "            traces = [trace]\n",
    "\n",
    "            # Statistics based on MMA\n",
    "            if mma:\n",
    "                window = int(21 * 12 * mma[0])\n",
    "                rolling_average = column_data.rolling(window=window).mean()\n",
    "                rolling_std = column_data.rolling(window=window).std()\n",
    "                \n",
    "                # MMA trace\n",
    "                traces.append({\n",
    "                    'x': column_data.index,\n",
    "                    'y': rolling_average,\n",
    "                    'mode': 'lines',\n",
    "                    'name': f'Média {(mma[0]):.0f}a ± {mma[1]}dp',\n",
    "                    'line': {'color': 'green'}, \n",
    "                    'legendgroup': 'mma', \n",
    "                })\n",
    "\n",
    "                # Traces for ± standard deviations from the MMA\n",
    "                traces.append({\n",
    "                    'x': column_data.index,\n",
    "                    'y': rolling_average + mma[1] * rolling_std,\n",
    "                    'mode': 'lines',\n",
    "                    'name': f'+{mma[1]} STD',\n",
    "                    'line': {'color': 'green', 'dash': 'dash'}, \n",
    "                    'legendgroup': 'mma', \n",
    "                    'showlegend': False, \n",
    "                })\n",
    "\n",
    "                traces.append({\n",
    "                    'x': column_data.index,\n",
    "                    'y': rolling_average - mma[1] * rolling_std,\n",
    "                    'mode': 'lines',\n",
    "                    'name': f'-{mma[1]} STD',\n",
    "                    'line': {'color': 'green', 'dash': 'dash'}, \n",
    "                    'legendgroup': 'mma', \n",
    "                    'showlegend': False, \n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            return []\n",
    "\n",
    "        return traces\n",
    "\n",
    "    def update_axis_bounds(fig, side, g_max, g_min, options, default_settings):\n",
    "        \"\"\"\n",
    "        ...\n",
    "        options : dict, optional\n",
    "            Contains visualization options for left and right data. Each side (left/right) can have:\n",
    "            ...\n",
    "            - 'range': bool or str, optional (default is False)\n",
    "                Determines the logic used to set the y-axis bounds:\n",
    "                - 'flexible': No custom logic, Plotly determines y-axis bounds.\n",
    "                - False: Upper bound is set to the nearest power of 10 above the maximum data value.\n",
    "                - 'half': Upper bound is set to the nearest multiple of 5 above the maximum data value.\n",
    "                - 'full': Upper bound is set to the nearest power of 10 above the maximum data value.\n",
    "        ...\n",
    "        \"\"\"\n",
    "        range_option = options.get(side, {}).get('range', default_settings['range'])\n",
    "        \n",
    "        # Check if range logic should be applied\n",
    "        if (\n",
    "            range_option not in ['flexible', 'full'] and \n",
    "            g_max != float('-inf') and \n",
    "            g_min != float('inf')\n",
    "        ):\n",
    "            # Determine upper bound\n",
    "            if range_option == 'half':\n",
    "                upper_bound = 5 * 10 ** math.ceil(math.log10(g_max) - 1)\n",
    "            elif range_option == False:  # or any other invalid value\n",
    "                upper_bound = 10 ** math.ceil(math.log10(g_max))\n",
    "            upper_bound = upper_bound if g_max > 0 else g_max\n",
    "            \n",
    "            # Determine lower bound\n",
    "            lower_bound = 10 ** math.floor(math.log10(g_min)) if g_min > 0 else g_min\n",
    "            \n",
    "            # Update layout\n",
    "            axis_key = 'yaxis' if side == 'left' else 'yaxis2'\n",
    "            fig.update_layout({axis_key: dict(range=[lower_bound, upper_bound])})\n",
    "\n",
    "   # Default settings for visualization\n",
    "    default_settings = {\n",
    "        'shape': 'line',\n",
    "        'mode': 'standalone',\n",
    "        'legendgroup': None,\n",
    "        'normalization': False, \n",
    "        'normalization_columns': None, \n",
    "        'mma': None, \n",
    "        'outliers': None, \n",
    "        'range': 'flexible', \n",
    "    }\n",
    "    \n",
    "    # Flags to determine if we have data on either side\n",
    "    left_data_exists = any(item.startswith('left') for item in data.keys())\n",
    "    right_data_exists = any(item.startswith('right') for item in data.keys())\n",
    "\n",
    "    # Initialize variables for storing the global max and min values for each side\n",
    "    global_max = {'left': float('-inf'), 'right': float('-inf')}\n",
    "    global_min = {'left': float('inf'), 'right': float('inf')}\n",
    "\n",
    "    # Process each side separately\n",
    "    for side, items in data.items():\n",
    "        # Skip if the side is 'title'\n",
    "        if side == 'title':\n",
    "            continue\n",
    "        \n",
    "        # Determine the base side (left or right)\n",
    "        side_base = 'left' if 'left' in side else 'right' if 'right' in side else None\n",
    "        \n",
    "        if side_base:\n",
    "            # Get the options for this side, if any\n",
    "            side_options = {**default_settings, **options.get(side, {})}\n",
    "            \n",
    "            # Generate traces for this side\n",
    "            for item in items:\n",
    "                traces = get_trace(item, side, \n",
    "                                   side_options['shape'],\n",
    "                                   side_options['mode'],\n",
    "                                   side_options['normalization'],\n",
    "                                   side_options['normalization_columns'] or items, \n",
    "                                   side_options['mma'],\n",
    "                                   side_options['outliers'],\n",
    "                                   )\n",
    "                for trace in traces:\n",
    "                    if side_options.get('legendgroup'):\n",
    "                        trace['legendgroup'] = side_options['legendgroup']\n",
    "                    \n",
    "                    # If side contains 'right', assign to yaxis2\n",
    "                    trace['yaxis'] = 'y2' if 'right' in side and left_data_exists else 'y1'\n",
    "\n",
    "                    # Update global min and max\n",
    "                    y_values = trace['y']\n",
    "                    if not y_values.empty:\n",
    "                        max_val = max(y_values)\n",
    "                        min_val = min(y_values)\n",
    "                        global_max[side_base] = max(global_max[side_base], max_val)\n",
    "                        global_min[side_base] = min(global_min[side_base], min_val)\n",
    "\n",
    "                    fig.add_trace(go.Scatter(**trace))\n",
    "\n",
    "    # Figure Update Layout\n",
    "    fig.update_layout(\n",
    "        template='plotly_white',\n",
    "        title_text=f'{ticker} ({company}) {data.get(\"title\", [\"\", \"\", \"\"])[0]}',\n",
    "\n",
    "        xaxis_title='Data',\n",
    "        yaxis_title=data.get('title', [\"\", \"\", \"\"])[1],\n",
    "        yaxis2={'title': data.get('title', [\"\", \"\", \"\"])[2], 'overlaying': 'y', 'side': 'right'} if left_data_exists and right_data_exists else {},\n",
    "\n",
    "        legend=dict(\n",
    "            orientation='h',\n",
    "            font_size=10,\n",
    "        ),\n",
    "        width=6.27 * 200,  # converting inches to 96 pixels for width\n",
    "        height=3.52 * 200,  # converting inches to 96 pixels for height\n",
    "    )\n",
    "    \n",
    "    # Applying the flexible_range logic. Note: The logic is NOT applied if flexible_range is True. If it's False, it IS applied.\n",
    "    update_axis_bounds(fig, 'left', global_max['left'], global_min['left'], options, default_settings)\n",
    "    update_axis_bounds(fig, 'right', global_max['right'], global_min['right'], options, default_settings)\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = '13.09.02 - Outros Ativos Não Circulantes de Longo Prazo por Faturamento'\n",
    "data = {\n",
    "    'title': [f'{item} - {plot}', 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': [item], \n",
    "    'right': [cagr(item, years), ofs(item, years)], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, 'mma': [years, 2], },\n",
    "    'right': {'shape': 'ine', 'mode': 'standalone', 'normalization': False, 'outliers': False, }, \n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company][item][plot] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dual_axis(df, data):\n",
    "    '''\n",
    "    data: Dicionário contendo chaves 'left' e 'right', com as colunas correspondentes.\n",
    "               Exemplo: {'left': [col1, col2], 'right': [col3, col4]}\n",
    "    df: DataFrame contendo os dados.\n",
    "    '''\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "    # Determine y-axis ranges\n",
    "    factor = 1.50\n",
    "    left_min = df[data['left']].min().min() if df[data['left']].min().min() < 0 else df[data['left']].min().min() * -1\n",
    "    left_min *= factor\n",
    "    left_max_abs = max(abs(df[data['left']].min().min()), abs(df[data['left']].max().max())) * factor\n",
    "\n",
    "    right_min = df[data['right']].min().min() if df[data['right']].min().min() < 0 else df[data['right']].min().min() * -1\n",
    "    right_min *= factor\n",
    "    right_max_abs = max(abs(df[data['right']].min().min()), abs(df[data['right']].max().max())) * factor\n",
    "\n",
    "    # Find the zero alignment factor\n",
    "    zero_factor = abs(left_min) / left_max_abs\n",
    "\n",
    "    # Adjust the right y-axis ranges to align the zeros\n",
    "    right_min_adj = -right_max_abs * zero_factor\n",
    "    right_max_adj = right_max_abs * (1 - zero_factor)\n",
    "\n",
    "    # Adicione os dados do eixo esquerdo\n",
    "    for column in data['right']:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=df.index, y=df[column], mode='lines', name=column.split(' - ')[1]),\n",
    "            secondary_y=True\n",
    "        )\n",
    "\n",
    "    # Adicione os dados do eixo direito\n",
    "    fill_mode = 'tozeroy'\n",
    "    for column in data['left']:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=df.index, y=df[column], fill=fill_mode, name=column.split(' - ')[1]),\n",
    "            secondary_y=False\n",
    "        )\n",
    "        fill_mode = 'tonexty'\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text=f'{company} - {data[\"title\"][0]}',\n",
    "        xaxis_title='Data',\n",
    "        yaxis_title=data['title'][1],\n",
    "        yaxis2_title=data['title'][2],\n",
    "        yaxis_range=[left_min, left_max_abs],\n",
    "        yaxis2_range=[right_min_adj, right_max_adj]\n",
    "    )\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stacked_area(df, data):\n",
    "    '''\n",
    "    df: DataFrame containing the data.\n",
    "    data: Dictionary containing the columns to be plotted.\n",
    "    '''\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Helper function to get data from column name or series\n",
    "    def get_data(item):\n",
    "        if isinstance(item, str):\n",
    "            return df[item]\n",
    "        return item\n",
    "\n",
    "    # For 'left' data\n",
    "    for item in data['left']:\n",
    "        data_values = get_data(item)\n",
    "        name = item.split(' - ')[1] if isinstance(item, str) else item.name\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df.index,\n",
    "                y=data_values,\n",
    "                name=name,\n",
    "                fill='tonexty', \n",
    "                stackgroup='left',\n",
    "                # legendgroup='left',\n",
    "                showlegend=True\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # For 'right' data\n",
    "    for item in data['right']:\n",
    "        data_values = get_data(item)\n",
    "        name = item.split(' - ')[1] if isinstance(item, str) else item.name\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df.index,\n",
    "                y=data_values,\n",
    "                name=name,\n",
    "                fill='tonexty', \n",
    "                stackgroup='right',\n",
    "                # legendgroup='right',\n",
    "                showlegend=True,\n",
    "                yaxis='y2'\n",
    "            )\n",
    "        )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text=f'{company} - {data[\"title\"][0]}',\n",
    "        xaxis_title='Data',\n",
    "        yaxis_title=data['title'][1],\n",
    "        yaxis2=dict(title=data['title'][2], overlaying='y', side='right')\n",
    "    )\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_100_stacked_area(df, data):\n",
    "    '''\n",
    "    df: DataFrame containing the data.\n",
    "    data: Dictionary containing the columns to be plotted.\n",
    "    '''\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Helper function to get data from column name or series\n",
    "    def get_data(item):\n",
    "        if isinstance(item, str):\n",
    "            return df[item]\n",
    "        return item\n",
    "\n",
    "    # Function to normalize data\n",
    "    def normalize_data(columns):\n",
    "        temp_df = df[columns].copy()\n",
    "        temp_df['total'] = temp_df.sum(axis=1)\n",
    "        for column in columns:\n",
    "            temp_df[column] = temp_df.apply(lambda row: row[column] / row['total'] * 100 if row['total'] != 0 else 0, axis=1)\n",
    "        return temp_df\n",
    "\n",
    "    left_normalized = normalize_data(data['left'])\n",
    "    right_normalized = normalize_data(data['right'])\n",
    "\n",
    "    # Plot 'left' data\n",
    "    for column in data['left']:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df.index,\n",
    "                y=left_normalized[column],\n",
    "                name=column.split(' - ')[1],\n",
    "                fill='tonexty',\n",
    "                stackgroup='left',\n",
    "                legendgroup='left',\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Plot 'right' data on secondary y-axis\n",
    "    for column in data['right']:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df.index,\n",
    "                y=right_normalized[column],\n",
    "                name=column.split(' - ')[1],\n",
    "                fill='tonexty',\n",
    "                stackgroup='right',\n",
    "                legendgroup='right',\n",
    "                yaxis='y2'\n",
    "            )\n",
    "        )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text=f'{company} - {data[\"title\"][0]}',\n",
    "        xaxis_title='Data',\n",
    "        yaxis_title=data['title'][1],\n",
    "        yaxis2=dict(title=data['title'][2], overlaying='y', side='right')\n",
    "    )\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lines(df, data):\n",
    "    '''\n",
    "    data: Dicionário contendo chaves 'left' e 'title'.\n",
    "               Exemplo: {'left': [col1, col2], 'title': 'Equity Multiplier'}\n",
    "    df: DataFrame contendo os dados.\n",
    "    '''\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Adicione os dados do eixo esquerdo\n",
    "    for column in data['left']:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=df.index, y=df[column], fill='none', name=column.split(' - ')[1])\n",
    "        )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text=f'{company} - {data[\"title\"][0]}',\n",
    "        xaxis_title='Data',\n",
    "        yaxis_title=data['title'][1],\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_basics(df, col, window):\n",
    "    figs = {}\n",
    "    if df[col].sum() != 0:\n",
    "\n",
    "        year_average = df[col].rolling(window=365).mean()\n",
    "\n",
    "        # Calculate rolling mean and standard deviation\n",
    "        rolling_average = df[col].rolling(window=window).mean()\n",
    "        rolling_std = df[col].rolling(window=window).std()\n",
    "\n",
    "        # Create a single line plot\n",
    "        title = f'A - Linha do Tempo'\n",
    "        fig_line = px.line(df, x=df.index, y=col, title=f'{company} - {col} - {title}',\n",
    "                            labels={'value': 'Valor (R$)', 'variable': f'{title}'})\n",
    "        fig_line.add_scatter(x=df.index, y=year_average, mode='lines', line=dict(color='blue'), name='Média Anual')\n",
    "        figs[title] = fig_line\n",
    "        # fig_line.show()\n",
    "\n",
    "        # Create a moving average plot with ±2 standard deviations\n",
    "        title = f'B - Média Móvel e ±2 Desvios Padrão'\n",
    "        fig_mma_std = px.area(df, x=df.index, y=col, title=f'{company} - {col} - {title}',\n",
    "                            labels={'value': 'Valor (R$)', 'variable': f'{title}'})\n",
    "        fig_mma_std.add_scatter(x=df.index, y=year_average, mode='lines', line=dict(color='blue'), name='Média Anual')\n",
    "        fig_mma_std.add_scatter(x=df.index, y=rolling_average, mode='lines', line=dict(color='green'), name='Média Móvel')\n",
    "        fig_mma_std.add_scatter(x=df.index, y=rolling_average + 2 * rolling_std, mode='lines', line=dict(color='green', dash='dash'), name='Média Móvel + 2 Desvios Padrão')\n",
    "        fig_mma_std.add_scatter(x=df.index, y=rolling_average - 2 * rolling_std, mode='lines', line=dict(color='green', dash='dash'), name='Média Móvel - 2 Desvios Padrão')\n",
    "        figs[title] = fig_mma_std\n",
    "        # fig_mma_std.show()\n",
    "\n",
    "    sub_cols = [c for c in df.columns if c.startswith(col.split(' - ')[0] + '.') and c.count('.') == col.count('.') + 1]\n",
    "    if sub_cols:\n",
    "        # Create a multi line plot\n",
    "        title =  f'C - Distribuição Individual'\n",
    "        fig_multiline = px.line(df, x=df.index, y=sub_cols, title=f'{company} - {col} - {title}',\n",
    "                            labels={'value': 'Valor (R$)', 'variable': f'{title}'})\n",
    "        figs[title] = fig_multiline\n",
    "        # fig_area.show()\n",
    "\n",
    "        # Create a cumulative distribution plot\n",
    "        title =  f'D - Distribuição Acumulada'\n",
    "        fig_area = px.area(df, x=df.index, y=sub_cols, title=f'{company} - {col} - {title}',\n",
    "                            labels={'value': 'Valor (R$)', 'variable': f'{title}'})\n",
    "        figs[title] = fig_area\n",
    "        # fig_area.show()\n",
    "\n",
    "        # Create a proportional distribution plot\n",
    "        title = f'E - Distribuição Proporcional'\n",
    "        fig_area_100_stacked = px.area(df, x=df.index, y=sub_cols, title=f'{company} - {col} - {title}',\n",
    "                            labels={'value': 'Porcentagem (%)', 'variable': f'{title}'},\n",
    "                            groupnorm='percent')\n",
    "        figs[title] = fig_area_100_stacked\n",
    "        # fig_area_100_stacked.show()\n",
    "\n",
    "    return figs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_figs(figs, base_dir='./company/'):\n",
    "    \"\"\"\n",
    "    Save figures to the specified directory.\n",
    "\n",
    "    Parameters:\n",
    "    - col_figs: Dictionary of figures to save\n",
    "    - col: Column for which figures were generated\n",
    "    - company: Company for which figures were generated\n",
    "    - base_dir: Base directory where the figures will be saved\n",
    "    \"\"\"\n",
    "    for company, col in figs.items():\n",
    "        path = os.path.join(base_dir, company)\n",
    "        \n",
    "        # Create company directory if it doesn't exist\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "        for col, plots in col.items():\n",
    "            for title, plot in plots.items():\n",
    "                try:\n",
    "                    file_name = f'{company} - {col} - {title}.png'\n",
    "                    file_path = os.path.join(path, file_name)\n",
    "                    plot.write_image(file_path)\n",
    "                    # plot.show()\n",
    "                    print(file_name)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "    return figs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = 3\n",
    "figs = {}\n",
    "figs[company] = {}\n",
    "df = df_ticker[0]\n",
    "for item in df.columns:\n",
    "    figs[company][item] = {}\n",
    "    print(item)\n",
    "    try:\n",
    "        if df[item].sum() != 0:\n",
    "            plot = 'Valores, Média, CAGR e OFS'\n",
    "            data = {\n",
    "                'title': [f'{item} - {plot}', 'Reais (R$)', 'Porcentagem (%)'], \n",
    "                'left': [item], \n",
    "                'right': [cagr(item, years), ofs(item, years)], \n",
    "            }\n",
    "            options = {\n",
    "                'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, 'mma': [years, 2], },\n",
    "                'right': {'shape': 'ine', 'mode': 'standalone', 'normalization': False, 'outliers': False, }, \n",
    "            }\n",
    "            fig = plot_tweak(df_ticker[0], data, options)\n",
    "            figs[company][item][plot] = fig\n",
    "            # fig.show()\n",
    "\n",
    "            sub_cols = [column for column in df.columns if column.startswith(item.split(' - ')[0] + '.') and column.count('.') == item.count('.') + 1]\n",
    "            if sub_cols:\n",
    "                plot = 'Composição Cumulativa'\n",
    "                data = {\n",
    "                    'title': [f'{item} - {plot}', 'Reais (R$)', 'Porcentagem (%)'], \n",
    "                    'left': sub_cols, \n",
    "                    'right': [], \n",
    "                }\n",
    "                options = {\n",
    "                    'left': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, },\n",
    "                    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, }, \n",
    "                }\n",
    "                fig = plot_tweak(df_ticker[0], data, options)\n",
    "                figs[company][item][plot] = fig\n",
    "                # fig.show()\n",
    "\n",
    "                plot = 'Composição Individual'\n",
    "                data = {\n",
    "                    'title': [f'{item} - {plot}', 'Reais (R$)', 'Porcentagem (%)'], \n",
    "                    'left': sub_cols, \n",
    "                    'right': [], \n",
    "                }\n",
    "                options = {\n",
    "                    'left': {'shape': 'line', 'mode': 'standalone', 'normalization': False, },\n",
    "                    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, }, \n",
    "                }\n",
    "                fig = plot_tweak(df_ticker[0], data, options)\n",
    "                figs[company][item][plot] = fig\n",
    "                # fig.show()\n",
    "\n",
    "                plot = 'Composição Relativa'\n",
    "                data = {\n",
    "                    'title': [f'{item} - {plot}', 'Reais (R$)', 'Porcentagem (%)'], \n",
    "                    'left': sub_cols, \n",
    "                    'right': [], \n",
    "                }\n",
    "                options = {\n",
    "                    'left': {'shape': 'line', 'mode': 'standalone', 'normalization': True, },\n",
    "                    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, }, \n",
    "                }\n",
    "                fig = plot_tweak(df_ticker[0], data, options)\n",
    "                figs[company][item][plot] = fig\n",
    "                # fig.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Equity Multiplier'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['01 - Ativo Total', '02.03 - Patrimônio Líquido'], \n",
    "    'right': [ '11.03.01 - Equity Multiplier (Ativos por Patrimônio Líquido)',], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'cumulative', 'normalization': True, 'range': 'flexible', },\n",
    "    'right': {'shape': 'ine', 'mode': 'standalone', 'normalization': False, }, \n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Proporção dos Ativos'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': [ '11.01.03 - Ativos Circulantes de Curto Prazo por Ativos', '11.01.04 - Ativos Não Circulantes de Longo Prazo por Ativos',], \n",
    "    'right': [], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'cumulative', 'normalization': True, 'range': 'flexible', },\n",
    "    'right': {'shape': 'ine', 'mode': 'standalone', 'normalization': True, }, \n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Proporção dos Passivos'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': [ '11.02.01 - Passivos Circulantes de Curto Prazo por Ativos', '11.02.02 - Passivos Não Circulantes de Longo Prazo por Ativos', '11.03 - Patrimônio Líquido por Ativos'], \n",
    "    'right': [], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'cumulative', 'normalization': True, 'range': 'flexible', },\n",
    "    'right': {'shape': 'ine', 'mode': 'standalone', 'normalization': False, }, \n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Passivos por Patrimônio Líquido'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': [ '11.03.02.01 - Passivos Circulantes de Curto Prazo por Patrimônio Líquido',  '11.03.02.02 - Passivos Não Circulantes de Longo Prazo por Patrimônio Líquido',], \n",
    "    'right': [], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'cumulative', 'normalization': True, 'range': 'flexible', },\n",
    "    'right': {'shape': 'ine', 'mode': 'standalone', 'normalization': False, 'outliers': True, }, \n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Ativos e Liquidez'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['01.01 - Ativo Circulante de Curto Prazo', '02.01 - Passivo Circulante de Curto Prazo'], \n",
    "    'right': ['11.01.02 - Liquidez (Ativos Circulantes por Passivos Circulantes)', ], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, },\n",
    "    'right': {'shape': 'ine', 'mode': 'standalone', 'normalization': False, 'mma': [3,2]}, \n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Ativos e Prazos'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': [df['01.01 - Ativo Circulante de Curto Prazo'], df['01.02 - Ativo Não Circulante de Longo Prazo']], \n",
    "    'right': ['11.01.03 - Ativos Circulantes de Curto Prazo por Ativos', '11.01.04 - Ativos Não Circulantes de Longo Prazo por Ativos', ], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': True, },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Capital de Giro'\n",
    "trace = (df['01.02 - Ativo Não Circulante de Longo Prazo']/df['02.02 - Passivo Não Circulante de Longo Prazo'])\n",
    "trace.name = 'Liquide de Longo Prazo (Ativos Não Circulantes por Passivos Não Circulantes)'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['11.01.02 - Liquidez (Ativos Circulantes por Passivos Circulantes)', trace], \n",
    "    'right': ['11.01.01 - Capital de Giro (Ativos Circulantes - Passivos Circulantes)'], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'range': 'flexible', },\n",
    "    'right': {'shape': 'area', 'mode': 'standalone', 'normalization': False, 'range': 'flexible', },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Contas a Receber e Faturamento'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['01.01.03 - Contas a Receber', '01.02.01.03 - Contas a Receber'], \n",
    "    'right': ['13.03 - Contas por Faturamento'], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'line', 'mode': 'standalone', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3,2], },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Estoques e Faturamento'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['01.01.04 - Estoques', '01.02.01.04 - Estoques'], \n",
    "    'right': ['13.04 - Estoques por Faturamento'], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, 'range': 'flexible', },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3,2], 'range': 'flexible', },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Ativos Biológicos e Faturamento'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['01.01.05 - Ativos Biológicos', '01.02.01.05 - Ativos Biológicos'], \n",
    "    'right': ['13.05 - Ativos Biológicos por Faturamento'], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3,2]},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Despesas e Faturamento'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['01.01.07 - Despesas', '01.02.01.07 - Despesas'], \n",
    "    'right': ['13.07 - Despesas por Faturamento'], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3,2]},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Tributos e Faturamento'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['01.01.06 - Tributos', '01.02.01.06 - Tributos'], \n",
    "    'right': ['13.06 - Tributos por Faturamento'], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3,2]},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Capex Ativos Imobilizados e Intangíveis'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['01.02.03 - Imobilizados', '01.02.04 - Intangível', '01.02.02 - Investimentos Não Capex'], \n",
    "    'right': ['01.02.03 - Imobilizados', '01.02.04 - Intangível', '01.02.02 - Investimentos Não Capex'], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': True, },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Imobilização do Patrimônio'\n",
    "trace = (df['11.03.04 - Patrimônio Imobilizado']/df['02.03 - Patrimônio Líquido'])\n",
    "trace.name = 'Patrimônio Imobilizado por Patrimônio Líquido'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['11.03.04 - Patrimônio Imobilizado', '02.03 - Patrimônio Líquido'], \n",
    "    'right': [trace], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'cumulative', 'normalization': False, 'mma': [3,2]},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Prazo da Dívida'\n",
    "trace = df['12.01.02.01 - Dívida Bruta Circulante de Curto Prazo']/df['12.01.02 - Dívida Bruta']\n",
    "trace.name = 'Dívida de Curto Prazo por Dívida '\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['12.01.02.01 - Dívida Bruta Circulante de Curto Prazo', '12.01.02.02 - Dívida Bruta Não Circulante de Longo Prazo Prazo'], \n",
    "    'right': [trace], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False,'mma': [3,2]},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Jurisdição da Dívida'\n",
    "trace = df['12.01.02.03 - Dívida Bruta em Moeda Nacional']/(df['12.01.02.03 - Dívida Bruta em Moeda Nacional']+df['12.01.02.04 - Dívida Bruta em Moeda Estrangeira'])\n",
    "trace.name = 'Nacionalização da Dívida'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['12.01.02.03 - Dívida Bruta em Moeda Nacional', '12.01.02.04 - Dívida Bruta em Moeda Estrangeira'], \n",
    "    'right': [trace], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False,'mma': [3,2], },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Dívida de Curto Prazo por Ativo de Curto Prazo'\n",
    "trace = df['12.01.02.01 - Dívida Bruta Circulante de Curto Prazo']/df['01.01 - Ativo Circulante de Curto Prazo']\n",
    "trace.name = 'Dívida de Curto Prazo por Ativo de Curto Prazo'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['02.01.04.01.01 - Empréstimos e Financiamentos em Moeda Nacional', '02.01.04.01.02 - Empréstimos e Financiamentos em Moeda Estrangeira', '02.01.04.02 - Debêntures', '02.01.04.03 - Arrendamentos', '02.01.04.09 - Outros empréstimos, financiamentos e debêntures', ], \n",
    "    'left_01': ['01.01 - Ativo Circulante de Curto Prazo'], \n",
    "    'right': [trace], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, },\n",
    "    'left_01': {'shape': 'line', 'mode': 'standalone', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2]},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Dívida de Longo Prazo por Ativo de Longo Prazo'\n",
    "trace = df['12.01.02.02 - Dívida Bruta Não Circulante de Longo Prazo Prazo']/df['01.02 - Ativo Não Circulante de Longo Prazo']\n",
    "trace.name = 'Dívida de Longo Prazo por Ativo de Longo Prazo'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['02.02.01.01.01 - Empréstimos e Financiamentos em Moeda Nacional', '02.02.01.01.02 - Empréstimos e Financiamentos em Moeda Estrangeira', '02.02.01.02 - Debêntures', '02.02.01.03 - Arrendamentos', '02.02.02.09 - Outros empréstimos, financiamentos e debêntures', ], \n",
    "    'left_01': ['01.02 - Ativo Não Circulante de Longo Prazo'], \n",
    "    'right': [trace], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, 'range': 'flexible'},\n",
    "    'left_01': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'range': 'flexible'},\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], 'range': 'flexible'},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Dívida por Patrimônio Líquido'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['12.01.02.01 - Dívida Bruta Circulante de Curto Prazo', '12.01.02.02 - Dívida Bruta Não Circulante de Longo Prazo Prazo', ], \n",
    "    'left_01': ['02.03 - Patrimônio Líquido'], \n",
    "    'right': ['12.02.01 - Dívida Bruta por Patrimônio Líquido'], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, },\n",
    "    'left_01': {'shape': 'line', 'mode': 'standalone', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3,2], },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Dívida Líquida'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': [df['12.01.02 - Dívida Bruta'], ], \n",
    "    'left_01': [df['01.01.01 - Caixa e Disponibilidades de Caixa']*-1], \n",
    "    'left_02': [df['12.01.03 - Dívida Líquida']], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, 'range': 'flexible'},\n",
    "    'left_01': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, 'range': 'flexible'},\n",
    "    'left_02': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'range': 'flexible'},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Dívida Líquida por EBITDA'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': [df['12.04.01 - Dívida Líquida por EBITDA']*-1, ], \n",
    "    'left_01': ['12.02.01 - Dívida Bruta por Patrimônio Líquido'],\n",
    "    'right': ['12.01.02 - Dívida Bruta', '02.03 - Patrimônio Líquido'], \n",
    "    # 'right': [ofs('12.04.01 - Dívida Líquida por EBITDA', 3), ]\n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'line', 'mode': 'cumulative', 'normalization': False, 'range': 'half'},\n",
    "    'left_01': {'shape': 'line', 'mode': 'cumulative', 'normalization': False, 'range': 'half'},\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'outliers': False, 'range': 'flexible'},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Endividamento Financeiro'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': [df['02.03 - Patrimônio Líquido'], df['12.01.02 - Dívida Bruta'], ], \n",
    "    'right': ['12.02.02 - Endividamento Financeiro'], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'cumulative', 'normalization': False, 'mma': [3, 2]},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Serviço da Dívida'\n",
    "trace = df['12.01.03 - Dívida Líquida']/df['03.11 - Lucro Líquido']\n",
    "trace.name = 'Serviço da Dívida'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['12.01.03 - Dívida Líquida', '03.11 - Lucro Líquido'], \n",
    "    'right': [trace], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Índice de Cobertura'\n",
    "trace = df['07.08.03.01 - Juros Pagos']/df['03.05 - LAJIR EBIT Resultado Antes do Resultado Financeiro e dos Tributos']\n",
    "trace.name = 'Juros por EBIT'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['07.08.03.01 - Juros Pagos', '03.05 - LAJIR EBIT Resultado Antes do Resultado Financeiro e dos Tributos', ], \n",
    "    'right': [trace], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Composição do Patrimônio Líquido'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['02.03.01 - Capital Social', '02.03.02 - Reservas de Capital', '02.03.03 - Reservas de Reavaliação', '02.03.04 - Reservas de Lucros', '02.03.05 - Lucros ou Prejuízos Acumulados', '02.03.06 - Ajustes de Avaliação Patrimonial', '02.03.07 - Ajustes Acumulados de Conversão', '02.03.08 - Outros Resultados Abrangentes', ], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, 'range': 'flexible', },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Composição do Patrimônio Líquido'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['02.03.01 - Capital Social', '02.03.02 - Reservas de Capital', '02.03.03 - Reservas de Reavaliação', '02.03.04 - Reservas de Lucros', '02.03.05 - Lucros ou Prejuízos Acumulados', '02.03.06 - Ajustes de Avaliação Patrimonial', '02.03.07 - Ajustes Acumulados de Conversão', '02.03.08 - Outros Resultados Abrangentes', ], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'line', 'mode': 'standalone', 'normalization': False, },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Margem Bruta'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left_1': [df['03.02 - Custo de Produção']*-1, df['03.03 - Resultado Bruto (Receita Líquida)'], ], \n",
    "    'right': [df['16.01 - Margem Bruta (Resultado Bruto (Receita Líquida) por Receita Bruto)'] * 100, ]\n",
    "}\n",
    "options = {\n",
    "    'left_1': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Margem Operacional'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left_1': [df['03.01 - Receita Bruta'], df['03.04 - Despesas Operacionais']*-1, ], \n",
    "    'right': [df['16.02 - Margem Operacional (Receitas Operacionais por Receita Bruta)'] * -100,]\n",
    "}\n",
    "options = {\n",
    "    'left_1': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, 'range': 'flexible', },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Margem EBIT'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left_1': [df['03.04 - Despesas Operacionais']*-1, df['03.05 - LAJIR EBIT Resultado Antes do Resultado Financeiro e dos Tributos'], ], \n",
    "    'right': [df['16.03.01 - Margem EBIT (EBIT por Resultado Bruto (Receita Líquida)'] * 100,]\n",
    "}\n",
    "options = {\n",
    "    'left_1': {'shape': 'area', 'mode': 'cumulative', 'normalization': False,},\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], 'range': 'flexible', },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Margem de Depreciação'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left_1': [df['03.01 - Receita Bruta'], df['07.04.01 - Depreciação e Amortização'] * -1, ], \n",
    "    'right': [df['16.03.02 - Margem de Depreciação por Resultado Bruto (Receita Líquida)'] * -100,]\n",
    "}\n",
    "options = {\n",
    "    'left_1': {'shape': 'area', 'mode': 'cumulative', 'normalization': False,},\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], 'range': 'flexible', },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Margem EBITDA'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left_1': [df['03.05 - LAJIR EBIT Resultado Antes do Resultado Financeiro e dos Tributos'], df['13.01 - LAJIDA EBITDA Resultado Antes do Resultado Financeiro e dos Tributos mais Depreciação e Amortização'], df['07.04.01 - Depreciação e Amortização'] * -1], \n",
    "    'right': [df['16.03 - Margem EBITDA (EBITDA por Resultado Bruto (Receita Líquida)'] * 100, df['16.03.02 - Margem de Depreciação por Resultado Bruto (Receita Líquida)'] * 100, ]\n",
    "}\n",
    "options = {\n",
    "    'left_1': {'shape': 'area', 'mode': 'cumulative', 'normalization': False,},\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], 'range': 'flexible', },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Resultado Financeiro'\n",
    "trace = df['03.06 - Resultado Financeiro (Não Operacional)']/df['03.05 - LAJIR EBIT Resultado Antes do Resultado Financeiro e dos Tributos']\n",
    "trace.name = 'Margem Financeira'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left_1': [df['03.05 - LAJIR EBIT Resultado Antes do Resultado Financeiro e dos Tributos'], df['03.06 - Resultado Financeiro (Não Operacional)']], \n",
    "    'right': [trace * 100, ]\n",
    "}\n",
    "options = {\n",
    "    'left_1': {'shape': 'area', 'mode': 'cumulative', 'normalization': False,},\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], 'range': 'flexible', },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Margem Líquida'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': [df['03.01 - Receita Bruta']], \n",
    "    'left_1': [df['03.02 - Custo de Produção'] * -1, df['03.04 - Despesas Operacionais'] * -1, df['03.06 - Resultado Financeiro (Não Operacional)'], df['03.08 - Impostos IRPJ e CSLL'] * -1, df['03.11 - Lucro Líquido']], \n",
    "    'right': [df['16.05 - Margem Líquida (Lucro Líquido por Receita Bruta)'] * 100, ]\n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'line', 'mode': 'standalone', 'normalization': False,'range': 'flexible', },\n",
    "    'left_1': {'shape': 'area', 'mode': 'cumulative', 'normalization': False,'range': 'flexible', },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], 'range': 'half', },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Resultado e Margem Líquida'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': [df['03.01 - Receita Bruta']], \n",
    "    'left_1': [df['03.11 - Lucro Líquido']], \n",
    "    'right': [df['16.05 - Margem Líquida (Lucro Líquido por Receita Bruta)'] * 100, ]\n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'line', 'mode': 'standalone', 'normalization': False,'range': 'flexible', },\n",
    "    'left_1': {'shape': 'area', 'mode': 'cumulative', 'normalization': False,'range': 'flexible', },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], 'range': 'half', },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Patrimônio e Resultado (ROE)'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': [df['02.03 - Patrimônio Líquido']], \n",
    "    'left_1': [df['03.11 - Lucro Líquido']], \n",
    "    'right': [df['14.04.01 - ROE (Resultado por Patrimônio)'] * 100, ]\n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, },\n",
    "    'left_1': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], 'range': 'flexible'},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Capital Investido e Resultado (ROIC)'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': [df['14.03 - Capital Investido']], \n",
    "    'left_1': [df['03.05 - LAJIR EBIT Resultado Antes do Resultado Financeiro e dos Tributos']], \n",
    "    'right': [df['14.03.01 - ROIC (Retorno por Capital Investido)'] * 100, ]\n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, },\n",
    "    'left_1': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], 'range': 'flexible'},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Ativos e Resultado (ROAS)'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': [df['01 - Ativo Total']], \n",
    "    'left_1': [df['03.05 - LAJIR EBIT Resultado Antes do Resultado Financeiro e dos Tributos']], \n",
    "    'right': [df['14.05.01 - ROAS (EBIT por Ativos)'], ]\n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, },\n",
    "    'left_1': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], 'range': 'flexible'},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Ativos e Resultado (Coeficiente de Retorno)'\n",
    "trace = df['03.11 - Lucro Líquido'] / df['01 - Ativo Total']\n",
    "trace.name = 'Coeficiente de Retorno'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': [df['01 - Ativo Total']], \n",
    "    'left_1': [df['03.11 - Lucro Líquido']], \n",
    "    'right': [trace * 100, ]\n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, },\n",
    "    'left_1': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], 'range': 'flexible'},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'ROE, ROIC, ROAS e Coeficiente de Retorno'\n",
    "trace = df['03.11 - Lucro Líquido'] / df['01 - Ativo Total']\n",
    "trace.name = 'Coeficiente de Retorno'\n",
    "data = {\n",
    "    'title': [title, 'Porcentagem (%)', 'Reais (R$)', ], \n",
    "    # 'left': [df['01 - Ativo Total']], \n",
    "    # 'left_1': [df['03.11 - Lucro Líquido']], \n",
    "    'right': [df['14.04.01 - ROE (Resultado por Patrimônio)'] * 100, df['14.03.01 - ROIC (Retorno por Capital Investido)'] * 100, df['14.05.01 - ROAS (EBIT por Ativos)'] * 100, trace * 100, ]\n",
    "}\n",
    "\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, 'range': 'half'},\n",
    "    'left_1': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'range': 'half'},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Price'\n",
    "if df.TICKER[0][-1] == '3':\n",
    "    acoes = df['00.01.01 - Ações ON']\n",
    "else:\n",
    "    acoes = df['00.02.01 - Ações PN']\n",
    "\n",
    "trace = df['Adj Close'] / df['00.01.01 - Ações ON']\n",
    "trace.name = 'Preço por Ação'\n",
    "data = {\n",
    "    'title': [title, 'Porcentagem (%)', 'Reais (R$)', ], \n",
    "    'left': [df['Adj Close']], \n",
    "    'left_1': [df['03.11 - Lucro Líquido']], \n",
    "    'left_2': [acoes], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'line', 'mode': 'standalone', 'normalization': True, 'range': 'flexible'},\n",
    "    'left_1': {'shape': 'line', 'mode': 'standalone', 'normalization': True, 'range': 'flexible'},\n",
    "    'left_2': {'shape': 'line', 'mode': 'standalone', 'normalization': True, 'range': 'flexible'},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs = save_figs(figs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
