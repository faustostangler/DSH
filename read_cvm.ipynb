{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import assets.helper as b3\n",
    "import assets.functions as run\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import os\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge Mix and Match all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    math = run.load_pkl(f'{b3.app_folder}math')\n",
    "except Exception as e:\n",
    "    math = run.get_math()\n",
    "    math = run.save_pkl(math, f'{b3.app_folder}math')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    setorial = run.load_pkl(f'{b3.app_folder}setorial')\n",
    "except Exception as e:\n",
    "    setorial = run.get_classificacao_setorial(setorial='')\n",
    "    setorial = run.save_pkl(setorial, f'{b3.app_folder}setorial')\n",
    "# setorial.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    b3_cvm = run.load_pkl(f'{b3.app_folder}b3_cvm')\n",
    "except Exception as e:\n",
    "    b3_cvm = run.b3_grab(b3.search_url)\n",
    "    b3_cvm = run.save_pkl(b3_cvm, f'{b3.app_folder}b3_cvm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETOR: O setor econômico mais amplo ao qual a empresa pertence.\n",
    "# SUBSETOR: Uma categorização mais específica dentro do setor mais amplo.\n",
    "# SEGMENTO: Uma classificação ainda mais granular do negócio da empresa.\n",
    "# DENOM_CIA: Esta é a denominação ou nome da empresa.\n",
    "# COMPANHIA: Nome ou denominação oficial da empresa listada.\n",
    "# PREGAO: Refere-se ao nome pelo qual a empresa é conhecida no pregão da bolsa de valores.\n",
    "# LISTAGEM: Categoria ou segmento de listagem da empresa na bolsa de valores, que pode indicar o nível de governança corporativa ou outros critérios.\n",
    "# TICK: Abreviação ou símbolo da empresa usada no mercado de ações.\n",
    "# TICKERS: Símbolos de negociação da empresa em diferentes mercados ou plataformas.\n",
    "# CD_CVM: Este poderia ser um código ou identificador único relacionado à empresa, possivelmente relacionado à Comissão de Valores Mobiliários do Brasil (CVM).\n",
    "# CVM: Código ou identificador relacionado à empresa na Comissão de Valores Mobiliários, o órgão regulador do mercado de capitais no Brasil.\n",
    "# ISIN: Número de Identificação Internacional de Valores Mobiliários – um identificador único para valores mobiliários.\n",
    "# CNPJ_CIA: Este é o número do Cadastro Nacional da Pessoa Jurídica (CNPJ) da empresa, um identificador único para empresas no Brasil.\n",
    "# CNPJ: Cadastro Nacional da Pessoa Jurídica – é o número de identificação das empresas brasileiras.\n",
    "# SITE: Site oficial ou página relevante da empresa.\n",
    "# ATIVIDADE: Descreve a principal atividade de negócios da empresa.\n",
    "\n",
    "# ANO: Este é o ano ao qual os dados se referem.\n",
    "# DT_REFER: Esta é a data de referência para a entrada de dados.\n",
    "# DT_FIM_EXERC: Esta é a data final para o exercício ou período de relato financeiro.\n",
    "# DT_INI_EXERC: Esta poderia ser a data inicial para o exercício ou período de relato financeiro.\n",
    "\n",
    "# AGRUPAMENTO: Isso descreve o nível de agregação dos dados. Por exemplo, 'con' pode indicar dados consolidados.\n",
    "# BALANCE_SHEET: Isso indica a seção específica da demonstração financeira, como Balanço Patrimonial ('BPA').\n",
    "# GRUPO_DFP: Isso representa o tipo de grupo de demonstração financeira. Por exemplo, 'DF Consolidado - Balanço Patrimonial Ativo' sugere que é um balanço patrimonial consolidado focado em ativos.\n",
    "# CD_CONTA: Este poderia ser um código ou identificador único relacionado a uma conta específica ou item de linha na demonstração financeira.\n",
    "# DS_CONTA: Descreve a conta específica ou item de linha na demonstração financeira, como 'Ativo Total'.\n",
    "\n",
    "# VL_CONTA: Representa o valor associado à conta específica ou item de linha.\n",
    "# MOEDA: Isso indica a moeda na qual os valores são representados. 'REAL' sugere Real Brasileiro.\n",
    "# ESCALA_MOEDA: Isso fornece a escala ou unidade para os valores monetários. 'MIL' pode indicar que os valores estão em milhares.\n",
    "\n",
    "# ST_CONTA_FIXA: Pode indicar o status ou tipo de conta. O significado de valores como 'S' dependeria do contexto dos dados.\n",
    "# COLUNA_DF: O propósito desta coluna não é imediatamente claro a partir da amostra. Pode representar algum tipo de classificação ou categorização relacionada aos dados financeiros.\n",
    "\n",
    "# ESCRITURADOR: Entidade ou empresa responsável por registrar ou gerenciar os valores mobiliários da empresa.\n",
    "# ACIONISTAS: Informações ou identificadores relacionados aos acionistas da empresa.\n",
    "\n",
    "# FILENAME: Este é o arquivo de onde os dados são originados. Ele fornece o nome do arquivo que contém a respectiva entrada de dados.\n",
    "# DEMONSTRATIVO: Este representa o tipo de demonstração financeira. Pode indicar se os dados são de um relatório intermediário (como 'itr') ou de outro tipo de relatório financeiro.\n",
    "# VERSAO: Isso pode representar a versão ou iteração dos dados/relatórios financeiros.\n",
    "\n",
    "columns = [\n",
    "    'SETOR_x',\n",
    "    'SUBSETOR_x',\n",
    "    'SEGMENTO_x',\n",
    "    'DENOM_CIA',\n",
    "        # 'COMPANHIA',\n",
    "    'PREGAO',\n",
    "    'LISTAGEM',\n",
    "    'TICK',\n",
    "    'TICKERS',\n",
    "    'CD_CVM',\n",
    "        # 'CVM',\n",
    "        # 'ISIN',\n",
    "    'CNPJ_CIA',\n",
    "        # 'CNPJ',\n",
    "    'SITE',\n",
    "    'ATIVIDADE',\n",
    "        # 'ANO',\n",
    "    'DT_REFER',\n",
    "        # 'DT_FIM_EXERC',\n",
    "        # 'DT_INI_EXERC',\n",
    "    'AGRUPAMENTO',\n",
    "    'BALANCE_SHEET',\n",
    "    # 'GRUPO_DFP',\n",
    "    'CD_CONTA',\n",
    "    'DS_CONTA',\n",
    "    'VL_CONTA',\n",
    "    # 'MOEDA',\n",
    "    # 'ESCALA_MOEDA',\n",
    "    # 'ST_CONTA_FIXA',\n",
    "    # 'COLUNA_DF',\n",
    "    'ESCRITURADOR',\n",
    "    'ACIONISTAS', \n",
    "    # 'FILENAME', \n",
    "    # 'DEMONSTRATIVO', \n",
    "    # 'VERSAO',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b3_cvm.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['FILENAME', 'DEMONSTRATIVO', 'BALANCE_SHEET', 'ANO', 'AGRUPAMENTO',\n",
    "       'CNPJ_CIA', 'DT_REFER', 'VERSAO', 'DENOM_CIA', 'CD_CVM', 'GRUPO_DFP',\n",
    "       'MOEDA', 'ESCALA_MOEDA', 'DT_FIM_EXERC', 'CD_CONTA', 'DS_CONTA',\n",
    "       'VL_CONTA', 'ST_CONTA_FIXA', 'DT_INI_EXERC', 'COLUNA_DF', 'COMPANHIA',\n",
    "       'PREGAO', 'TICK', 'LISTAGEM', 'TICKERS', 'ISIN', \n",
    "       'ATIVIDADE', 'SETOR', 'SUBSETOR', 'SEGMENTO', 'SITE', 'ESCRITURADOR',]\n",
    "df = b3_cvm['CONSUMO CICLICO'][columns].set_index('DT_REFER')\n",
    "df = convert_columns(df)\n",
    "df['DENOM_CIA'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acoes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acoes = run.load_pkl(f'{b3.app_folder}acoes')\n",
    "# Process the data and return the result\n",
    "acoes['Trimestre'] = pd.to_datetime(acoes['Trimestre'], errors='coerce', dayfirst=True)\n",
    "acoes['BALANCE_SHEET'] = 'STK'\n",
    "column_mapping = {\n",
    "    'Ações ON': '00.01.01',\n",
    "    'Ações PN': '00.02.01',\n",
    "    'Ações ON em Tesouraria': '00.01.02',\n",
    "    'Ações PN em Tesouraria': '00.02.02'\n",
    "}\n",
    "acoes = acoes.rename(columns={\"Companhia\": \"DENOM_CIA\", \"Trimestre\": \"DT_REFER\"})\n",
    "\n",
    "acoes = acoes.melt(id_vars=['DENOM_CIA', 'DT_REFER', 'BALANCE_SHEET'], \n",
    "                        value_vars=['Ações ON', 'Ações PN', 'Ações ON em Tesouraria', 'Ações PN em Tesouraria'],\n",
    "                        var_name='DS_CONTA', value_name='VL_CONTA').sort_values(by=['DENOM_CIA', 'DT_REFER', 'DS_CONTA'])\n",
    "\n",
    "acoes['CD_CONTA'] = acoes['DS_CONTA'].map(column_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intel_b3 = run.load_pkl(f'{b3.app_folder}intel_b3')\n",
    "df = intel_b3['BENS INDUSTRIAIS']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company = 'ARMAC LOCACAO LOGISTICA E SERVICOS SA'\n",
    "quarter = '2019-12-31'\n",
    "mc = acoes['DENOM_CIA'] == company\n",
    "mc &= acoes['DT_REFER'] == quarter\n",
    "acoesc = acoes[mc]\n",
    "\n",
    "mc = df['DENOM_CIA'] == company\n",
    "mc &= df['DT_REFER'] == quarter\n",
    "dfc = df[mc]\n",
    "\n",
    "df_ffill = pd.concat([dfc, acoesc], ignore_index=True).ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_stock_data(group):\n",
    "    company, quarter = group.name\n",
    "    \n",
    "    # Filter acoes based on company and quarter\n",
    "    mc = acoes['DENOM_CIA'] == company\n",
    "    mc &= acoes['DT_REFER'] == quarter\n",
    "    acoesc = acoes[mc]\n",
    "\n",
    "    # Concatenate and ffill\n",
    "    return pd.concat([group, acoesc], ignore_index=True).ffill()\n",
    "\n",
    "result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_ffill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intelacoes = {}\n",
    "for setor, df in intel_b3.items():\n",
    "    print(setor)\n",
    "    df_concat = pd.concat([df.set_index(['DENOM_CIA', 'DT_REFER']), acoes.set_index(['DENOM_CIA', 'DT_REFER'])], axis=0, sort=False).reset_index()\n",
    "    filled_df = df_concat.groupby(['DENOM_CIA', 'DT_REFER'], group_keys=False).apply(lambda group: group.ffill().bfill()).reset_index()\n",
    "    intelacoes[setor] = filled_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate them vertically\n",
    "df_concat = pd.concat([df.set_index(['DENOM_CIA', 'DT_REFER']), acoes.set_index(['DENOM_CIA', 'DT_REFER'])], axis=0, sort=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_df = df_concat.groupby(['DENOM_CIA', 'DT_REFER'], group_keys=False).apply(lambda group: group.ffill().bfill()).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = filled_df['DENOM_CIA'] == 'ARMAC LOCACAO LOGISTICA E SERVICOS SA'\n",
    "m &= filled_df['DT_REFER'] == '2019-12-31'\n",
    "m &= filled_df['BALANCE_SHEET'] == 'STK'\n",
    "\n",
    "filled_df[m][cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b3_cvm = run.load_pkl(f'{b3.app_folder}b3_cvm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_types = {'index': 'int',\n",
    " 'FILENAME': 'category',\n",
    " 'DEMONSTRATIVO': 'category',\n",
    " 'BALANCE_SHEET': 'category',\n",
    " 'ANO': 'category',\n",
    " 'AGRUPAMENTO': 'category',\n",
    " 'CNPJ_CIA': 'category',\n",
    " 'DT_REFER': 'object',\n",
    " 'VERSAO': 'category',\n",
    " 'DENOM_CIA': 'category',\n",
    " 'CD_CVM': 'category',\n",
    " 'GRUPO_DFP': 'category',\n",
    " 'MOEDA': 'category',\n",
    " 'ESCALA_MOEDA': 'category',\n",
    " 'DT_FIM_EXERC': 'object',\n",
    " 'CD_CONTA': 'category',\n",
    " 'DS_CONTA': 'category',\n",
    " 'VL_CONTA': 'float',\n",
    " 'ST_CONTA_FIXA': 'category',\n",
    " 'DT_INI_EXERC': 'object',\n",
    " 'COLUNA_DF': 'category',\n",
    " 'COMPANHIA': 'category',\n",
    " 'PREGAO': 'category',\n",
    " 'TICK': 'category',\n",
    " 'LISTAGEM': 'category',\n",
    " 'CVM': 'category',\n",
    " 'TICKERS': 'category',\n",
    " 'ISIN': 'category',\n",
    " 'CNPJ': 'category',\n",
    " 'ATIVIDADE': 'category',\n",
    " 'SETOR': 'category',\n",
    " 'SUBSETOR': 'category',\n",
    " 'SEGMENTO': 'category',\n",
    " 'SITE': 'category',\n",
    " 'ESCRITURADOR': 'category',\n",
    " 'CD_CONTA_original': 'category',\n",
    " 'DS_CONTA_original': 'category'}\n",
    "date_columns = ['DT_REFER', 'DT_FIM_EXERC', 'DT_INI_EXERC']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('BENS INDUSTRIAIS_intel.csv', dtype=column_types, index_col='Unnamed: 0', parse_dates=True)\n",
    "# df = pd.read_csv('COMUNICACOES_df.csv')\n",
    "# df_typed = pd.read_csv(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um dicionário onde as chaves são os nomes das colunas e os valores são os valores únicos para cada coluna\n",
    "col_dict = {col: df[col].unique().tolist() for col in df.columns}\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_dict['BALANCE_SHEET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['CNPJ_CIA', 'DENOM_CIA', 'DT_REFER', 'CD_CONTA', 'DS_CONTA', 'VL_CONTA', 'SETOR', 'SUBSETOR', 'SEGMENTO', 'DT_INI_EXERC', 'ATIVIDADE', 'SITE', 'ESCRITURADOR', 'FILENAME', 'DEMONSTRATIVO', 'BALANCE_SHEET', 'ANO', 'AGRUPAMENTO', 'VERSAO', 'GRUPO_DFP', 'MOEDA', 'ESCALA_MOEDA', 'ST_CONTA_FIXA', 'COLUNA_DF', 'COMPANHIA', 'TICKERS', 'CVM', 'ISIN', 'DT_FIM_EXERC', ]]\n",
    "# 'PREGAO', 'TICK', 'CD_CVM', 'LISTAGEM', # 'CD_CONTA_original', 'DS_CONTA_original', \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formulas_old = [\n",
    "    # Relações Entre Ativos e Passivos\n",
    "    ('_020302_reservas_de_capital', '_020303_reservas_de_reavaliacao', '_020304_reservas_de_lucros'),\n",
    "    # Dívida\n",
    "    ('_0201040101_emprestimos_e_financiamentos_em_moeda_nacional', '_0201040102_emprestimos_e_financiamentos_em_moeda_estrangeira', '_02010402_debentures', '_02010403_arrendamentos', '_02010409_outros_emprestimos_financiamentos_e_debentures'),\n",
    "    ('_0202010101_emprestimos_e_financiamentos_em_moeda_nacional', '_0202010102_emprestimos_e_financiamentos_em_moeda_estrangeira', '_02020102_debentures', '_02020103_arrendamentos', '_02020209_outros_emprestimos_financiamentos_e_debentures'),\n",
    "    ('_0201040102_emprestimos_e_financiamentos_em_moeda_estrangeira', '_0202010102_emprestimos_e_financiamentos_em_moeda_estrangeira'),\n",
    "    ('_010101_caixa_e_disponibilidades_de_caixa',),\n",
    "    ('_010202_investimentos_nao_capex', '_010203_imobilizados', '_010204_intangivel'),\n",
    "    ('_0305_lajir_ebit_resultado_antes_do_resultado_financeiro_e_dos_tributos', '_070401_depreciacao_e_amortizacao'),\n",
    "    # Resultados Fundamentalistas\n",
    "    ('_0203_patrimonio_liquido',),\n",
    "    ('_010101_caixa_e_disponibilidades_de_caixa',),\n",
    "    ('_070803_remuneracao_de_capital_de_terceiros', '_070804_remuneracao_de_capital_proprio'),\n",
    "    # Análise do Fluxo de Caixa\n",
    "    ('_0601_caixa_das_operacoes', '_0602_caixa_de_investimentos_capex'),\n",
    "    ('_0603_caixa_de_financiamento',),\n",
    "    ('_060201_investimentos', '_060202_imobilizado_e_intangivel'),\n",
    "]\n",
    "\n",
    "def de_transform_corrected(key):\n",
    "    # Strip the leading underscore and split at the first underscore\n",
    "    parts = key[1:].split('_', 1)\n",
    "\n",
    "    # Adjust code by inserting periods every two characters\n",
    "    code = '.'.join([parts[0][i:i+2] for i in range(0, len(parts[0]), 2)])\n",
    "    \n",
    "    # Adjust description capitalization\n",
    "    description = ' '.join([word.capitalize() if word not in ['e', 'de', 'do', 'dos', 'da', 'das', 'em'] else word.lower() for word in parts[1].split('_')])\n",
    "    \n",
    "    return code, description\n",
    "\n",
    "# De-transform the formulas using the corrected function\n",
    "formulas = []\n",
    "for group in formulas_old:\n",
    "    new_group = []\n",
    "    for key in group:\n",
    "        new_group.append(de_transform_corrected(key))\n",
    "    formulas.append(tuple(new_group))\n",
    "\n",
    "formulas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_sheet = df.groupby(['CNPJ_CIA', 'DT_REFER'], group_keys=True)\n",
    "balance_sheet.groups.keys()\n",
    "df_ = balance_sheet.get_group(('00.242.184/0001-04', '2019-12-31'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (, 'Emprestimos e Financiamentos em Moeda Estrangeira'),\n",
    "m = df['CD_CONTA'] == '07.08.04'\n",
    "df[m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dados Abertos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(file):\n",
    "    path = \"C:\\\\Users\\\\faust\\\\OneDrive\\\\Área de Trabalho\\\\dados abertos\\\\\"\n",
    "    df = pd.read_csv(path+file+\".csv\", sep=';', encoding='latin1')\n",
    "    return df.head(25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fca_cia_aberta_2010\"\n",
    "fca_cia_aberta_2010 = read(file)\n",
    "# link para o NSD do formulário cadastral\n",
    "fca_cia_aberta_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fca_cia_aberta_auditor_2010\"\n",
    "fca_cia_aberta_auditor_2010 = read(file)\n",
    "# informações dos auditores CNPJ e CPF, datas dos auditores CPF\n",
    "fca_cia_aberta_auditor_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fca_cia_aberta_canal_divulgacao_2010\"\n",
    "fca_cia_aberta_canal_divulgacao_2010 = read(file)\n",
    "# Onde as DRE são divulgadas\n",
    "fca_cia_aberta_canal_divulgacao_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fca_cia_aberta_departamento_acionistas_2010\"\n",
    "fca_cia_aberta_departamento_acionistas_2010 = read(file)\n",
    "# Endereços dos DRI\n",
    "fca_cia_aberta_departamento_acionistas_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fca_cia_aberta_dri_2010\"\n",
    "fca_cia_aberta_dri_2010 = read(file)\n",
    "# NOMES e endereços dos DRI\n",
    "fca_cia_aberta_dri_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fca_cia_aberta_endereco_2010\"\n",
    "fca_cia_aberta_endereco_2010 = read(file)\n",
    "# Endereço completo do DRI\n",
    "fca_cia_aberta_endereco_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fca_cia_aberta_geral_2010\"\n",
    "fca_cia_aberta_geral_2010 = read(file)\n",
    "# Cadastro CVM, Atividade, Descrição e Controle Acionário\n",
    "fca_cia_aberta_geral_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fca_cia_aberta_pais_estrangeiro_negociacao_2010\"\n",
    "fca_cia_aberta_pais_estrangeiro_negociacao_2010 = read(file)\n",
    "# País estrangeiro... ?\n",
    "fca_cia_aberta_pais_estrangeiro_negociacao_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fca_cia_aberta_valor_mobiliario_2010\"\n",
    "fca_cia_aberta_valor_mobiliario_2010 = read(file)\n",
    "# Valor mobiliário, Mercado e Segmento\n",
    "fca_cia_aberta_valor_mobiliario_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_2023\"\n",
    "fre_cia_aberta_2023 = read(file)\n",
    "# Link do Documento\n",
    "fre_cia_aberta_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_acao_entregue_2023\"\n",
    "fre_cia_aberta_acao_entregue_2023 = read(file)\n",
    "# Remuneração da Diretoria\n",
    "fre_cia_aberta_acao_entregue_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_administrador_declaracao_genero_2023\"\n",
    "fre_cia_aberta_administrador_declaracao_genero_2023 = read(file)\n",
    "# Gênero dos administradores\n",
    "fre_cia_aberta_administrador_declaracao_genero_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_administrador_declaracao_raca_2023\"\n",
    "fre_cia_aberta_administrador_declaracao_raca_2023 = read(file)\n",
    "# Raça dos administradores\n",
    "fre_cia_aberta_administrador_declaracao_raca_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_administrador_membro_conselho_fiscal_2023\"\n",
    "fre_cia_aberta_administrador_membro_conselho_fiscal_2023 = read(file)\n",
    "# Membros do Conselho Fiscal\n",
    "fre_cia_aberta_administrador_membro_conselho_fiscal_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_ativo_imobilizado_2023\"\n",
    "fre_cia_aberta_ativo_imobilizado_2023 = read(file)\n",
    "# Ativos e Propriedades por empresa\n",
    "fre_cia_aberta_ativo_imobilizado_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_ativo_intangivel_2023\"\n",
    "fre_cia_aberta_ativo_intangivel_2023 = read(file)\n",
    "# Ativos e Propriedades por empresa\n",
    "fre_cia_aberta_ativo_intangivel_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_auditor_2023\"\n",
    "fre_cia_aberta_auditor_2023 = read(file)\n",
    "# Remuneração por auditor\n",
    "fre_cia_aberta_auditor_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_auditor_responsavel_2023\"\n",
    "fre_cia_aberta_auditor_responsavel_2023 = read(file)\n",
    "# Endereço do Auditor\n",
    "fre_cia_aberta_auditor_responsavel_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_capital_social_2023\"\n",
    "fre_cia_aberta_capital_social_2023 = read(file)\n",
    "# Modificações no Capital Social e Ações\n",
    "fre_cia_aberta_capital_social_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_capital_social_aumento_2023\"\n",
    "fre_cia_aberta_capital_social_aumento_2023 = read(file)\n",
    "# Idem\n",
    "fre_cia_aberta_capital_social_aumento_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_capital_social_aumento_classe_acao_2023\"\n",
    "fre_cia_aberta_capital_social_aumento_classe_acao_2023 = read(file)\n",
    "# Em branco\n",
    "fre_cia_aberta_capital_social_aumento_classe_acao_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_capital_social_classe_acao_2023\"\n",
    "fre_cia_aberta_capital_social_classe_acao_2023 = read(file)\n",
    "# Preferencial Classe A, B e C\n",
    "fre_cia_aberta_capital_social_classe_acao_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_capital_social_desdobramento_2023\"\n",
    "fre_cia_aberta_capital_social_desdobramento_2023 = read(file)\n",
    "# Desdobramentos de Ações\n",
    "fre_cia_aberta_capital_social_desdobramento_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_capital_social_desdobramento_classe_acao_2023\"\n",
    "fre_cia_aberta_capital_social_desdobramento_classe_acao_2023 = read(file)\n",
    "# em branco\n",
    "fre_cia_aberta_capital_social_desdobramento_classe_acao_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_capital_social_reducao_2023\"\n",
    "fre_cia_aberta_capital_social_reducao_2023 = read(file)\n",
    "# Redução de capital\n",
    "fre_cia_aberta_capital_social_reducao_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_capital_social_titulo_conversivel_2023\"\n",
    "fre_cia_aberta_capital_social_titulo_conversivel_2023 = read(file)\n",
    "# Redução de capital\n",
    "fre_cia_aberta_capital_social_titulo_conversivel_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_direito_acao_2023\"\n",
    "fre_cia_aberta_direito_acao_2023 = read(file)\n",
    "# ?\n",
    "fre_cia_aberta_direito_acao_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_historico_emissor_2023\"\n",
    "fre_cia_aberta_historico_emissor_2023 = read(file)\n",
    "# Constituição do emissor e local\n",
    "fre_cia_aberta_historico_emissor_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_informacao_financeira_2023\"\n",
    "fre_cia_aberta_informacao_financeira_2023 = read(file)\n",
    "# DRE Resumido\n",
    "fre_cia_aberta_informacao_financeira_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_membro_comite_2023\"\n",
    "fre_cia_aberta_membro_comite_2023 = read(file)\n",
    "# CPF e Remuneração\n",
    "fre_cia_aberta_membro_comite_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_obrigacao_2023\"\n",
    "fre_cia_aberta_obrigacao_2023 = read(file)\n",
    "# Obrigações e Dívidas\n",
    "fre_cia_aberta_obrigacao_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_outro_valor_mobiliario_2023\"\n",
    "fre_cia_aberta_outro_valor_mobiliario_2023 = read(file)\n",
    "# ?\n",
    "fre_cia_aberta_outro_valor_mobiliario_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_participacao_sociedade_2023\"\n",
    "fre_cia_aberta_participacao_sociedade_2023 = read(file)\n",
    "# Participações em outras empresas\n",
    "fre_cia_aberta_participacao_sociedade_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_participacao_sociedade_valorizacao_acao_2023\"\n",
    "fre_cia_aberta_participacao_sociedade_valorizacao_acao_2023 = read(file)\n",
    "# ?\n",
    "fre_cia_aberta_participacao_sociedade_valorizacao_acao_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_posicao_acionaria_2023\"\n",
    "fre_cia_aberta_posicao_acionaria_2023 = read(file)\n",
    "# Composição acionária por acionista majoritário\n",
    "fre_cia_aberta_posicao_acionaria_2023[['CNPJ_Companhia', 'Data_Referencia', 'Versao', 'ID_Documento',\n",
    "       'ID_Acionista', 'Acionista', 'Tipo_Pessoa_Acionista',\n",
    "       'CPF_CNPJ_Acionista', 'ID_Acionista_Relacionado',\n",
    "       'Acionista_Relacionado', 'Tipo_Pessoa_Acionista_Relacionado',\n",
    "       'CPF_CNPJ_Acionista_Relacionado',\n",
    "       'Quantidade_Acao_Ordinaria_Circulacao',\n",
    "       'Percentual_Acao_Ordinaria_Circulacao',\n",
    "       'Quantidade_Acao_Preferencial_Circulacao',\n",
    "       'Percentual_Acao_Preferencial_Circulacao',\n",
    "       'Quantidade_Total_Acoes_Circulacao',\n",
    "       'Percentual_Total_Acoes_Circulacao', ]]\n",
    "# fre_cia_aberta_posicao_acionaria_2023.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_relacao_familiar_2023\"\n",
    "fre_cia_aberta_relacao_familiar_2023 = read(file)\n",
    "# Parentescos\n",
    "fre_cia_aberta_relacao_familiar_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_relacao_subordinacao_2023\"\n",
    "fre_cia_aberta_relacao_subordinacao_2023 = read(file)\n",
    "# Subordnicação \n",
    "fre_cia_aberta_relacao_subordinacao_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_transacao_parte_relacionada_2023\"\n",
    "fre_cia_aberta_transacao_parte_relacionada_2023 = read(file)\n",
    "# Partes relacionadas\n",
    "fre_cia_aberta_transacao_parte_relacionada_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_2023\"\n",
    "fre_cia_aberta_2023 = read(file)\n",
    "# Link do Documento\n",
    "fre_cia_aberta_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_group(cias_por_setor, window):\n",
    "    for company, group_df in cias_por_setor:\n",
    "        try:\n",
    "            # Calculate the moving average for the last 4 periods\n",
    "            group_df['MA'] = group_df['VL_CONTA'].rolling(window=window).mean()\n",
    "            \n",
    "            # Calculate the rolling sum for the last 4 periods\n",
    "            group_df['Rolling_Sum'] = group_df['VL_CONTA'].rolling(window=window).sum()\n",
    "            \n",
    "            # Calculate the lifelong cumulative sum\n",
    "            group_df['Cumulative_Sum'] = group_df['VL_CONTA'].cumsum()\n",
    "            \n",
    "            # Plot raw data\n",
    "            # group_df['VL_CONTA'].plot(label='Raw Data', legend=True)\n",
    "\n",
    "            # Plot moving average\n",
    "            group_df['MA'].plot(label=f'{window} Quarters Moving Average', legend=True, linestyle='--')\n",
    "            \n",
    "            # Plot rolling sum\n",
    "            group_df['Rolling_Sum'].plot(label=f'{window} Quarters Sum', legend=True, linestyle='-.')\n",
    "            \n",
    "            # Plot lifelong cumulative sum\n",
    "            group_df['Cumulative_Sum'].plot(label='Lifelong Cumulative Sum', legend=True, linestyle='-.')\n",
    "\n",
    "            plt.title(f\"{group_df['CD_CVM'].iloc[-1]} {group_df['DENOM_CIA'].iloc[-1]}\")\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"Error plotting for {company}: {e}\")\n",
    "    return True\n",
    "\n",
    "cias_por_setor = df[(df['AGRUPAMENTO'] == 'con') & (df['CD_CONTA'] == '3.11')].groupby('CD_CVM')\n",
    "plot_group(cias_por_setor, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cias_por_setor = df[(df['AGRUPAMENTO'] == 'con') & (df['CD_CONTA'] == '2.03')].groupby('DENOM_CIA')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "for company, group_df in cias_por_setor:\n",
    "    try:\n",
    "        group_df[['VL_CONTA']].plot(ax=ax, label=company)\n",
    "    except:\n",
    "        print(company)\n",
    "\n",
    "ax.set_title(\"VL_CONTA by Company\")\n",
    "ax.set_ylabel(\"VL_CONTA\")\n",
    "ax.set_xlabel(\"Index\")\n",
    "ax.legend(loc=\"best\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intelacoes Fundamentalista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intelacoes = run.load_pkl(f'{b3.app_folder}intelacoes')\n",
    "intelacoes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('BENS INDUSTRIAIS_intelacoes.pkl')\n",
    "# df.to_csv('BENS INDUSTRIAIS_intelacoes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Unnamed: 0', 'FILENAME', 'DEMONSTRATIVO', 'BALANCE_SHEET', 'ANO',\n",
    "       'AGRUPAMENTO', 'CNPJ_CIA', 'DT_REFER', 'VERSAO', 'DENOM_CIA', 'CD_CVM',\n",
    "       'GRUPO_DFP', 'MOEDA', 'ESCALA_MOEDA', 'DT_FIM_EXERC', 'CD_CONTA',\n",
    "       'DS_CONTA', 'VL_CONTA', 'ST_CONTA_FIXA', 'DT_INI_EXERC', 'COLUNA_DF',\n",
    "       'COMPANHIA', 'PREGAO', 'TICK', 'LISTAGEM', 'CVM', 'TICKERS', 'ISIN',\n",
    "       'CNPJ', 'ATIVIDADE', 'SETOR', 'SUBSETOR', 'SEGMENTO', 'SITE',\n",
    "       'ESCRITURADOR', 'CD_CONTA_original', 'DS_CONTA_original', 'Companhia',\n",
    "       'Trimestre', 'Ações ON', 'Ações PN', 'Ações ON em Tesouraria',\n",
    "       'Ações PN em Tesouraria', 'URL']\n",
    "cols = ['SETOR', 'SUBSETOR', 'SEGMENTO', 'CNPJ_CIA', 'DENOM_CIA', 'CD_CVM',  'PREGAO', 'TICK', 'LISTAGEM', 'TICKERS', 'DT_REFER', 'BALANCE_SHEET', 'CD_CONTA', 'DS_CONTA', 'VL_CONTA', ]\n",
    "datetime_cols = ['DT_REFER', 'DT_FIM_EXERC', 'DT_INI_EXERC', 'Trimestre']\n",
    "company_cols = ['SETOR', 'SUBSETOR', 'SEGMENTO', 'CNPJ_CIA', 'DENOM_CIA', 'CD_CVM']\n",
    "dateseries_col = ['DT_REFER']\n",
    "sheet_cols = ['BALANCE_SHEET', 'CD_CONTA', 'DS_CONTA', 'VL_CONTA']\n",
    "stocks_cols = ['Ações ON', 'Ações PN', 'Ações ON em Tesouraria', 'Ações PN em Tesouraria']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by 'SETOR', 'SUBSETOR', and 'SEGMENTO' to count unique companies and aggregate their TICK values\n",
    "ticks_by_setor = df.groupby(['SETOR', 'SUBSETOR', 'SEGMENTO']).agg({\n",
    "    'DENOM_CIA': 'nunique',\n",
    "    'TICK': lambda x: list(set(x.dropna()))\n",
    "}).reset_index()\n",
    "\n",
    "# Renaming columns for clarity\n",
    "ticks_by_setor.rename(columns={'DENOM_CIA': 'TOTAL DE COMPANHIAS'}, inplace=True)\n",
    "\n",
    "ticks_by_setor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conta = '02.03'\n",
    "\n",
    "# Filtering the data for the account 'CD_CONTA' with value '02.03' and the latest quarter\n",
    "conta_by_setor = df[df['DT_REFER'] == df['DT_REFER'].max()]\n",
    "conta_by_setor = conta_by_setor[conta_by_setor['CD_CONTA'] == conta]\n",
    "\n",
    "# Grouping by 'SETOR', 'SUBSETOR', and 'SEGMENTO' to aggregate 'VL_CONTA' values\n",
    "conta_by_setor = conta_by_setor.groupby(['SETOR', 'SUBSETOR', 'SEGMENTO', ]).agg({\n",
    "    'VL_CONTA': ['nunique', 'sum', 'max', 'min', 'mean', 'std', 'skew', lambda x: x.kurt()]\n",
    "}).reset_index()\n",
    "\n",
    "conta_by_setor.rename(columns={'VL_CONTA': conta}, inplace=True)\n",
    "\n",
    "conta_by_setor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = df\n",
    "# dfc = dfc.set_index('DT_REFER')\n",
    "company = 'WEG SA'\n",
    "quarter = '2020-12-31'\n",
    "conta = '01.01.01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = dfc['DENOM_CIA'] != 'nothing'\n",
    "mask &= dfc['DT_REFER'] == quarter\n",
    "mask &= dfc['DENOM_CIA'] == company\n",
    "# mask &= dfc['PREGAO'] == ''\n",
    "# mask &= dfc['TICK'] == ''\n",
    "# mask &= dfc['BALANCE_SHEET'] == ''\n",
    "mask &= dfc['CD_CONTA'] == conta\n",
    "# mask &= dfc['DS_CONTA'] == ''\n",
    "\n",
    "# dfc[mask][cols]\n",
    "data = dfc[mask][['DENOM_CIA', 'DT_REFER', 'CD_CONTA', 'DS_CONTA', 'VL_CONTA']].set_index('DT_REFER')\n",
    "sheet = df[(df['DENOM_CIA'] == company) & (df['DT_REFER'] == quarter)]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = pd.concat([dfc, rows], ignore_index=True).ffill().drop_duplicates()\n",
    "m = dfc['BALANCE_SHEET'].isin(sh)\n",
    "dfc[m][cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fund"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund = load_pkl(f'{b3.app_folder}fund')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('BENS INDUSTRIAIS_fund.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('BENS INDUSTRIAIS_fund.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TICKERS'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Macro Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install yfinance -q -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baixando Cotações do Índice Bovespa\n",
    "ibov = yf.download('^BVSP')\n",
    "df = yf.download(['WEGE3.SA','BBDC4.SA', 'PETR4.SA'], group_by='ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df['WEGE3.SA']['Adj Close']))\n",
    "tickers = df.columns.get_level_values(0).unique().tolist()\n",
    "tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tick in tickers:\n",
    "    df[tick]['Adj Close'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q alpha_vantage\n",
    "# Importando a classe Timeseries de alpha_vantage.timeseries\n",
    "from alpha_vantage.timeseries import TimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHAVANTAGE_API_KEY = 'KR3OMFL1CLANZUXP'\n",
    "# Criando o objeto ts\n",
    "ts = TimeSeries(key=ALPHAVANTAGE_API_KEY, output_format='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados, meta_dados = ts.get_symbol_search('alphabet')\n",
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtendo os dados semanais do IBOV usando get_weekly\n",
    "dados, meta_dados = ts.get_daily(symbol='AAPL', )\n",
    "dados['4. close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install quandl -q -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quandl\n",
    "mydata = quandl.get(\"FRED/GDP\")\n",
    "api = 'LpAz8JCUosdwhHqnWnA4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = quandl.get_table('ZACKS/FC', ticker='AAPL',)\n",
    "mydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas datareader\n",
    "import os\n",
    "import pandas_datareader as pdr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIINGO_API_KEY = '591375a6e5852ca48f778902fec322581511c89a'\n",
    "import tiingo\n",
    "\n",
    "config = {}\n",
    "config['session'] = True\n",
    "config['api_key'] = TIINGO_API_KEY\n",
    "client = tiingo.TiingoClient(config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "TIINGO_API_KEY = '591375a6e5852ca48f778902fec322581511c89a'\n",
    "url = 'https://api.tiingo.com/tiingo/fundamentals/definitions'\n",
    "url = 'https://api.tiingo.com/tiingo/daily/AAPL/prices?startDate=2012-1-1'\n",
    "# url = 'https://api.tiingo.com/tiingo/daily/AAPL/prices'\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': 'Token ' + TIINGO_API_KEY\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "data = response.json()\n",
    "data = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['close'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pdr.DataReader('GE', 'yahoo')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Yahoo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iterrow in fund and get same key from both dict to concat both and remove duplicates\n",
    "\n",
    "save quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integrate fund to quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrate funds to quotes, so each TICK contains quotes and also also all financial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = run.load_pkl(f'{b3.app_folder}quotes')\n",
    "fund = run.load_pkl(f'{b3.app_folder}fund')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['AERIS', 'ESTAPAR', 'ARMAC', 'ATMASA', 'AZUL', 'BARDELLA', 'CCR SA', 'ECORODOVIAS', 'ACO ALTONA', 'EMBPAR S/A', 'EMBRAER', 'ETERNIT', 'FRAS-LE', 'GPS', 'HAGA S/A', 'HIDROVIAS', 'ROMI', 'JSL', 'KEPLER WEBER', 'LOG-IN', 'MARCOPOLO', 'METALFRIO', 'RIOSULENSE', 'METISA', 'MILLS', 'MINASMAQUINA', 'NORDON MET', 'PORTOBELLO', 'PORTO VM', 'PRINER', 'RANDON PART', 'RECRUSUL', 'RUMO S.A.', 'SANTOS BRP', 'SCHULZ', 'SEQUOIA LOG', 'SONDOTECNICA', 'TAURUS ARMAS', 'TEGMA', 'TRIUNFO PART', 'TREVISA', 'VALID', 'WEG', 'WETZEL S/A', 'WILSON SONS', 'WLM IND COM', 'BRISANET', 'BRITANIA', 'DESKTOP', 'TELEBRAS', 'TELEF BRASIL', 'UNIFIQUE', 'ALLIED', 'ALPARGATAS', 'AMERICANAS', 'ANIMA', 'AREZZO CO', 'BAHEMA', 'BAHIAPCH', 'BIC MONARK', 'ZAMP S.A.', 'CEA MODAS', 'CEABS', 'CAMBUCI', 'CEDRO', 'COTEMINAS', 'SANTANENSE', 'COGNA ON', 'TENDA', 'TENDA ATACAD', 'FICA', 'CRUZEIRO EDU', 'CURY S/A', 'CYRELA REALT', 'DIRECIONAL', 'DOHLER', 'DOTZ SA', 'EVEN', 'EZTEC', 'GRENDENE', 'GRUPO SOMA', 'GRUPO SBF', 'GUARARAPES', 'GUARUPART', 'HELBOR', 'HERCULES', 'HOTEIS OTHON', 'IMC S/A', 'IOCHP-MAXION', 'JHSF PART', 'JOAO FORTES', 'KARSTEN', 'LAVVI', 'LOCALIZA', 'QUERO-QUERO', 'LOJAS RENNER', 'MAGAZ LUIZA', 'METAL LEVE', 'ESTRELA', 'LOJAS MARISA', 'MELNICK', 'MITRE REALTY', 'MOBLY', 'MOURA DUBEUX', 'MOVIDA', 'ESPACOLASER', 'MRV', 'MUNDIAL', 'PDG REALT', 'PETZ', 'PETTENATI', 'PLANOEPLANO', 'PLASCAR PART', 'VESTE', 'RNI', 'ROSSI RESID', 'SPTURIS', 'SARAIVA LIVR', 'SER EDUCA', 'SMART FIT', 'SPRINGS', 'TIME FOR FUN', 'TECHNOS', 'TECNISA', 'TEKA', 'TEX RENAUX', 'TRACK FIELD', 'TRISUL', 'UNICASA', 'VAMOS', 'VIA', 'VIVARA S.A.', 'VIVER', 'VULCABRAS', 'WHIRLPOOL', 'YDUQS PART', 'AGROGALAXY', 'AMBEV S/A', 'CARREFOUR BR', 'BOA SAFRA', 'BOMBRIL', 'BRASILAGRO', 'BRF SA', 'CAMIL', 'EXCELSIOR', 'GRUPO MATEUS', 'JBS', 'JOSAPAR', 'MARFRIG', 'M.DIASBRANCO', 'MINERVA', 'MINUPAR', 'GRUPO NATURA', 'POMIFRUTAS', 'RAIZEN', 'SAO MARTINHO', 'ASSAI', 'SLC AGRICOLA', 'TERRASANTAPA', '3TENTOS', 'ALFA HOLDING', 'ALPER S.A.', 'APERAM', 'B3', 'BANCO BMG', 'BANESTES', 'BBSEGURIDADE', 'ALFA INVEST', 'AMAZONIA', 'BRADESCO', 'BTGP BANCO', 'BANESE', 'BANRISUL', 'MERC INVEST', 'MERCANTIL', 'NORD BRASIL', 'SANTANDER BR', 'BR PARTNERS', 'BR PROPERT', 'NEXPE', 'BRB BANCO', 'CAIXA SEGURI', 'PAR AL BAHIA', 'SEG AL BAHIA', 'CIELO', 'CLEARSALE', 'ALFA CONSORC', 'COR RIBEIRO', 'CORREDOR LOG', 'MERC FINANC', 'MERCANTII', 'MERCATO EXPR', 'MERCEDESBENZ', 'CSU DIGITAL', 'SYN PROP TEC', 'DMFINANCEIRA', 'ALFA FINANC', 'G2D INVEST', 'GENERALSHOPP', 'GP INVEST', 'HBR REALTY', 'INTER CO', 'IRBBRASIL RE', 'LOG COM PROP', 'LOPES BRASIL', 'MONT ARANHA', 'MULTIPLAN', 'MULTITERMINA', 'PORTO SEGURO', 'PPLA', 'SAO CARLOS', 'SIMPAR', 'WIZ CO', 'AURA 360', 'AURATUS', 'BRADESPAR', 'BRASKEM', 'FERBASA', 'MELHOR SP', 'SID NACIONAL', 'CBA', 'CSNMINERACAO', 'DEXCO', 'DEXXOS PAR', 'EUCATEX', 'FER HERINGER', 'GERDAU', 'IRANI', 'KLABIN S/A', 'MANGELS INDL', 'GERDAU MET', 'NUTRIPLANT', 'PANATLANTICA', 'PARANAPANEMA', 'SANSUY', 'SUZANO S.A.', 'TEKNO', 'CRISTAL', 'UNIPAR', 'USIMINAS', 'VITTIA', 'ATOMPAR', 'CEMEPE', 'INVEST BEMGE', 'POLPAR', '3R PETROLEUM', 'COSAN', 'ENAUTA PART', 'OCEANPACT', 'OSX BRASIL', 'PETRORIO', 'VIBRA', 'PET MANGUINH', 'ULTRAPAR', 'ALLIAR', 'BAUMER', 'BLAU', 'VIVEO', 'D1000VFARMA', 'DIMED', 'FLEURY', 'MATER DEI', 'HYPERA', 'KORA SAUDE', 'ODONTOPREV', 'ONCOCLINICAS', 'ONCOMED', 'OUROFINO S/A', 'PROFARMA', 'QUALICORP', 'QUALICORSEG', 'QUALITY SOFT', 'RAIADROGASIL', 'REDE D OR', 'BEMOBI TECH', 'ENJOEI', 'GETNINJAS', 'INFRACOMM', 'INTELBRAS', 'WDC NETWORKS', 'LOCAWEB', 'MELIUZ', 'MULTILASER', 'NEOGRID', 'PADTEC', 'POSITIVO TEC', 'SINQIA', 'TRADEMASTER', 'TRADIMAQ', 'TOTVS', 'WESTWING', 'AES BRASIL', 'AFLUENTE T', 'ALUPAR', 'AMBIPAR', 'AUREN', 'ELETROBRAS', 'EBRASIL', 'ELETROPAR', 'ELETROMIDIA', 'ELETROPAULO', 'ELETRORIVERS', 'ELETROZEMA', 'CELESC', 'CASAN', 'CELGPAR', 'CEG', 'CEB', 'CEMIG', 'COELCE', 'CEEE-D', 'COPEL', 'SABESP', 'SANEPAR', 'CPFL ENERGIA', 'ELEKTRO', 'EMAE', 'ENEVA', 'EQUATORIAL', 'EQTL PARA', 'LIGHT S/A', 'NEOENERGIA', 'OMEGAENERGIA', 'ORIZON', 'REDE ENERGIA', 'REDE INTEGRA', 'RENOVA', 'GER PARANAP']),\n",
       " dict_keys(['AERI3']))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes.keys(), quotes['AERIS'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PREGAO</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>TICKER</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-11-12</th>\n",
       "      <td>AERIS</td>\n",
       "      <td>6.72</td>\n",
       "      <td>7.090000</td>\n",
       "      <td>6.050000</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>6.078847</td>\n",
       "      <td>10719500.0</td>\n",
       "      <td>AERI3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-13</th>\n",
       "      <td>AERIS</td>\n",
       "      <td>6.09</td>\n",
       "      <td>6.480000</td>\n",
       "      <td>6.070000</td>\n",
       "      <td>6.420000</td>\n",
       "      <td>6.397738</td>\n",
       "      <td>2830900.0</td>\n",
       "      <td>AERI3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-16</th>\n",
       "      <td>AERIS</td>\n",
       "      <td>6.53</td>\n",
       "      <td>6.980000</td>\n",
       "      <td>6.530000</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>6.77642</td>\n",
       "      <td>5568700.0</td>\n",
       "      <td>AERI3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-17</th>\n",
       "      <td>AERIS</td>\n",
       "      <td>6.90</td>\n",
       "      <td>7.050000</td>\n",
       "      <td>6.720000</td>\n",
       "      <td>6.730000</td>\n",
       "      <td>6.706663</td>\n",
       "      <td>3922900.0</td>\n",
       "      <td>AERI3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-18</th>\n",
       "      <td>AERIS</td>\n",
       "      <td>6.84</td>\n",
       "      <td>6.860000</td>\n",
       "      <td>6.540000</td>\n",
       "      <td>6.730000</td>\n",
       "      <td>6.706663</td>\n",
       "      <td>1352500.0</td>\n",
       "      <td>AERI3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-19</th>\n",
       "      <td>GER PARANAP</td>\n",
       "      <td>25.76</td>\n",
       "      <td>26.540001</td>\n",
       "      <td>25.370001</td>\n",
       "      <td>25.370001</td>\n",
       "      <td>25.370001</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>GEPA4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-20</th>\n",
       "      <td>GER PARANAP</td>\n",
       "      <td>25.50</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>25.370001</td>\n",
       "      <td>25.370001</td>\n",
       "      <td>25.370001</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>GEPA4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-21</th>\n",
       "      <td>GER PARANAP</td>\n",
       "      <td>25.35</td>\n",
       "      <td>25.350000</td>\n",
       "      <td>25.010000</td>\n",
       "      <td>25.010000</td>\n",
       "      <td>25.01</td>\n",
       "      <td>600.0</td>\n",
       "      <td>GEPA4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-22</th>\n",
       "      <td>GER PARANAP</td>\n",
       "      <td>25.25</td>\n",
       "      <td>25.250000</td>\n",
       "      <td>25.250000</td>\n",
       "      <td>25.250000</td>\n",
       "      <td>25.25</td>\n",
       "      <td>100.0</td>\n",
       "      <td>GEPA4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-25</th>\n",
       "      <td>GER PARANAP</td>\n",
       "      <td>25.40</td>\n",
       "      <td>25.400000</td>\n",
       "      <td>25.400000</td>\n",
       "      <td>25.400000</td>\n",
       "      <td>25.4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>GEPA4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1766549 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 PREGAO   Open       High        Low      Close  Adj Close  \\\n",
       "Date                                                                         \n",
       "2020-11-12        AERIS   6.72   7.090000   6.050000   6.100000   6.078847   \n",
       "2020-11-13        AERIS   6.09   6.480000   6.070000   6.420000   6.397738   \n",
       "2020-11-16        AERIS   6.53   6.980000   6.530000   6.800000    6.77642   \n",
       "2020-11-17        AERIS   6.90   7.050000   6.720000   6.730000   6.706663   \n",
       "2020-11-18        AERIS   6.84   6.860000   6.540000   6.730000   6.706663   \n",
       "...                 ...    ...        ...        ...        ...        ...   \n",
       "2023-09-19  GER PARANAP  25.76  26.540001  25.370001  25.370001  25.370001   \n",
       "2023-09-20  GER PARANAP  25.50  25.500000  25.370001  25.370001  25.370001   \n",
       "2023-09-21  GER PARANAP  25.35  25.350000  25.010000  25.010000      25.01   \n",
       "2023-09-22  GER PARANAP  25.25  25.250000  25.250000  25.250000      25.25   \n",
       "2023-09-25  GER PARANAP  25.40  25.400000  25.400000  25.400000       25.4   \n",
       "\n",
       "                Volume TICKER  \n",
       "Date                           \n",
       "2020-11-12  10719500.0  AERI3  \n",
       "2020-11-13   2830900.0  AERI3  \n",
       "2020-11-16   5568700.0  AERI3  \n",
       "2020-11-17   3922900.0  AERI3  \n",
       "2020-11-18   1352500.0  AERI3  \n",
       "...                ...    ...  \n",
       "2023-09-19      2500.0  GEPA4  \n",
       "2023-09-20      1100.0  GEPA4  \n",
       "2023-09-21       600.0  GEPA4  \n",
       "2023-09-22       100.0  GEPA4  \n",
       "2023-09-25       100.0  GEPA4  \n",
       "\n",
       "[1766549 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigdata = []\n",
    "for pregao, d in quotes.items():\n",
    "    for ticker, df in d.items():\n",
    "        try:\n",
    "            df.insert(0, 'PREGAO', pregao)\n",
    "        except Exception as e:\n",
    "            df['PREGAO'] = pregao  # Update 'PREGAO' column\n",
    "        \n",
    "        try:\n",
    "            df['TICKER'] = ticker  # Update 'TICKER' column\n",
    "        except Exception as e:\n",
    "            df.insert(1, 'TICKER', ticker)\n",
    "\n",
    "        bigdata.append(df)\n",
    "bigdata = pd.concat(bigdata, ignore_index=False)\n",
    "bigdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['BENS INDUSTRIAIS', 'COMUNICACOES', 'CONSUMO CICLICO', 'CONSUMO NAO CICLICO', 'FINANCEIRO', 'MATERIAIS BASICOS', 'NAO CLASSIFICADOS', 'Nenhum', 'OUTROS', 'PETROLEO GAS E BIOCOMBUSTIVEIS', 'SAUDE', 'TECNOLOGIA DA INFORMACAO', 'UTILIDADE PUBLICA'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fund.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data subset\n",
    "df_fund = fund['BENS INDUSTRIAIS']\n",
    "\n",
    "# Data preprocessing\n",
    "# Convert specific columns to object type\n",
    "df_fund[['VERSAO', 'CD_CVM']] = df_fund[['VERSAO', 'CD_CVM']].astype('object')\n",
    "\n",
    "# Convert 'DT_REFER' to datetime format\n",
    "df_fund['DT_REFER'] = pd.to_datetime(df_fund['DT_REFER'])\n",
    "\n",
    "# Pivot for CD_CONTA\n",
    "df_cd_conta = df_fund.pivot_table(index=['DT_REFER', 'PREGAO'], \n",
    "                                  columns=['CD_CONTA', 'DS_CONTA'], \n",
    "                                  values='VL_CONTA', \n",
    "                                  aggfunc='sum').reset_index()\n",
    "\n",
    "# Flatten the multi-level columns after pivot\n",
    "df_cd_conta.columns = [' - '.join(col).strip(' - ') for col in df_cd_conta.columns.values]\n",
    "\n",
    "# Extract unique combinations of DT_REFER and PREGAO without the account details and get an unique mapping between the dates, PREGAO, and the pivoted account data.\n",
    "df_unique = df_fund.reset_index(drop=True).drop_duplicates(subset=['DT_REFER', 'PREGAO']).drop(['CD_CONTA', 'DS_CONTA', 'VL_CONTA'], axis=1)\n",
    "df_merged = pd.merge(df_unique, df_cd_conta, on=['DT_REFER', 'PREGAO'])\n",
    "\n",
    "# Set index and handle missing values\n",
    "df_merged = df_merged.set_index(['DT_REFER', 'PREGAO'], drop=True)\n",
    "\n",
    "# Group by 'PREGAO' and apply resampling\n",
    "df_resampled = (\n",
    "    df_merged\n",
    "    .reset_index()\n",
    "    .groupby('PREGAO')\n",
    "    .apply(lambda group: group.set_index('DT_REFER').resample('D').asfreq().ffill().bfill().fillna(0))\n",
    "    .drop('PREGAO', axis=1)  # Drop the redundant 'PREGAO' column introduced by `groupby`\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdata = bigdata.reset_index()\n",
    "bigdata['Date'] = pd.to_datetime(bigdata['Date'])\n",
    "df_resampled = df_resampled.reset_index()\n",
    "df_resampled['DT_REFER'] = pd.to_datetime(df_resampled['DT_REFER'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Get unique PREGAO values from df_resampled\n",
    "unique_pregao = df_resampled['PREGAO'].unique()\n",
    "\n",
    "# Step 2: Filter bigdata\n",
    "filtered_bigdata = bigdata[bigdata['PREGAO'].isin(unique_pregao)]\n",
    "\n",
    "df_merged = pd.merge(filtered_bigdata, df_resampled, left_on=['Date', 'PREGAO'], right_on=['DT_REFER', 'PREGAO'], how='outer')\n",
    "df_merged = df_merged.ffill().bfill().fillna(0).sort_values(by=['PREGAO', 'Date']).set_index('Date', drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ACO ALTONA', 'AERIS', 'ALL NORTE', 'ALL PAULISTA', 'ARMAC',\n",
       "       'ARTERIS', 'ATMASA', 'AUTOBAN', 'AZEVEDO', 'AZUL', 'BARDELLA',\n",
       "       'BBMLOGISTICA', 'CCR SA', 'CONC RAPOSO', 'CONC RIO TER',\n",
       "       'DTCOM-DIRECT', 'ECON', 'ECOPISTAS', 'ECORODOVIAS', 'ECOVIAS',\n",
       "       'EMBPAR S/A', 'EMBRAER', 'ESTAPAR', 'ETERNIT', 'FER C ATLANT',\n",
       "       'FLEX S/A', 'FRAS-LE', 'GOL', 'GPS', 'GRUAIRPORT', 'HAGA S/A',\n",
       "       'HIDROVIAS', 'HMOBI S.A', 'INEPAR', 'INVEPAR', 'JSL',\n",
       "       'KEPLER WEBER', 'LOG-IN', 'MARCOPOLO', 'METALFRIO', 'METISA',\n",
       "       'METRO-SP', 'MILLS', 'MINASMAQUINA', 'MRS LOGIST', 'NORDON MET',\n",
       "       'PORTO VM', 'PORTOBELLO', 'PRATICA', 'PRINER', 'RANDON PART',\n",
       "       'RECRUSUL', 'RIOSULENSE', 'ROD COLINAS', 'ROD TIETE', 'ROMI',\n",
       "       'RT BANDEIRAS', 'RUMO S.A.', 'SALUS INFRA', 'SANTOS BRP', 'SCHULZ',\n",
       "       'SEQUOIA LOG', 'SONDOTECNICA', 'TAURUS ARMAS', 'TEGMA', 'TREVISA',\n",
       "       'TRIUNFO PART', 'VALID', 'VIAOESTE', 'WEG', 'WETZEL S/A',\n",
       "       'WILSON SONS', 'WLM IND COM'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['PREGAO'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "company = 'SCHULZ'\n",
    "df = df_merged[df_merged['PREGAO'] == company].sort_index()\n",
    "# df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01 - Ativo Total',\n",
       " '01.01 - Ativo Circulante de Curto Prazo',\n",
       " '01.01.01 - Caixa e Disponibilidades de Caixa',\n",
       " '01.01.02 - Aplicações Financeiras',\n",
       " '01.01.03 - Contas a Receber',\n",
       " '01.01.04 - Estoques',\n",
       " '01.01.05 - Ativos Biológicos',\n",
       " '01.01.06 - Tributos',\n",
       " '01.01.07 - Despesas',\n",
       " '01.01.09 - Outros Ativos Circulantes',\n",
       " '01.02 - Ativo Não Circulante de Longo Prazo',\n",
       " '01.02.01 - Ativos Financeiros',\n",
       " '01.02.01.01 - Ativos Financeiros a Valor Justo',\n",
       " '01.02.01.02 - Ativos Financeiros ao Custo Amortizado',\n",
       " '01.02.01.03 - Contas a Receber',\n",
       " '01.02.01.04 - Estoques',\n",
       " '01.02.01.05 - Ativos Biológicos',\n",
       " '01.02.01.06 - Tributos',\n",
       " '01.02.01.07 - Despesas',\n",
       " '01.02.01.09 - Outros Ativos Não Circulantes',\n",
       " '01.02.02 - Investimentos Não Capex',\n",
       " '01.02.02.01 - Propriedades - Investimentos Não Capex',\n",
       " '01.02.02.02 - Arrendamentos - Investimentos Não Capex',\n",
       " '01.02.03 - Imobilizados',\n",
       " '01.02.03.01 - Imobilizados em Operação',\n",
       " '01.02.03.02 - Imobilizados em Arrendamento',\n",
       " '01.02.03.03 - Imobilizados em Andamento',\n",
       " '01.02.04 - Intangível',\n",
       " '01.03 - Empréstimos',\n",
       " '01.04 - Tributos Diferidos',\n",
       " '01.05 - Investimentos',\n",
       " '01.05.01 - Participações em Coligadas',\n",
       " '01.05.02 - Participações em Controladas',\n",
       " '01.06 - Imobilizados',\n",
       " '01.06.01 - Propriedades - Investimentos Não Capex',\n",
       " '01.06.02 - Arrendamento - Investimentos Não Capex',\n",
       " '01.06.03 - Tangíveis - Investimentos Não Capex',\n",
       " '01.07 - Intangíveis',\n",
       " '01.09.09 - Outros Ativos']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = df_merged.columns.tolist()\n",
    "\n",
    "# Create lists based on the starting character of the column name\n",
    "col_1 = [col for col in cols if col.startswith('01')]\n",
    "col_2 = [col for col in cols if col.startswith('02')]\n",
    "col_3 = [col for col in cols if col.startswith('03')]\n",
    "col_4 = [col for col in cols if col.startswith('04')]\n",
    "col_5 = [col for col in cols if col.startswith('05')]\n",
    "col_6 = [col for col in cols if col.startswith('06')]\n",
    "col_7 = [col for col in cols if col.startswith('07')]\n",
    "cols_other = [col for col in cols if not col[0].isdigit()]\n",
    "col_ohlc = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', ]\n",
    "\n",
    "# Display the structure of the balance sheet from the numbered columns\n",
    "structure = {\n",
    "    \"01\": col_1,\n",
    "    \"02\": col_2,\n",
    "    \"03\": col_3,\n",
    "    \"04\": col_4,\n",
    "    \"05\": col_5,\n",
    "    \"06\": col_6,\n",
    "    \"07\": col_7,\n",
    "    \"Other\": cols_other,\n",
    "    \"OHLC\": col_ohlc\n",
    "}\n",
    "structure['01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01.01 - Ativo Circulante de Curto Prazo: from 213060 to 1867844, 4.54 times min to max\n",
      "01.02 - Ativo Não Circulante de Longo Prazo: from 203862 to 993416, 2.40 times min to max\n"
     ]
    }
   ],
   "source": [
    "cols_plot = ['01.01 - Ativo Circulante de Curto Prazo', '01.02 - Ativo Não Circulante de Longo Prazo']\n",
    "# cols_plot = ['01 - Ativo Total']\n",
    "# Extracting data for the specified columns\n",
    "data_analysis = df[[\"Date\"] + cols_plot]\n",
    "\n",
    "# Generating summary statistics for the columns\n",
    "summary_stats = data_analysis.describe()\n",
    "\n",
    "for col in cols_plot:\n",
    "    dp = df[col].std()\n",
    "    mean = df[col].mean()\n",
    "    range_1 = mean - 2 * dp\n",
    "    range_2 = mean + 2 * dp\n",
    "    min = df[col].min()\n",
    "    max = df[col].max()\n",
    "    mult = max/min\n",
    "    print(f'{col}: from {range_1:.0f} to {range_2:.0f}, {mult:.2f} times min to max')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the first-level major subgroups to use the full original column name\n",
    "first_level_subgroups = {col: [] for col in col_1 if len(col.split(\" - \")[0].split(\".\")) == 2}\n",
    "\n",
    "# Create stacked area plots for the first-level major categories and their deeper subgroups\n",
    "# Extract the columns for the first-level major subgroups\n",
    "\n",
    "# Create a single area plot for all the first-level major categories\n",
    "\n",
    "fig_line = px.line(df, x=\"Date\", y=first_level_cols, \n",
    "                   title=f\"{company}: Total de Ativos: Linha do Tempo\",\n",
    "                   labels={\"value\": \"Valor (R$)\", \"variable\": \"Ativos\"})\n",
    "fig_line.show()\n",
    "\n",
    "fig_area = px.area(df, x=\"Date\", y=first_level_cols, \n",
    "                          title=f\"{company}: Total de Ativos: Distribuição Cumulativa\",\n",
    "                          labels={\"value\": \"Valor (R$)\", \"variable\": \"Ativos\"})\n",
    "fig_area.show()\n",
    "\n",
    "fig_100_stacked = px.area(df, x=\"Date\", y=first_level_cols, \n",
    "                          title=f\"{company}: Total de Ativos: Distribuição Proporcional\",\n",
    "                          labels={\"value\": \"Porcentagem (%)\", \"variable\": \"Ativos\"},\n",
    "                          groupnorm='percent')  # Normalize to percentage\n",
    "fig_100_stacked.show()\n",
    "\n",
    "for key in first_level_subgroups:\n",
    "    # Extract level 3 items for each major subgroup\n",
    "    subgroup_cols = [col for col in df.columns if col.startswith(key.split(\" - \")[0]) and len(col.split(\" - \")[0].split(\".\")) == 3]\n",
    "    if subgroup_cols:\n",
    "        deeper_fig_line = px.line(df, x=\"Date\", y=subgroup_cols, \n",
    "                             title=f\"{company}: {key.split(' - ')[1]}: Linha do Tempo\",\n",
    "                             labels={\"value\": \"Valor (R$)\", \"variable\": f\"{key}\"})\n",
    "        deeper_fig_line.show()\n",
    "\n",
    "        deeper_fig_area = px.area(df, x=\"Date\", y=subgroup_cols, \n",
    "                                title=f\"{company}: {key.split(' - ')[1]}: Distribuição Cumulativa\",\n",
    "                                labels={\"value\": \"Valor (R$)\", \"variable\": f\"{key}\"})\n",
    "        deeper_fig_area.show()\n",
    "\n",
    "        deeper_fig_100_stacked = px.area(df, x=\"Date\", y=subgroup_cols, \n",
    "                                title=f\"{company}: {key.split(' - ')[1]}: Distribuição Proporcional\",\n",
    "                                labels={\"value\": \"Porcentagem (%)\", \"variable\": f\"{key}\"}, \n",
    "                                groupnorm='percent')  # Normalize to percentage\n",
    "        deeper_fig_100_stacked.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to plot moving average for a given column\n",
    "def plot_moving_average(df, column, window, label):\n",
    "    \"\"\"\n",
    "    Plots a given column from the dataframe df with its moving average and ±2 standard deviations.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing the data.\n",
    "    - column: Column name to be plotted.\n",
    "    - window: Rolling window size for moving average.\n",
    "    - label: Label for the column, usually a more descriptive name.\n",
    "\n",
    "    Returns:\n",
    "    - A Plotly figure object.\n",
    "    \"\"\"\n",
    "    # Calculate rolling mean (moving average) and standard deviation\n",
    "    rolling_mean = df[column].rolling(window=window).mean()\n",
    "    rolling_std = df[column].rolling(window=window).std()\n",
    "\n",
    "    # Create the plot\n",
    "    fig = px.line(df, x=\"Date\", y=column, \n",
    "                  title=f\"{company}: {label}: Média Móvel e ±2 Desvios Padrão\",\n",
    "                  labels={\"Date\": \"Data\", column: \"Valor (R$)\"})\n",
    "\n",
    "    # Add moving average and ±2 standard deviations\n",
    "    fig.add_traces(go.Scatter(x=df[\"Date\"], y=df[column], mode='lines', \n",
    "                              name=\"Valores Brutos\"))\n",
    "    fig.add_traces(go.Scatter(x=df[\"Date\"], y=rolling_mean, mode='lines', \n",
    "                              line=dict(dash=\"dot\", color=\"red\"), name=\"Média Móvel\"))\n",
    "    fig.add_traces(go.Scatter(x=df[\"Date\"], y=rolling_mean + 2*rolling_std, mode='lines', \n",
    "                              line=dict(dash=\"dash\", color=\"green\"), name=\"Média Móvel +2 Desvios Padrão\"))\n",
    "    fig.add_traces(go.Scatter(x=df[\"Date\"], y=rolling_mean - 2*rolling_std, mode='lines', \n",
    "                              line=dict(dash=\"dash\", color=\"blue\"), name=\"Média Móvel -2 Desvios Padrão\"))\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a function to save the plots\n",
    "def save_plot(fig, folder, filename):\n",
    "    \"\"\"\n",
    "    Save the Plotly figure as a PNG image in the specified folder with the given filename.\n",
    "    \n",
    "    Parameters:\n",
    "    - fig: Plotly figure object to be saved.\n",
    "    - folder: Folder path to save the image.\n",
    "    - filename: Name for the saved image file.\n",
    "    \"\"\"\n",
    "    # Create folder if it doesn't exist\n",
    "    if not os.path.exists(f'company/{folder}'):\n",
    "        os.makedirs(f'company/{folder}')\n",
    "    \n",
    "    # Define the full path for the file\n",
    "    file_path = os.path.join(f'company/{folder}', filename + \".png\")\n",
    "    \n",
    "    # Save the figure as a PNG image\n",
    "    fig.write_image(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single area plot for all the first-level major categories\n",
    "fig_line = px.line(df, x=\"Date\", y=first_level_cols, \n",
    "                   title=f\"{company}: Total de Ativos: Linha do Tempo\",\n",
    "                   labels={\"value\": \"Valor (R$)\", \"variable\": \"Ativos\"})\n",
    "fig_line.show()\n",
    "\n",
    "fig_area = px.area(df, x=\"Date\", y=first_level_cols, \n",
    "                          title=f\"{company}: Total de Ativos: Distribuição Cumulativa\",\n",
    "                          labels={\"value\": \"Valor (R$)\", \"variable\": \"Ativos\"})\n",
    "fig_area.show()\n",
    "\n",
    "fig_100_stacked = px.area(df, x=\"Date\", y=first_level_cols, \n",
    "                          title=f\"{company}: Total de Ativos: Distribuição Proporcional\",\n",
    "                          labels={\"value\": \"Porcentagem (%)\", \"variable\": \"Ativos\"},\n",
    "                          groupnorm='percent')  # Normalize to percentage\n",
    "fig_100_stacked.show()\n",
    "\n",
    "# Moving average plot for the first-level major categories\n",
    "for col in first_level_cols:\n",
    "    fig_moving_avg = plot_moving_average(df, col, window, col.split(' - ')[1])\n",
    "    fig_moving_avg.show()\n",
    "\n",
    "# For each deeper level subgroup\n",
    "for i, key in enumerate(first_level_subgroups):\n",
    "    # Extract level 3 items for each major subgroup\n",
    "    subgroup_cols = [col for col in df.columns if col.startswith(key.split(\" - \")[0]) and len(col.split(\" - \")[0].split(\".\")) == 3]\n",
    "    if subgroup_cols:\n",
    "        deeper_fig_line = px.line(df, x=\"Date\", y=subgroup_cols, \n",
    "                             title=f\"{company}: {key.split(' - ')[1]}: Linha do Tempo\",\n",
    "                             labels={\"value\": \"Valor (R$)\", \"variable\": f\"{key}\"})\n",
    "        deeper_fig_line.show()\n",
    "\n",
    "        deeper_fig_area = px.area(df, x=\"Date\", y=subgroup_cols, \n",
    "                                title=f\"{company}: {key.split(' - ')[1]}: Distribuição Cumulativa\",\n",
    "                                labels={\"value\": \"Valor (R$)\", \"variable\": f\"{key}\"})\n",
    "        deeper_fig_area.show()\n",
    "\n",
    "        deeper_fig_100_stacked = px.area(df, x=\"Date\", y=subgroup_cols, \n",
    "                                title=f\"{company}: {key.split(' - ')[1]}: Distribuição Proporcional\",\n",
    "                                labels={\"value\": \"Porcentagem (%)\", \"variable\": f\"{key}\"}, \n",
    "                                groupnorm='percent')  # Normalize to percentage\n",
    "        deeper_fig_100_stacked.show()\n",
    "\n",
    "        # Moving average plot for the deeper-level subcategories\n",
    "        for sub_col in subgroup_cols:\n",
    "            fig_moving_avg = plot_moving_average(df, sub_col, window, sub_col.split(' - ')[1])\n",
    "            fig_moving_avg.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01.01 - Ativo Circulante de Curto Prazo\n",
      "01.02 - Ativo Não Circulante de Longo Prazo\n",
      "01.05 - Investimentos\n",
      "01.06 - Imobilizados\n"
     ]
    }
   ],
   "source": [
    "window = 1 * 365\n",
    "\n",
    "\n",
    "# Create a directory for the company\n",
    "company_dir = f\"./{company}\"\n",
    "\n",
    "# # Save the first-level major category plots\n",
    "save_plot(fig_line, company_dir, f\"{company} - 01 - Ativo Total - Linha do Tempo\")\n",
    "save_plot(fig_area, company_dir, f\"{company} - 01 - Ativo Total - Distribuição Cumulativa\")\n",
    "save_plot(fig_100_stacked, company_dir, f\"{company} - 01 - Ativo Total - Distribuição Proporcional\")\n",
    "\n",
    "# Adjust the first-level major subgroups to use the full original column name\n",
    "first_level_subgroups = {col: [] for col in col_1 if len(col.split(\" - \")[0].split(\".\")) == 2}\n",
    "\n",
    "# Extract the columns for the first-level major subgroups\n",
    "first_level_cols = list(first_level_subgroups.keys())\n",
    "\n",
    "# For each first-level major category\n",
    "for col in first_level_cols:\n",
    "    fig_moving_avg = plot_moving_average(df, col, window, col.split(' - ')[1])\n",
    "    save_plot(fig_moving_avg, company_dir, f\"{company} - 01 - Ativo Total - Média Móvel\")\n",
    "\n",
    "# For each deeper level subgroup\n",
    "for i, key in enumerate(first_level_subgroups):\n",
    "    subgroup_cols = [col for col in df.columns if col.startswith(key.split(\" - \")[0]) and len(col.split(\" - \")[0].split(\".\")) == 3]\n",
    "    if subgroup_cols:\n",
    "        print(key)\n",
    "        # Directory for the deeper-level subcategory plots\n",
    "        subgroup_dir = os.path.join(company_dir, key)\n",
    "        subgroup_dir = os.path.join(company_dir)\n",
    "        title=f\"{company} - {key} - \"\n",
    "        deeper_fig_line = px.line(df, x=\"Date\", y=subgroup_cols, \n",
    "                             title = title + \"Linha do Tempo\",\n",
    "                             labels={\"value\": \"Valor (R$)\", \"variable\": f\"{key}\"})\n",
    "        save_plot(deeper_fig_line, subgroup_dir, title + \"Linha do Tempo\")\n",
    "        \n",
    "        deeper_fig_area = px.area(df, x=\"Date\", y=subgroup_cols, \n",
    "                                title = title + \"Distribuição Cumulativa\",\n",
    "                                labels={\"value\": \"Valor (R$)\", \"variable\": f\"{key}\"})\n",
    "        save_plot(deeper_fig_area, subgroup_dir, title + \"Distribuição Cumulativa\")\n",
    "\n",
    "        deeper_fig_100_stacked = px.area(df, x=\"Date\", y=subgroup_cols, \n",
    "                                title = title + \"Distribuição Proporcional\",\n",
    "                                labels={\"value\": \"Porcentagem (%)\", \"variable\": f\"{key}\"}, \n",
    "                                groupnorm='percent')  # Normalize to percentage\n",
    "        save_plot(deeper_fig_100_stacked, subgroup_dir, title + \"Distribuição Proporcional\")\n",
    "        \n",
    "        # Save the moving average plots for the deeper-level subcategories\n",
    "        for sub_col in subgroup_cols:\n",
    "            fig_moving_avg = plot_moving_average(df, sub_col, window, sub_col.split(' - ')[1])\n",
    "            save_plot(fig_moving_avg, subgroup_dir, title + \"Média Móvel\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "window = 1 * 365\n",
    "\n",
    "def save_plot(fig, folder, filename):\n",
    "    \"\"\"Save the Plotly figure as a PNG image.\"\"\"\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    file_path = os.path.join(folder, filename + \".png\")\n",
    "    fig.write_image(file_path)\n",
    "\n",
    "def plot_moving_average(df, column, window, title):\n",
    "    \"\"\"Generate a plot with its moving average and ±2 standard deviations.\"\"\"\n",
    "    rolling_mean = df[column].rolling(window=window).mean()\n",
    "    rolling_std = df[column].rolling(window=window).std()\n",
    "\n",
    "    fig = px.line(df, x=\"Date\", y=column, title=title, labels={\"Date\": \"Data\", column: \"Valor (R$)\"})\n",
    "    fig.add_traces(go.Scatter(x=df[\"Date\"], y=df[column], mode='lines', name=\"Valores Brutos\"))\n",
    "    fig.add_traces(go.Scatter(x=df[\"Date\"], y=rolling_mean, mode='lines', line=dict(dash=\"dot\", color=\"red\"), name=\"Média Móvel\"))\n",
    "    fig.add_traces(go.Scatter(x=df[\"Date\"], y=rolling_mean + 2*rolling_std, mode='lines', line=dict(dash=\"dash\", color=\"green\"), name=\"Média Móvel +2 Desvios Padrão\"))\n",
    "    fig.add_traces(go.Scatter(x=df[\"Date\"], y=rolling_mean - 2*rolling_std, mode='lines', line=dict(dash=\"dash\", color=\"blue\"), name=\"Média Móvel -2 Desvios Padrão\"))\n",
    "    return fig\n",
    "\n",
    "# Base directory for the company\n",
    "company_dir = f\"./company/{company}\"\n",
    "\n",
    "# Save the first-level major category plots\n",
    "plots = {\n",
    "    \"Linha do Tempo\": fig_line,\n",
    "    \"Distribuição Cumulativa\": fig_area,\n",
    "    \"Distribuição Proporcional\": fig_100_stacked\n",
    "}\n",
    "\n",
    "for title, fig in plots.items():\n",
    "    save_plot(fig, company_dir, f\"{company} - 01 - Ativo Total - {title}\")\n",
    "\n",
    "# First-level major subgroups\n",
    "first_level_subgroups = {col: [] for col in col_1 if len(col.split(\" - \")[0].split(\".\")) == 2}\n",
    "first_level_cols = list(first_level_subgroups.keys())\n",
    "\n",
    "# Save plots for each first-level major category\n",
    "for col in first_level_cols:\n",
    "    title = f\"{company} - {col} - Média Móvel\"\n",
    "    fig_moving_avg = plot_moving_average(df, col, window, title)\n",
    "    save_plot(fig_moving_avg, company_dir, title)\n",
    "\n",
    "# For each deeper level subgroup\n",
    "for key in first_level_subgroups:\n",
    "    subgroup_cols = [col for col in df.columns if col.startswith(key.split(\" - \")[0]) and len(col.split(\" - \")[0].split(\".\")) == 3]\n",
    "    if subgroup_cols:\n",
    "        subgroup_dir = os.path.join(company_dir, key.split(' - ')[1])\n",
    "        titles = {\n",
    "            \"Linha do Tempo\": \"Linha do Tempo\",\n",
    "            \"Distribuição Cumulativa\": \"Distribuição Cumulativa\",\n",
    "            \"Distribuição Proporcional\": \"Distribuição Proporcional\",\n",
    "            \"Média Móvel\": \"Média Móvel\"\n",
    "        }\n",
    "        for title, plot_type in titles.items():\n",
    "            if plot_type == \"Linha do Tempo\":\n",
    "                fig = px.line(df, x=\"Date\", y=subgroup_cols, title=f\"{company} - {key} - {plot_type}\")\n",
    "            elif plot_type == \"Distribuição Cumulativa\":\n",
    "                fig = px.area(df, x=\"Date\", y=subgroup_cols, title=f\"{company} - {key} - {plot_type}\")\n",
    "            elif plot_type == \"Distribuição Proporcional\":\n",
    "                fig = px.area(df, x=\"Date\", y=subgroup_cols, title=f\"{company} - {key} - {plot_type}\", groupnorm='percent')\n",
    "            else:\n",
    "                fig_moving_avg = plot_moving_average(df, col, window, title)\n",
    "            save_plot(fig, subgroup_dir, f\"{company} - {key} - {plot_type}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_1 = [col for col in cols if col.startswith('01')]\n",
    "col_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 1: 01 - Ativo Total\n",
      "['01.01 - Ativo Circulante de Curto Prazo', '01.02 - Ativo Não Circulante de Longo Prazo', '01.03 - Empréstimos', '01.04 - Tributos Diferidos', '01.05 - Investimentos', '01.06 - Imobilizados', '01.07 - Intangíveis']\n"
     ]
    }
   ],
   "source": [
    "sheet_part = '01'\n",
    "structure[sheet_part]\n",
    "for col in structure[sheet_part]:\n",
    "    # Count the number of periods in the item's name\n",
    "    level = col.count('.') + 1\n",
    "    \n",
    "    # Determine the level based on the count and print the sub-columns\n",
    "    if level == 1:\n",
    "        print(f\"Level 1: {col}\")\n",
    "        sub_cols = [item for item in structure[sheet_part] if item.startswith(col.split(' - ')[0]) and item.count('.') == 1]\n",
    "        print(sub_cols)\n",
    "        break\n",
    "    elif level == 2:\n",
    "        print(f\"Level 2: {col}\")\n",
    "        sub_cols = [item for item in structure[sheet_part] if item.startswith(col.split(' - ')[0]) and item.count('.') == 2]\n",
    "        print(sub_cols)\n",
    "    elif level == 3:\n",
    "        print(f\"Level 3: {col}\")\n",
    "        sub_cols = [item for item in structure[sheet_part] if item.startswith(col.split(' - ')[0]) and item.count('.') == 3]\n",
    "        print(sub_cols)\n",
    "    elif level == 4:\n",
    "        print(f\"Level 4: {col}\")\n",
    "        sub_cols = [item for item in structure[sheet_part] if item.startswith(col.split(' - ')[0]) and item.count('.') == 4]\n",
    "        print(sub_cols)\n",
    "    elif level == 5:\n",
    "        print(f\"Level 5: {col}\")\n",
    "        sub_cols = [item for item in structure[sheet_part] if item.startswith(col.split(' - ')[0]) and item.count('.') == 5]\n",
    "        print(sub_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = '01.01 - Ativo Circulante de Curto Prazo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01.01.01 - Caixa e Disponibilidades de Caixa',\n",
       " '01.01.02 - Aplicações Financeiras',\n",
       " '01.01.03 - Contas a Receber',\n",
       " '01.01.04 - Estoques',\n",
       " '01.01.05 - Ativos Biológicos',\n",
       " '01.01.06 - Tributos',\n",
       " '01.01.07 - Despesas',\n",
       " '01.01.09 - Outros Ativos Circulantes']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[c for c in df.columns if c.startswith(col.split(' - ')[0] + '.') and c.count('.') == col.count('.') + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_figs(company, df, col, window):\n",
    "    figs = {}\n",
    "    sub_cols = [c for c in df.columns if c.startswith(col.split(' - ')[0] + '.') and c.count('.') == col.count('.') + 1]\n",
    "\n",
    "    # Calculate rolling mean and standard deviation\n",
    "    rolling_mean = df[col].rolling(window=window).mean()\n",
    "    rolling_std = df[col].rolling(window=window).std()\n",
    "\n",
    "    # Create a single line plot\n",
    "    title = f'Linha do Tempo'\n",
    "    fig_line = px.line(df, x=df.index, y=col, title=f'{col} - {title}',\n",
    "                        labels={'value': 'Valor (R$)', 'variable': f'{title}'})\n",
    "    figs[title] = fig_line\n",
    "    # fig_line.show()\n",
    "\n",
    "    # Create a moving average plot with ±2 standard deviations\n",
    "    title = f'Média Móvel e ±2 Desvios Padrão'\n",
    "    fig_mma_std = px.area(df, x=df.index, y=col, title=f'{col} - {title}',\n",
    "                        labels={'value': 'Valor (R$)', 'variable': f'{title}'})\n",
    "    fig_mma_std.add_scatter(x=df.index, y=rolling_mean, mode='lines', line=dict(color='green'), name='Média Móvel')\n",
    "    fig_mma_std.add_scatter(x=df.index, y=rolling_mean + 2 * rolling_std, mode='lines', line=dict(color='green', dash='dash'), name='Média Móvel + 2 Desvios Padrão')\n",
    "    fig_mma_std.add_scatter(x=df.index, y=rolling_mean - 2 * rolling_std, mode='lines', line=dict(color='green', dash='dash'), name='Média Móvel - 2 Desvios Padrão')\n",
    "    figs[title] = fig_mma_std\n",
    "    # fig_mma_std.show()\n",
    "\n",
    "    # Create a cumulative distribution plot\n",
    "    title =  f'Distribuição Acumulada'\n",
    "    fig_area = px.area(df, x=df.index, y=sub_cols, title=f'{col} - {title}',\n",
    "                        labels={'value': 'Valor (R$)', 'variable': f'{title}'})\n",
    "    figs[title] = fig_area\n",
    "    # fig_area.show()\n",
    "\n",
    "    # Create a proportional distribution plot\n",
    "    title = f'Distribuição Proporcional'\n",
    "    fig_area_100_stacked = px.area(df, x=df.index, y=sub_cols, title=f'{col} - {title}',\n",
    "                        labels={'value': 'Porcentagem (%)', 'variable': f'{title}'},\n",
    "                        groupnorm='percent')\n",
    "    figs[title] = fig_area_100_stacked\n",
    "    # fig_area_100_stacked.show()\n",
    "\n",
    "    return figs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_dir = f\"./company/{company}\"\n",
    "window = 365 * 5\n",
    "all_figs = {}\n",
    "all_figs[company] = {}\n",
    "\n",
    "start_time = run.time.time()\n",
    "for i, col in enumerate(structure['01']):\n",
    "    all_figs[company][col] = generate_figs(company, df, col, window)\n",
    "    run.remaining_time(start_time, len(structure['01']), i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for company, col_figs in all_figs.items():\n",
    "    print(f'{company}')\n",
    "    for col, figs in col_figs.items():\n",
    "        print(f'    {col}')\n",
    "        for title, fig in figs.items():\n",
    "            print(f'        {title}')\n",
    "            # fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
