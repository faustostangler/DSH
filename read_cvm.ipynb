{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import assets.helper as b3\n",
    "import assets.functions as run\n",
    "\n",
    "from typing import Dict, Union, List, Optional, Any\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import os\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "import plotly.graph_objects as go\n",
    "from plotly.graph_objs import Figure\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge Mix and Match all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    math = run.load_pkl(f'{b3.app_folder}math')\n",
    "except Exception as e:\n",
    "    math = run.get_math()\n",
    "    math = run.save_pkl(math, f'{b3.app_folder}math')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    setorial = run.load_pkl(f'{b3.app_folder}setorial')\n",
    "except Exception as e:\n",
    "    setorial = run.get_classificacao_setorial(setorial='')\n",
    "    setorial = run.save_pkl(setorial, f'{b3.app_folder}setorial')\n",
    "# setorial.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    b3_cvm = run.load_pkl(f'{b3.app_folder}b3_cvm')\n",
    "except Exception as e:\n",
    "    b3_cvm = run.b3_grab(b3.search_url)\n",
    "    b3_cvm = run.save_pkl(b3_cvm, f'{b3.app_folder}b3_cvm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETOR: O setor econômico mais amplo ao qual a empresa pertence.\n",
    "# SUBSETOR: Uma categorização mais específica dentro do setor mais amplo.\n",
    "# SEGMENTO: Uma classificação ainda mais granular do negócio da empresa.\n",
    "# DENOM_CIA: Esta é a denominação ou nome da empresa.\n",
    "# COMPANHIA: Nome ou denominação oficial da empresa listada.\n",
    "# PREGAO: Refere-se ao nome pelo qual a empresa é conhecida no pregão da bolsa de valores.\n",
    "# LISTAGEM: Categoria ou segmento de listagem da empresa na bolsa de valores, que pode indicar o nível de governança corporativa ou outros critérios.\n",
    "# TICK: Abreviação ou símbolo da empresa usada no mercado de ações.\n",
    "# TICKERS: Símbolos de negociação da empresa em diferentes mercados ou plataformas.\n",
    "# CD_CVM: Este poderia ser um código ou identificador único relacionado à empresa, possivelmente relacionado à Comissão de Valores Mobiliários do Brasil (CVM).\n",
    "# CVM: Código ou identificador relacionado à empresa na Comissão de Valores Mobiliários, o órgão regulador do mercado de capitais no Brasil.\n",
    "# ISIN: Número de Identificação Internacional de Valores Mobiliários – um identificador único para valores mobiliários.\n",
    "# CNPJ_CIA: Este é o número do Cadastro Nacional da Pessoa Jurídica (CNPJ) da empresa, um identificador único para empresas no Brasil.\n",
    "# CNPJ: Cadastro Nacional da Pessoa Jurídica – é o número de identificação das empresas brasileiras.\n",
    "# SITE: Site oficial ou página relevante da empresa.\n",
    "# ATIVIDADE: Descreve a principal atividade de negócios da empresa.\n",
    "\n",
    "# ANO: Este é o ano ao qual os dados se referem.\n",
    "# DT_REFER: Esta é a data de referência para a entrada de dados.\n",
    "# DT_FIM_EXERC: Esta é a data final para o exercício ou período de relato financeiro.\n",
    "# DT_INI_EXERC: Esta poderia ser a data inicial para o exercício ou período de relato financeiro.\n",
    "\n",
    "# AGRUPAMENTO: Isso descreve o nível de agregação dos dados. Por exemplo, 'con' pode indicar dados consolidados.\n",
    "# BALANCE_SHEET: Isso indica a seção específica da demonstração financeira, como Balanço Patrimonial ('BPA').\n",
    "# GRUPO_DFP: Isso representa o tipo de grupo de demonstração financeira. Por exemplo, 'DF Consolidado - Balanço Patrimonial Ativo' sugere que é um balanço patrimonial consolidado focado em ativos.\n",
    "# CD_CONTA: Este poderia ser um código ou identificador único relacionado a uma conta específica ou item de linha na demonstração financeira.\n",
    "# DS_CONTA: Descreve a conta específica ou item de linha na demonstração financeira, como 'Ativo Total'.\n",
    "\n",
    "# VL_CONTA: Representa o valor associado à conta específica ou item de linha.\n",
    "# MOEDA: Isso indica a moeda na qual os valores são representados. 'REAL' sugere Real Brasileiro.\n",
    "# ESCALA_MOEDA: Isso fornece a escala ou unidade para os valores monetários. 'MIL' pode indicar que os valores estão em milhares.\n",
    "\n",
    "# ST_CONTA_FIXA: Pode indicar o status ou tipo de conta. O significado de valores como 'S' dependeria do contexto dos dados.\n",
    "# COLUNA_DF: O propósito desta coluna não é imediatamente claro a partir da amostra. Pode representar algum tipo de classificação ou categorização relacionada aos dados financeiros.\n",
    "\n",
    "# ESCRITURADOR: Entidade ou empresa responsável por registrar ou gerenciar os valores mobiliários da empresa.\n",
    "# ACIONISTAS: Informações ou identificadores relacionados aos acionistas da empresa.\n",
    "\n",
    "# FILENAME: Este é o arquivo de onde os dados são originados. Ele fornece o nome do arquivo que contém a respectiva entrada de dados.\n",
    "# DEMONSTRATIVO: Este representa o tipo de demonstração financeira. Pode indicar se os dados são de um relatório intermediário (como 'itr') ou de outro tipo de relatório financeiro.\n",
    "# VERSAO: Isso pode representar a versão ou iteração dos dados/relatórios financeiros.\n",
    "\n",
    "columns = [\n",
    "    'SETOR_x',\n",
    "    'SUBSETOR_x',\n",
    "    'SEGMENTO_x',\n",
    "    'DENOM_CIA',\n",
    "        # 'COMPANHIA',\n",
    "    'PREGAO',\n",
    "    'LISTAGEM',\n",
    "    'TICK',\n",
    "    'TICKERS',\n",
    "    'CD_CVM',\n",
    "        # 'CVM',\n",
    "        # 'ISIN',\n",
    "    'CNPJ_CIA',\n",
    "        # 'CNPJ',\n",
    "    'SITE',\n",
    "    'ATIVIDADE',\n",
    "        # 'ANO',\n",
    "    'DT_REFER',\n",
    "        # 'DT_FIM_EXERC',\n",
    "        # 'DT_INI_EXERC',\n",
    "    'AGRUPAMENTO',\n",
    "    'BALANCE_SHEET',\n",
    "    # 'GRUPO_DFP',\n",
    "    'CD_CONTA',\n",
    "    'DS_CONTA',\n",
    "    'VL_CONTA',\n",
    "    # 'MOEDA',\n",
    "    # 'ESCALA_MOEDA',\n",
    "    # 'ST_CONTA_FIXA',\n",
    "    # 'COLUNA_DF',\n",
    "    'ESCRITURADOR',\n",
    "    'ACIONISTAS', \n",
    "    # 'FILENAME', \n",
    "    # 'DEMONSTRATIVO', \n",
    "    # 'VERSAO',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b3_cvm.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['FILENAME', 'DEMONSTRATIVO', 'BALANCE_SHEET', 'ANO', 'AGRUPAMENTO',\n",
    "       'CNPJ_CIA', 'DT_REFER', 'VERSAO', 'DENOM_CIA', 'CD_CVM', 'GRUPO_DFP',\n",
    "       'MOEDA', 'ESCALA_MOEDA', 'DT_FIM_EXERC', 'CD_CONTA', 'DS_CONTA',\n",
    "       'VL_CONTA', 'ST_CONTA_FIXA', 'DT_INI_EXERC', 'COLUNA_DF', 'COMPANHIA',\n",
    "       'PREGAO', 'TICK', 'LISTAGEM', 'TICKERS', 'ISIN', \n",
    "       'ATIVIDADE', 'SETOR', 'SUBSETOR', 'SEGMENTO', 'SITE', 'ESCRITURADOR',]\n",
    "df = b3_cvm['CONSUMO CICLICO'][columns].set_index('DT_REFER')\n",
    "df = convert_columns(df)\n",
    "df['DENOM_CIA'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acoes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acoes = run.load_pkl(f'{b3.app_folder}acoes')\n",
    "# Process the data and return the result\n",
    "acoes['Trimestre'] = pd.to_datetime(acoes['Trimestre'], errors='coerce', dayfirst=True)\n",
    "acoes['BALANCE_SHEET'] = 'STK'\n",
    "column_mapping = {\n",
    "    'Ações ON': '00.01.01',\n",
    "    'Ações PN': '00.02.01',\n",
    "    'Ações ON em Tesouraria': '00.01.02',\n",
    "    'Ações PN em Tesouraria': '00.02.02'\n",
    "}\n",
    "acoes = acoes.rename(columns={\"Companhia\": \"DENOM_CIA\", \"Trimestre\": \"DT_REFER\"})\n",
    "\n",
    "acoes = acoes.melt(id_vars=['DENOM_CIA', 'DT_REFER', 'BALANCE_SHEET'], \n",
    "                        value_vars=['Ações ON', 'Ações PN', 'Ações ON em Tesouraria', 'Ações PN em Tesouraria'],\n",
    "                        var_name='DS_CONTA', value_name='VL_CONTA').sort_values(by=['DENOM_CIA', 'DT_REFER', 'DS_CONTA'])\n",
    "\n",
    "acoes['CD_CONTA'] = acoes['DS_CONTA'].map(column_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intel_b3 = run.load_pkl(f'{b3.app_folder}intel_b3')\n",
    "df = intel_b3['BENS INDUSTRIAIS']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company = 'ARMAC LOCACAO LOGISTICA E SERVICOS SA'\n",
    "quarter = '2019-12-31'\n",
    "mc = acoes['DENOM_CIA'] == company\n",
    "mc &= acoes['DT_REFER'] == quarter\n",
    "acoesc = acoes[mc]\n",
    "\n",
    "mc = df['DENOM_CIA'] == company\n",
    "mc &= df['DT_REFER'] == quarter\n",
    "dfc = df[mc]\n",
    "\n",
    "df_ffill = pd.concat([dfc, acoesc], ignore_index=True).ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_stock_data(group):\n",
    "    company, quarter = group.name\n",
    "    \n",
    "    # Filter acoes based on company and quarter\n",
    "    mc = acoes['DENOM_CIA'] == company\n",
    "    mc &= acoes['DT_REFER'] == quarter\n",
    "    acoesc = acoes[mc]\n",
    "\n",
    "    # Concatenate and ffill\n",
    "    return pd.concat([group, acoesc], ignore_index=True).ffill()\n",
    "\n",
    "result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_ffill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intelacoes = {}\n",
    "for setor, df in intel_b3.items():\n",
    "    print(setor)\n",
    "    df_concat = pd.concat([df.set_index(['DENOM_CIA', 'DT_REFER']), acoes.set_index(['DENOM_CIA', 'DT_REFER'])], axis=0, sort=False).reset_index()\n",
    "    filled_df = df_concat.groupby(['DENOM_CIA', 'DT_REFER'], group_keys=False).apply(lambda group: group.ffill().bfill()).reset_index()\n",
    "    intelacoes[setor] = filled_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate them vertically\n",
    "df_concat = pd.concat([df.set_index(['DENOM_CIA', 'DT_REFER']), acoes.set_index(['DENOM_CIA', 'DT_REFER'])], axis=0, sort=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_df = df_concat.groupby(['DENOM_CIA', 'DT_REFER'], group_keys=False).apply(lambda group: group.ffill().bfill()).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = filled_df['DENOM_CIA'] == 'ARMAC LOCACAO LOGISTICA E SERVICOS SA'\n",
    "m &= filled_df['DT_REFER'] == '2019-12-31'\n",
    "m &= filled_df['BALANCE_SHEET'] == 'STK'\n",
    "\n",
    "filled_df[m][cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b3_cvm = run.load_pkl(f'{b3.app_folder}b3_cvm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_types = {'index': 'int',\n",
    " 'FILENAME': 'category',\n",
    " 'DEMONSTRATIVO': 'category',\n",
    " 'BALANCE_SHEET': 'category',\n",
    " 'ANO': 'category',\n",
    " 'AGRUPAMENTO': 'category',\n",
    " 'CNPJ_CIA': 'category',\n",
    " 'DT_REFER': 'object',\n",
    " 'VERSAO': 'category',\n",
    " 'DENOM_CIA': 'category',\n",
    " 'CD_CVM': 'category',\n",
    " 'GRUPO_DFP': 'category',\n",
    " 'MOEDA': 'category',\n",
    " 'ESCALA_MOEDA': 'category',\n",
    " 'DT_FIM_EXERC': 'object',\n",
    " 'CD_CONTA': 'category',\n",
    " 'DS_CONTA': 'category',\n",
    " 'VL_CONTA': 'float',\n",
    " 'ST_CONTA_FIXA': 'category',\n",
    " 'DT_INI_EXERC': 'object',\n",
    " 'COLUNA_DF': 'category',\n",
    " 'COMPANHIA': 'category',\n",
    " 'PREGAO': 'category',\n",
    " 'TICK': 'category',\n",
    " 'LISTAGEM': 'category',\n",
    " 'CVM': 'category',\n",
    " 'TICKERS': 'category',\n",
    " 'ISIN': 'category',\n",
    " 'CNPJ': 'category',\n",
    " 'ATIVIDADE': 'category',\n",
    " 'SETOR': 'category',\n",
    " 'SUBSETOR': 'category',\n",
    " 'SEGMENTO': 'category',\n",
    " 'SITE': 'category',\n",
    " 'ESCRITURADOR': 'category',\n",
    " 'CD_CONTA_original': 'category',\n",
    " 'DS_CONTA_original': 'category'}\n",
    "date_columns = ['DT_REFER', 'DT_FIM_EXERC', 'DT_INI_EXERC']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('BENS INDUSTRIAIS_intel.csv', dtype=column_types, index_col='Unnamed: 0', parse_dates=True)\n",
    "# df = pd.read_csv('COMUNICACOES_df.csv')\n",
    "# df_typed = pd.read_csv(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um dicionário onde as chaves são os nomes das colunas e os valores são os valores únicos para cada coluna\n",
    "col_dict = {col: df[col].unique().tolist() for col in df.columns}\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_dict['BALANCE_SHEET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['CNPJ_CIA', 'DENOM_CIA', 'DT_REFER', 'CD_CONTA', 'DS_CONTA', 'VL_CONTA', 'SETOR', 'SUBSETOR', 'SEGMENTO', 'DT_INI_EXERC', 'ATIVIDADE', 'SITE', 'ESCRITURADOR', 'FILENAME', 'DEMONSTRATIVO', 'BALANCE_SHEET', 'ANO', 'AGRUPAMENTO', 'VERSAO', 'GRUPO_DFP', 'MOEDA', 'ESCALA_MOEDA', 'ST_CONTA_FIXA', 'COLUNA_DF', 'COMPANHIA', 'TICKERS', 'CVM', 'ISIN', 'DT_FIM_EXERC', ]]\n",
    "# 'PREGAO', 'TICK', 'CD_CVM', 'LISTAGEM', # 'CD_CONTA_original', 'DS_CONTA_original', \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formulas_old = [\n",
    "    # Relações Entre Ativos e Passivos\n",
    "    ('_020302_reservas_de_capital', '_020303_reservas_de_reavaliacao', '_020304_reservas_de_lucros'),\n",
    "    # Dívida\n",
    "    ('_0201040101_emprestimos_e_financiamentos_em_moeda_nacional', '_0201040102_emprestimos_e_financiamentos_em_moeda_estrangeira', '_02010402_debentures', '_02010403_arrendamentos', '_02010409_outros_emprestimos_financiamentos_e_debentures'),\n",
    "    ('_0202010101_emprestimos_e_financiamentos_em_moeda_nacional', '_0202010102_emprestimos_e_financiamentos_em_moeda_estrangeira', '_02020102_debentures', '_02020103_arrendamentos', '_02020209_outros_emprestimos_financiamentos_e_debentures'),\n",
    "    ('_0201040102_emprestimos_e_financiamentos_em_moeda_estrangeira', '_0202010102_emprestimos_e_financiamentos_em_moeda_estrangeira'),\n",
    "    ('_010101_caixa_e_disponibilidades_de_caixa',),\n",
    "    ('_010202_investimentos_nao_capex', '_010203_imobilizados', '_010204_intangivel'),\n",
    "    ('_0305_lajir_ebit_resultado_antes_do_resultado_financeiro_e_dos_tributos', '_070401_depreciacao_e_amortizacao'),\n",
    "    # Resultados Fundamentalistas\n",
    "    ('_0203_patrimonio_liquido',),\n",
    "    ('_010101_caixa_e_disponibilidades_de_caixa',),\n",
    "    ('_070803_remuneracao_de_capital_de_terceiros', '_070804_remuneracao_de_capital_proprio'),\n",
    "    # Análise do Fluxo de Caixa\n",
    "    ('_0601_caixa_das_operacoes', '_0602_caixa_de_investimentos_capex'),\n",
    "    ('_0603_caixa_de_financiamento',),\n",
    "    ('_060201_investimentos', '_060202_imobilizado_e_intangivel'),\n",
    "]\n",
    "\n",
    "def de_transform_corrected(key):\n",
    "    # Strip the leading underscore and split at the first underscore\n",
    "    parts = key[1:].split('_', 1)\n",
    "\n",
    "    # Adjust code by inserting periods every two characters\n",
    "    code = '.'.join([parts[0][i:i+2] for i in range(0, len(parts[0]), 2)])\n",
    "    \n",
    "    # Adjust description capitalization\n",
    "    description = ' '.join([word.capitalize() if word not in ['e', 'de', 'do', 'dos', 'da', 'das', 'em'] else word.lower() for word in parts[1].split('_')])\n",
    "    \n",
    "    return code, description\n",
    "\n",
    "# De-transform the formulas using the corrected function\n",
    "formulas = []\n",
    "for group in formulas_old:\n",
    "    new_group = []\n",
    "    for key in group:\n",
    "        new_group.append(de_transform_corrected(key))\n",
    "    formulas.append(tuple(new_group))\n",
    "\n",
    "formulas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_sheet = df.groupby(['CNPJ_CIA', 'DT_REFER'], group_keys=True)\n",
    "balance_sheet.groups.keys()\n",
    "df_ = balance_sheet.get_group(('00.242.184/0001-04', '2019-12-31'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (, 'Emprestimos e Financiamentos em Moeda Estrangeira'),\n",
    "m = df['CD_CONTA'] == '07.08.04'\n",
    "df[m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dados Abertos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(file):\n",
    "    path = \"C:\\\\Users\\\\faust\\\\OneDrive\\\\Área de Trabalho\\\\dados abertos\\\\\"\n",
    "    df = pd.read_csv(path+file+\".csv\", sep=';', encoding='latin1')\n",
    "    return df.head(25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fca_cia_aberta_2010\"\n",
    "fca_cia_aberta_2010 = read(file)\n",
    "# link para o NSD do formulário cadastral\n",
    "fca_cia_aberta_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fca_cia_aberta_auditor_2010\"\n",
    "fca_cia_aberta_auditor_2010 = read(file)\n",
    "# informações dos auditores CNPJ e CPF, datas dos auditores CPF\n",
    "fca_cia_aberta_auditor_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fca_cia_aberta_canal_divulgacao_2010\"\n",
    "fca_cia_aberta_canal_divulgacao_2010 = read(file)\n",
    "# Onde as DRE são divulgadas\n",
    "fca_cia_aberta_canal_divulgacao_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fca_cia_aberta_departamento_acionistas_2010\"\n",
    "fca_cia_aberta_departamento_acionistas_2010 = read(file)\n",
    "# Endereços dos DRI\n",
    "fca_cia_aberta_departamento_acionistas_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fca_cia_aberta_dri_2010\"\n",
    "fca_cia_aberta_dri_2010 = read(file)\n",
    "# NOMES e endereços dos DRI\n",
    "fca_cia_aberta_dri_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fca_cia_aberta_endereco_2010\"\n",
    "fca_cia_aberta_endereco_2010 = read(file)\n",
    "# Endereço completo do DRI\n",
    "fca_cia_aberta_endereco_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fca_cia_aberta_geral_2010\"\n",
    "fca_cia_aberta_geral_2010 = read(file)\n",
    "# Cadastro CVM, Atividade, Descrição e Controle Acionário\n",
    "fca_cia_aberta_geral_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fca_cia_aberta_pais_estrangeiro_negociacao_2010\"\n",
    "fca_cia_aberta_pais_estrangeiro_negociacao_2010 = read(file)\n",
    "# País estrangeiro... ?\n",
    "fca_cia_aberta_pais_estrangeiro_negociacao_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fca_cia_aberta_valor_mobiliario_2010\"\n",
    "fca_cia_aberta_valor_mobiliario_2010 = read(file)\n",
    "# Valor mobiliário, Mercado e Segmento\n",
    "fca_cia_aberta_valor_mobiliario_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_2023\"\n",
    "fre_cia_aberta_2023 = read(file)\n",
    "# Link do Documento\n",
    "fre_cia_aberta_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_acao_entregue_2023\"\n",
    "fre_cia_aberta_acao_entregue_2023 = read(file)\n",
    "# Remuneração da Diretoria\n",
    "fre_cia_aberta_acao_entregue_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_administrador_declaracao_genero_2023\"\n",
    "fre_cia_aberta_administrador_declaracao_genero_2023 = read(file)\n",
    "# Gênero dos administradores\n",
    "fre_cia_aberta_administrador_declaracao_genero_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_administrador_declaracao_raca_2023\"\n",
    "fre_cia_aberta_administrador_declaracao_raca_2023 = read(file)\n",
    "# Raça dos administradores\n",
    "fre_cia_aberta_administrador_declaracao_raca_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_administrador_membro_conselho_fiscal_2023\"\n",
    "fre_cia_aberta_administrador_membro_conselho_fiscal_2023 = read(file)\n",
    "# Membros do Conselho Fiscal\n",
    "fre_cia_aberta_administrador_membro_conselho_fiscal_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_ativo_imobilizado_2023\"\n",
    "fre_cia_aberta_ativo_imobilizado_2023 = read(file)\n",
    "# Ativos e Propriedades por empresa\n",
    "fre_cia_aberta_ativo_imobilizado_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_ativo_intangivel_2023\"\n",
    "fre_cia_aberta_ativo_intangivel_2023 = read(file)\n",
    "# Ativos e Propriedades por empresa\n",
    "fre_cia_aberta_ativo_intangivel_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_auditor_2023\"\n",
    "fre_cia_aberta_auditor_2023 = read(file)\n",
    "# Remuneração por auditor\n",
    "fre_cia_aberta_auditor_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_auditor_responsavel_2023\"\n",
    "fre_cia_aberta_auditor_responsavel_2023 = read(file)\n",
    "# Endereço do Auditor\n",
    "fre_cia_aberta_auditor_responsavel_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_capital_social_2023\"\n",
    "fre_cia_aberta_capital_social_2023 = read(file)\n",
    "# Modificações no Capital Social e Ações\n",
    "fre_cia_aberta_capital_social_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_capital_social_aumento_2023\"\n",
    "fre_cia_aberta_capital_social_aumento_2023 = read(file)\n",
    "# Idem\n",
    "fre_cia_aberta_capital_social_aumento_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_capital_social_aumento_classe_acao_2023\"\n",
    "fre_cia_aberta_capital_social_aumento_classe_acao_2023 = read(file)\n",
    "# Em branco\n",
    "fre_cia_aberta_capital_social_aumento_classe_acao_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_capital_social_classe_acao_2023\"\n",
    "fre_cia_aberta_capital_social_classe_acao_2023 = read(file)\n",
    "# Preferencial Classe A, B e C\n",
    "fre_cia_aberta_capital_social_classe_acao_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_capital_social_desdobramento_2023\"\n",
    "fre_cia_aberta_capital_social_desdobramento_2023 = read(file)\n",
    "# Desdobramentos de Ações\n",
    "fre_cia_aberta_capital_social_desdobramento_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_capital_social_desdobramento_classe_acao_2023\"\n",
    "fre_cia_aberta_capital_social_desdobramento_classe_acao_2023 = read(file)\n",
    "# em branco\n",
    "fre_cia_aberta_capital_social_desdobramento_classe_acao_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_capital_social_reducao_2023\"\n",
    "fre_cia_aberta_capital_social_reducao_2023 = read(file)\n",
    "# Redução de capital\n",
    "fre_cia_aberta_capital_social_reducao_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_capital_social_titulo_conversivel_2023\"\n",
    "fre_cia_aberta_capital_social_titulo_conversivel_2023 = read(file)\n",
    "# Redução de capital\n",
    "fre_cia_aberta_capital_social_titulo_conversivel_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_direito_acao_2023\"\n",
    "fre_cia_aberta_direito_acao_2023 = read(file)\n",
    "# ?\n",
    "fre_cia_aberta_direito_acao_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_historico_emissor_2023\"\n",
    "fre_cia_aberta_historico_emissor_2023 = read(file)\n",
    "# Constituição do emissor e local\n",
    "fre_cia_aberta_historico_emissor_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_informacao_financeira_2023\"\n",
    "fre_cia_aberta_informacao_financeira_2023 = read(file)\n",
    "# DRE Resumido\n",
    "fre_cia_aberta_informacao_financeira_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_membro_comite_2023\"\n",
    "fre_cia_aberta_membro_comite_2023 = read(file)\n",
    "# CPF e Remuneração\n",
    "fre_cia_aberta_membro_comite_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_obrigacao_2023\"\n",
    "fre_cia_aberta_obrigacao_2023 = read(file)\n",
    "# Obrigações e Dívidas\n",
    "fre_cia_aberta_obrigacao_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_outro_valor_mobiliario_2023\"\n",
    "fre_cia_aberta_outro_valor_mobiliario_2023 = read(file)\n",
    "# ?\n",
    "fre_cia_aberta_outro_valor_mobiliario_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_participacao_sociedade_2023\"\n",
    "fre_cia_aberta_participacao_sociedade_2023 = read(file)\n",
    "# Participações em outras empresas\n",
    "fre_cia_aberta_participacao_sociedade_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_participacao_sociedade_valorizacao_acao_2023\"\n",
    "fre_cia_aberta_participacao_sociedade_valorizacao_acao_2023 = read(file)\n",
    "# ?\n",
    "fre_cia_aberta_participacao_sociedade_valorizacao_acao_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_posicao_acionaria_2023\"\n",
    "fre_cia_aberta_posicao_acionaria_2023 = read(file)\n",
    "# Composição acionária por acionista majoritário\n",
    "fre_cia_aberta_posicao_acionaria_2023[['CNPJ_Companhia', 'Data_Referencia', 'Versao', 'ID_Documento',\n",
    "       'ID_Acionista', 'Acionista', 'Tipo_Pessoa_Acionista',\n",
    "       'CPF_CNPJ_Acionista', 'ID_Acionista_Relacionado',\n",
    "       'Acionista_Relacionado', 'Tipo_Pessoa_Acionista_Relacionado',\n",
    "       'CPF_CNPJ_Acionista_Relacionado',\n",
    "       'Quantidade_Acao_Ordinaria_Circulacao',\n",
    "       'Percentual_Acao_Ordinaria_Circulacao',\n",
    "       'Quantidade_Acao_Preferencial_Circulacao',\n",
    "       'Percentual_Acao_Preferencial_Circulacao',\n",
    "       'Quantidade_Total_Acoes_Circulacao',\n",
    "       'Percentual_Total_Acoes_Circulacao', ]]\n",
    "# fre_cia_aberta_posicao_acionaria_2023.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_relacao_familiar_2023\"\n",
    "fre_cia_aberta_relacao_familiar_2023 = read(file)\n",
    "# Parentescos\n",
    "fre_cia_aberta_relacao_familiar_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_relacao_subordinacao_2023\"\n",
    "fre_cia_aberta_relacao_subordinacao_2023 = read(file)\n",
    "# Subordnicação \n",
    "fre_cia_aberta_relacao_subordinacao_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_transacao_parte_relacionada_2023\"\n",
    "fre_cia_aberta_transacao_parte_relacionada_2023 = read(file)\n",
    "# Partes relacionadas\n",
    "fre_cia_aberta_transacao_parte_relacionada_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_2023\"\n",
    "fre_cia_aberta_2023 = read(file)\n",
    "# Link do Documento\n",
    "fre_cia_aberta_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_group(cias_por_setor, window):\n",
    "    for company, group_df in cias_por_setor:\n",
    "        try:\n",
    "            # Calculate the moving average for the last 4 periods\n",
    "            group_df['MA'] = group_df['VL_CONTA'].rolling(window=window).mean()\n",
    "            \n",
    "            # Calculate the rolling sum for the last 4 periods\n",
    "            group_df['Rolling_Sum'] = group_df['VL_CONTA'].rolling(window=window).sum()\n",
    "            \n",
    "            # Calculate the lifelong cumulative sum\n",
    "            group_df['Cumulative_Sum'] = group_df['VL_CONTA'].cumsum()\n",
    "            \n",
    "            # Plot raw data\n",
    "            # group_df['VL_CONTA'].plot(label='Raw Data', legend=True)\n",
    "\n",
    "            # Plot moving average\n",
    "            group_df['MA'].plot(label=f'{window} Quarters Moving Average', legend=True, linestyle='--')\n",
    "            \n",
    "            # Plot rolling sum\n",
    "            group_df['Rolling_Sum'].plot(label=f'{window} Quarters Sum', legend=True, linestyle='-.')\n",
    "            \n",
    "            # Plot lifelong cumulative sum\n",
    "            group_df['Cumulative_Sum'].plot(label='Lifelong Cumulative Sum', legend=True, linestyle='-.')\n",
    "\n",
    "            plt.title(f\"{group_df['CD_CVM'].iloc[-1]} {group_df['DENOM_CIA'].iloc[-1]}\")\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"Error plotting for {company}: {e}\")\n",
    "    return True\n",
    "\n",
    "cias_por_setor = df[(df['AGRUPAMENTO'] == 'con') & (df['CD_CONTA'] == '3.11')].groupby('CD_CVM')\n",
    "plot_group(cias_por_setor, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cias_por_setor = df[(df['AGRUPAMENTO'] == 'con') & (df['CD_CONTA'] == '2.03')].groupby('DENOM_CIA')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "for company, group_df in cias_por_setor:\n",
    "    try:\n",
    "        group_df[['VL_CONTA']].plot(ax=ax, label=company)\n",
    "    except:\n",
    "        print(company)\n",
    "\n",
    "ax.set_title(\"VL_CONTA by Company\")\n",
    "ax.set_ylabel(\"VL_CONTA\")\n",
    "ax.set_xlabel(\"Index\")\n",
    "ax.legend(loc=\"best\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intelacoes Fundamentalista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intelacoes = run.load_pkl(f'{b3.app_folder}intelacoes')\n",
    "intelacoes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('BENS INDUSTRIAIS_intelacoes.pkl')\n",
    "# df.to_csv('BENS INDUSTRIAIS_intelacoes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Unnamed: 0', 'FILENAME', 'DEMONSTRATIVO', 'BALANCE_SHEET', 'ANO',\n",
    "       'AGRUPAMENTO', 'CNPJ_CIA', 'DT_REFER', 'VERSAO', 'DENOM_CIA', 'CD_CVM',\n",
    "       'GRUPO_DFP', 'MOEDA', 'ESCALA_MOEDA', 'DT_FIM_EXERC', 'CD_CONTA',\n",
    "       'DS_CONTA', 'VL_CONTA', 'ST_CONTA_FIXA', 'DT_INI_EXERC', 'COLUNA_DF',\n",
    "       'COMPANHIA', 'PREGAO', 'TICK', 'LISTAGEM', 'CVM', 'TICKERS', 'ISIN',\n",
    "       'CNPJ', 'ATIVIDADE', 'SETOR', 'SUBSETOR', 'SEGMENTO', 'SITE',\n",
    "       'ESCRITURADOR', 'CD_CONTA_original', 'DS_CONTA_original', 'Companhia',\n",
    "       'Trimestre', 'Ações ON', 'Ações PN', 'Ações ON em Tesouraria',\n",
    "       'Ações PN em Tesouraria', 'URL']\n",
    "cols = ['SETOR', 'SUBSETOR', 'SEGMENTO', 'CNPJ_CIA', 'DENOM_CIA', 'CD_CVM',  'PREGAO', 'TICK', 'LISTAGEM', 'TICKERS', 'DT_REFER', 'BALANCE_SHEET', 'CD_CONTA', 'DS_CONTA', 'VL_CONTA', ]\n",
    "datetime_cols = ['DT_REFER', 'DT_FIM_EXERC', 'DT_INI_EXERC', 'Trimestre']\n",
    "company_cols = ['SETOR', 'SUBSETOR', 'SEGMENTO', 'CNPJ_CIA', 'DENOM_CIA', 'CD_CVM']\n",
    "dateseries_col = ['DT_REFER']\n",
    "sheet_cols = ['BALANCE_SHEET', 'CD_CONTA', 'DS_CONTA', 'VL_CONTA']\n",
    "stocks_cols = ['Ações ON', 'Ações PN', 'Ações ON em Tesouraria', 'Ações PN em Tesouraria']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by 'SETOR', 'SUBSETOR', and 'SEGMENTO' to count unique companies and aggregate their TICK values\n",
    "ticks_by_setor = df.groupby(['SETOR', 'SUBSETOR', 'SEGMENTO']).agg({\n",
    "    'DENOM_CIA': 'nunique',\n",
    "    'TICK': lambda x: list(set(x.dropna()))\n",
    "}).reset_index()\n",
    "\n",
    "# Renaming columns for clarity\n",
    "ticks_by_setor.rename(columns={'DENOM_CIA': 'TOTAL DE COMPANHIAS'}, inplace=True)\n",
    "\n",
    "ticks_by_setor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conta = '02.03'\n",
    "\n",
    "# Filtering the data for the account 'CD_CONTA' with value '02.03' and the latest quarter\n",
    "conta_by_setor = df[df['DT_REFER'] == df['DT_REFER'].max()]\n",
    "conta_by_setor = conta_by_setor[conta_by_setor['CD_CONTA'] == conta]\n",
    "\n",
    "# Grouping by 'SETOR', 'SUBSETOR', and 'SEGMENTO' to aggregate 'VL_CONTA' values\n",
    "conta_by_setor = conta_by_setor.groupby(['SETOR', 'SUBSETOR', 'SEGMENTO', ]).agg({\n",
    "    'VL_CONTA': ['nunique', 'sum', 'max', 'min', 'mean', 'std', 'skew', lambda x: x.kurt()]\n",
    "}).reset_index()\n",
    "\n",
    "conta_by_setor.rename(columns={'VL_CONTA': conta}, inplace=True)\n",
    "\n",
    "conta_by_setor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = df\n",
    "# dfc = dfc.set_index('DT_REFER')\n",
    "company = 'WEG SA'\n",
    "quarter = '2020-12-31'\n",
    "conta = '01.01.01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = dfc['DENOM_CIA'] != 'nothing'\n",
    "mask &= dfc['DT_REFER'] == quarter\n",
    "mask &= dfc['DENOM_CIA'] == company\n",
    "# mask &= dfc['PREGAO'] == ''\n",
    "# mask &= dfc['TICK'] == ''\n",
    "# mask &= dfc['BALANCE_SHEET'] == ''\n",
    "mask &= dfc['CD_CONTA'] == conta\n",
    "# mask &= dfc['DS_CONTA'] == ''\n",
    "\n",
    "# dfc[mask][cols]\n",
    "data = dfc[mask][['DENOM_CIA', 'DT_REFER', 'CD_CONTA', 'DS_CONTA', 'VL_CONTA']].set_index('DT_REFER')\n",
    "sheet = df[(df['DENOM_CIA'] == company) & (df['DT_REFER'] == quarter)]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = pd.concat([dfc, rows], ignore_index=True).ffill().drop_duplicates()\n",
    "m = dfc['BALANCE_SHEET'].isin(sh)\n",
    "dfc[m][cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fund"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund = load_pkl(f'{b3.app_folder}fund')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('BENS INDUSTRIAIS_fund.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('BENS INDUSTRIAIS_fund.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TICKERS'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Macro Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install yfinance -q -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baixando Cotações do Índice Bovespa\n",
    "ibov = yf.download('^BVSP')\n",
    "df = yf.download(['WEGE3.SA','BBDC4.SA', 'PETR4.SA'], group_by='ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df['WEGE3.SA']['Adj Close']))\n",
    "tickers = df.columns.get_level_values(0).unique().tolist()\n",
    "tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tick in tickers:\n",
    "    df[tick]['Adj Close'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q alpha_vantage\n",
    "# Importando a classe Timeseries de alpha_vantage.timeseries\n",
    "from alpha_vantage.timeseries import TimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHAVANTAGE_API_KEY = 'KR3OMFL1CLANZUXP'\n",
    "# Criando o objeto ts\n",
    "ts = TimeSeries(key=ALPHAVANTAGE_API_KEY, output_format='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados, meta_dados = ts.get_symbol_search('alphabet')\n",
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtendo os dados semanais do IBOV usando get_weekly\n",
    "dados, meta_dados = ts.get_daily(symbol='AAPL', )\n",
    "dados['4. close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install quandl -q -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quandl\n",
    "mydata = quandl.get(\"FRED/GDP\")\n",
    "api = 'LpAz8JCUosdwhHqnWnA4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = quandl.get_table('ZACKS/FC', ticker='AAPL',)\n",
    "mydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas datareader\n",
    "import os\n",
    "import pandas_datareader as pdr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIINGO_API_KEY = '591375a6e5852ca48f778902fec322581511c89a'\n",
    "import tiingo\n",
    "\n",
    "config = {}\n",
    "config['session'] = True\n",
    "config['api_key'] = TIINGO_API_KEY\n",
    "client = tiingo.TiingoClient(config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "TIINGO_API_KEY = '591375a6e5852ca48f778902fec322581511c89a'\n",
    "url = 'https://api.tiingo.com/tiingo/fundamentals/definitions'\n",
    "url = 'https://api.tiingo.com/tiingo/daily/AAPL/prices?startDate=2012-1-1'\n",
    "# url = 'https://api.tiingo.com/tiingo/daily/AAPL/prices'\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': 'Token ' + TIINGO_API_KEY\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "data = response.json()\n",
    "data = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['close'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pdr.DataReader('GE', 'yahoo')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Yahoo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iterrow in fund and get same key from both dict to concat both and remove duplicates\n",
    "\n",
    "save quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get BCB Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.alert import Alert\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromedriver_path = \"D:\\\\Fausto Stangler\\\\Documentos\\\\Python\\\\DSH\\\\chromedriver-win64\\\\chromedriver.exe\"\n",
    "driver_wait_time = 5\n",
    "\n",
    "driver, wait = run.load_browser(chromedriver_path, driver_wait_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_bcb = 'https://www3.bcb.gov.br/sgspub/'\n",
    "url_bcb = 'https://www3.bcb.gov.br/sgspub/localizarseries/localizarSeries.do?method=prepararTelaPesquisaAvancada'\n",
    "\n",
    "driver.get(url_bcb)\n",
    "\n",
    "try:\n",
    "    alert = Alert(driver)\n",
    "    alert.accept()\n",
    "except Exception as e:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "element_xpath = '/html/body/table[1]/tbody/tr/td[3]/a'\n",
    "element = wait.until(EC.presence_of_element_located((By.XPATH, element_xpath)))\n",
    "# Get elements in Português\n",
    "if 'Português' in element.text.splitlines():\n",
    "    element.click()\n",
    "# # Get elements in English\n",
    "# if 'English' in element.text.splitlines():\n",
    "#     element.click()\n",
    "\n",
    "# Click on the first element\n",
    "element = wait.until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"tabLCS\"]/tbody/tr/td[1]/table/tbody/tr[12]/td')))\n",
    "element.click()\n",
    "\n",
    "# Switch to the iframe\n",
    "iframe_id = 'iCorpo'\n",
    "wait.until(EC.frame_to_be_available_and_switch_to_it((By.ID, iframe_id)))\n",
    "\n",
    "# Click on the second element\n",
    "element = wait.until(EC.element_to_be_clickable((By.XPATH, '/html/body/center/form/table[1]/tbody/tr[5]/td[2]/input')))\n",
    "element.click()\n",
    "\n",
    "# Click on the third element\n",
    "element = wait.until(EC.element_to_be_clickable((By.XPATH, '/html/body/center/form/input[9]')))\n",
    "element.click()\n",
    "\n",
    "# Grab the number of items for pagination\n",
    "pagination_xpath = '/html/body/form/span[1]/span[1]/b'\n",
    "num_items = int(wait.until(EC.presence_of_element_located((By.XPATH, pagination_xpath))).text)\n",
    "\n",
    "# Read the table\n",
    "table_xpath = '//*[@id=\"tabelaSeries\"]'  # or '//*[@id=\"tabelaConjunto\"]'\n",
    "table_html = wait.until(EC.presence_of_element_located((By.XPATH, table_xpath))).get_attribute('outerHTML')\n",
    "df = pd.read_html(table_html)[0]\n",
    "\n",
    "# Determine the number of pages for pagination (assuming 10 items per page)\n",
    "items_per_page = len(df)  # Adjust as per actual items per page\n",
    "num_pages = -(-num_items // items_per_page)  # Ceiling division\n",
    "items_per_page, num_pages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the pages and extract data\n",
    "start_time = run.time.time()\n",
    "for i, page_number in enumerate(range(num_pages - 1)):  # Already have data for first page\n",
    "        # Execute the JavaScript function for pagination\n",
    "    driver.execute_script(f'getPagina({page_number})')\n",
    "    \n",
    "    # Read the table on the new page\n",
    "    table_html = wait.until(EC.presence_of_element_located((By.XPATH, table_xpath))).get_attribute('outerHTML')\n",
    "    new_df = pd.read_html(table_html)[0]\n",
    "    \n",
    "    # Loop through each row of the new data\n",
    "    for _, row in new_df.iterrows():\n",
    "        # Extract the relevant parameter for JavaScript function from the row\n",
    "        series = row['Cód.']  # replace 'YourColumnName' with the actual column name\n",
    "        \n",
    "        # Execute the JavaScript function\n",
    "        driver.execute_script(f\"parent.pesquisarPorDocn('../localizarseries/localizarSeries.do?method=recuperarMetadadosPorDocn', '{series}', 'Dados básicos/Metadados');\")\n",
    "        print('grab the table xpath and save into new_df')\n",
    "        # Grab the data you need after executing the JavaScript\n",
    "        # Your code for grabbing data goes here...\n",
    "        \n",
    "        # NOTE: Be sure to implement appropriate waiting and checking for elements to ensure data is loaded before you try to grab it.\n",
    "\n",
    "    # Append the new data to the existing dataframe\n",
    "    df = pd.concat([df, new_df], ignore_index=True)\n",
    "    print(run.remaining_time(start_time, (num_pages - 1), i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get each series data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integrate fund to quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrate funds to quotes, so each TICK contains quotes and also also all financial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = run.load_pkl(f'{b3.app_folder}quotes')\n",
    "fund = run.load_pkl(f'{b3.app_folder}fund')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes.keys(), quotes['AERIS'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdata = []\n",
    "for pregao, d in quotes.items():\n",
    "    for ticker, df in d.items():\n",
    "        try:\n",
    "            df.insert(0, 'PREGAO', pregao)\n",
    "        except Exception as e:\n",
    "            df['PREGAO'] = pregao  # Update 'PREGAO' column\n",
    "        \n",
    "        try:\n",
    "            df['TICKER'] = ticker  # Update 'TICKER' column\n",
    "        except Exception as e:\n",
    "            df.insert(1, 'TICKER', ticker)\n",
    "\n",
    "        bigdata.append(df)\n",
    "bigdata = pd.concat(bigdata, ignore_index=False)\n",
    "bigdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data subset\n",
    "df_fund = fund['BENS INDUSTRIAIS']\n",
    "\n",
    "# Data preprocessing\n",
    "# Convert specific columns to object type\n",
    "df_fund[['VERSAO', 'CD_CVM']] = df_fund[['VERSAO', 'CD_CVM']].astype('object')\n",
    "\n",
    "# Convert 'DT_REFER' to datetime format\n",
    "df_fund['DT_REFER'] = pd.to_datetime(df_fund['DT_REFER'])\n",
    "\n",
    "# Pivot for CD_CONTA\n",
    "df_cd_conta = df_fund.pivot_table(index=['DT_REFER', 'PREGAO'], \n",
    "                                  columns=['CD_CONTA', 'DS_CONTA'], \n",
    "                                  values='VL_CONTA', \n",
    "                                  aggfunc='sum').reset_index()\n",
    "\n",
    "# Flatten the multi-level columns after pivot\n",
    "df_cd_conta.columns = [' - '.join(col).strip(' - ') for col in df_cd_conta.columns.values]\n",
    "\n",
    "# Extract unique combinations of DT_REFER and PREGAO without the account details and get an unique mapping between the dates, PREGAO, and the pivoted account data.\n",
    "df_unique = df_fund.reset_index(drop=True).drop_duplicates(subset=['DT_REFER', 'PREGAO']).drop(['CD_CONTA', 'DS_CONTA', 'VL_CONTA'], axis=1)\n",
    "df_merged = pd.merge(df_unique, df_cd_conta, on=['DT_REFER', 'PREGAO'])\n",
    "\n",
    "# Set index and handle missing values\n",
    "df_merged = df_merged.set_index(['DT_REFER', 'PREGAO'], drop=True)\n",
    "\n",
    "# Group by 'PREGAO' and apply resampling\n",
    "df_resampled = (\n",
    "    df_merged\n",
    "    .reset_index()\n",
    "    .groupby('PREGAO')\n",
    "    .apply(lambda group: group.set_index('DT_REFER').resample('D').asfreq().ffill().bfill().fillna(0))\n",
    "    .drop('PREGAO', axis=1)  # Drop the redundant 'PREGAO' column introduced by `groupby`\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdata = bigdata.reset_index()\n",
    "bigdata['Date'] = pd.to_datetime(bigdata['Date'])\n",
    "df_resampled = df_resampled.reset_index()\n",
    "df_resampled['DT_REFER'] = pd.to_datetime(df_resampled['DT_REFER'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Get unique PREGAO values from df_resampled\n",
    "companies = df_resampled['PREGAO'].unique()\n",
    "\n",
    "# Step 2: Filter bigdata\n",
    "filtered_bigdata = bigdata[bigdata['PREGAO'].isin(companies)]\n",
    "\n",
    "df_merged = pd.merge(filtered_bigdata, df_resampled, left_on=['Date', 'PREGAO'], right_on=['DT_REFER', 'PREGAO'], how='outer')\n",
    "\n",
    "# Sort the dataframe by 'PREGAO' and 'Date'\n",
    "df_merged = df_merged.sort_values(by=['PREGAO', 'Date'])\n",
    "\n",
    "# Group by 'PREGAO', then apply the fill methods within each group\n",
    "df_merged = df_merged.groupby('PREGAO', group_keys=False).apply(lambda group: group.ffill().bfill()).fillna(0).reset_index(drop=True)\n",
    "\n",
    "# Fill any remaining NaN values in the entire dataframe (outside of groups)\n",
    "df_merged = df_merged.set_index('Date', drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_metrics(df):\n",
    "    # Ensure no division by zero for all columns\n",
    "    df.replace(0, np.nan, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged.groupby('PREGAO', group_keys=False).apply(add_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company = companies[0]\n",
    "company = 'WEG'\n",
    "df = df_merged[df_merged['PREGAO'] == company]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setor, subsetor, segmento = df[['SETOR', 'SUBSETOR', 'SEGMENTO']].iloc[0]\n",
    "setor, subsetor, segmento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_cia = df_merged['PREGAO'] != company\n",
    "m_segmento = df_merged['SEGMENTO'] == segmento\n",
    "m_subsetor = df_merged['SUBSETOR'] == subsetor\n",
    "m_setor = df_merged['SETOR'] == setor\n",
    "\n",
    "cias_segmento = [cia for cia in df_merged[m_cia & m_segmento]['PREGAO'].unique().tolist()]\n",
    "cias_subsetor = [cia for cia in df_merged[m_cia & m_subsetor]['PREGAO'].unique().tolist() if cia not in cias_segmento]\n",
    "cias_setor = [cia for cia in df_merged[m_cia & m_setor]['PREGAO'].unique().tolist() if cia not in cias_subsetor and cia not in cias_segmento]\n",
    "cias_segmento, cias_subsetor, cias_setor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = np.sort(df['TICKER'].unique())\n",
    "df_ticker = []\n",
    "for ticker in tickers:\n",
    "    df_ticker.append(df[df['TICKER'] == ticker])\n",
    "df = df_ticker[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv('dash_df_merged.csv')\n",
    "df.to_csv('dash_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = run.save_pkl(df_merged, 'dash_df_merged')\n",
    "df = run.save_pkl(df, 'dash_df')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(df, subcolumns):\n",
    "    \"\"\"\n",
    "    Normalize data columns in a dataframe to their percentage of row-wise total.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Dataframe containing data to be normalized.\n",
    "    subcolumns : list of str\n",
    "        List of column names to be normalized.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    normalized_df : pd.DataFrame\n",
    "        Dataframe with normalized columns.\n",
    "    \"\"\"\n",
    "    # Filter subcolumns to include only columns that actually exist in df\n",
    "    subcolumns = [col for col in subcolumns if col in df.columns]\n",
    "\n",
    "    # Make a copy of the specified columns to prevent modifying the original dataframe\n",
    "    temp_df = df[subcolumns].copy()\n",
    "    \n",
    "    # Ensure there are no NaN values at the start of the columns\n",
    "    # [You might adapt this as per your requirement]\n",
    "    temp_df = temp_df.dropna(subset=subcolumns, how='all')\n",
    "    \n",
    "    # Calculate the total of the specified columns row-wise\n",
    "    temp_df['total'] = temp_df.sum(axis=1)\n",
    "\n",
    "    # Normalize each specified column by its percentage of the row-wise total\n",
    "    for column in subcolumns:\n",
    "        temp_df[column] = temp_df.apply(\n",
    "            lambda row: round(row[column] / row['total'] * 100, 2) if row['total'] != 0 else 0, \n",
    "            axis=1\n",
    "        )\n",
    "    \n",
    "    # Drop the total column and return the normalized dataframe\n",
    "    normalized_df = temp_df.drop(columns=['total'])\n",
    "    \n",
    "    return normalized_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclude_outliers(item, multiplier=1.5):\n",
    "    \"\"\"\n",
    "    Exclude outliers from a data series using \n",
    "    the Interquartile Range (IQR) method and a personalized multiplier.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_series : pd.Series\n",
    "        The original data series from which outliers will be excluded.\n",
    "    multiplier : float\n",
    "        The multiplier for the IQR. Outliers are defined as values below \n",
    "        Q1 - (multiplier * IQR) or above Q3 + (multiplier * IQR).\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    inliers : pd.Series\n",
    "        The data series with outliers excluded.\n",
    "    \"\"\"\n",
    "    data_series = df[item] if isinstance(item, str) else item\n",
    "\n",
    "    # Calculate the first (Q1) and third (Q3) quartiles\n",
    "    Q1 = data_series.quantile(0.25)\n",
    "    Q3 = data_series.quantile(0.75)\n",
    "    \n",
    "    # Calculate the Interquartile Range (IQR)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Define lower and upper bounds for inliers\n",
    "    lower_bound = Q1 - multiplier * IQR\n",
    "    upper_bound = Q3 + multiplier * IQR\n",
    "    \n",
    "    # Identify and return inliers\n",
    "    inliers = data_series[(data_series > lower_bound) & (data_series < upper_bound)]\n",
    "    \n",
    "    return inliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cagr(item, years=3):\n",
    "    \"\"\"\n",
    "    Calculate the Compound Annual Growth Rate (CAGR) for a given data series.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    item : str or pd.Series\n",
    "        The actual values for which the CAGR will be calculated. \n",
    "        Can be a string (column name) or a pandas Series.\n",
    "    years : int\n",
    "        The number of years over which the CAGR will be calculated.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    data_series : pd.Series\n",
    "        The CAGR values.\n",
    "    \"\"\"\n",
    "    # Retrieve the data series from the dataframe if item is a string (column name)\n",
    "    data_series = df[item] if isinstance(item, str) else item\n",
    "    \n",
    "    # Calculate the CAGR: [ (Ending Value / Beginning Value) ^ (1 / Number of Years) ] - 1\n",
    "    # Shift the original data series by the number of periods to calculate the growth rate\n",
    "    data_series = ((data_series / data_series.shift(periods=round(21*12*years))) ** (1/years)) - 1\n",
    "    \n",
    "    # Convert CAGR to percentage and smooth (accordingly to year) the series by taking a moving average, and round the series to two decimal places\n",
    "    data_series = data_series * 100\n",
    "    data_series = data_series.rolling(window=int(years*4)).mean()\n",
    "    data_series = data_series.round(2)\n",
    "    \n",
    "    # Name it appropriately\n",
    "    data_series.name = f'CAGR {years}a - {data_series.name.split(\" - \")[1]}'\n",
    "    \n",
    "    return data_series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ofs(item, years=3):\n",
    "    \"\"\"\n",
    "    Calculate the Oscillator Following the Stock (OFS) for a given data series.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_serie : pd.Series\n",
    "        The actual values for which the OFS oscillator will be calculated.\n",
    "    window : int\n",
    "        The window size for calculating the moving average and standard deviation.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    ofs : pd.Series\n",
    "        The OFS oscillator values, smoothed with a moving average.\n",
    "    \"\"\"\n",
    "    data_series = df[item] if isinstance(item, str) else item\n",
    "\n",
    "    # Calculate the moving average (mma) and standard deviation (std)\n",
    "    mma = data_series.rolling(window=int(21*12*years)).mean()\n",
    "    std = data_series.rolling(window=int(21*12*years)).std()\n",
    "    \n",
    "    # Define the high and low levels\n",
    "    high_level = mma + 2 * std\n",
    "    low_level = mma - 2 * std\n",
    "    \n",
    "    # Calculate the OFS oscillator, where +2 std=100 and -2 std=-100\n",
    "    data_series = ((data_series - low_level) / (high_level - low_level)) * 20 - 10\n",
    "    \n",
    "    # Smooth the OFS oscillator with a moving average\n",
    "    data_series = data_series.rolling(window=int(years*4)).mean()\n",
    "\n",
    "    # Name the series appropriately\n",
    "    data_series.name = f'OFS {years}a - {data_series.name.split(\" - \")[1]}'\n",
    "\n",
    "    return data_series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tweak(df: pd.DataFrame, data: Dict[str, Any], \n",
    "               options: Optional[Dict[str, Dict[str, Any]]] = {}) -> go.Figure:\n",
    "    \"\"\"\n",
    "    Generates a custom Plotly figure based on the provided data and visualization options.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The primary data source containing the columns to be plotted.\n",
    "        \n",
    "    data : dict\n",
    "        Contains metadata and column names/series for plotting. The dictionary should have the keys:\n",
    "        - 'title' : List containing the main title, left y-axis title, and right y-axis title.\n",
    "        - 'left' : List containing columns or series to be plotted on the left y-axis.\n",
    "        - 'right' : List containing columns or series to be plotted on the right y-axis.\n",
    "        \n",
    "    options : dict, optional\n",
    "        Contains visualization options for left and right data. Each side (left/right) can have:\n",
    "        - 'shape' : str, optional (default is 'line')\n",
    "            Shape of the plot, either 'line' or 'area'.\n",
    "        - 'mode' : str, optional (default is 'standalone')\n",
    "            Data representation mode, either 'standalone' or 'cumulative'.\n",
    "        - 'legendgroup' : str, optional\n",
    "            String to combine legend items into a group.\n",
    "        - 'normalization' : bool, optional (default is False)\n",
    "            Indicates if the data should be normalized.\n",
    "        - 'mma': tuple of (float, float), optional\n",
    "            Contains values for a moving average and its multiplier for standard deviation. \n",
    "            Format is (moving_average_period, standard_deviation_multiplier). None by default.\n",
    "        - 'outliers': bool, optional (default is False)\n",
    "            Indicates if outliers should be excluded.\n",
    "        - 'flexible_range': bool, optional (default is False)\n",
    "            If True, the max_min range logic is not applied. If False, it is applied.\n",
    "            \n",
    "    Returns:\n",
    "    -------\n",
    "    plotly.graph_objs.Figure\n",
    "        The generated Plotly figure.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the figure object and variables\n",
    "    company, ticker = df[['PREGAO', 'TICKER']].iloc[0]\n",
    "    fig = go.Figure()\n",
    "\n",
    "    def get_data_from_item(item, normalize=False, columns_for_normalization=None, \n",
    "                        exclude_outliers_multiplier=None, ofs=None):\n",
    "        \"\"\"\n",
    "        Retrieve data from either dataframe columns or directly from a pandas Series, \n",
    "        with optional outlier exclusion and z-score calculation.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            data_series = df[item] if isinstance(item, str) else item\n",
    "        \n",
    "            if normalize:\n",
    "                if isinstance(item, str):\n",
    "                    # If item is a string (column name), normalize using other columns if provided\n",
    "                    data_series = normalize_data(df, columns_for_normalization or [item])[item]\n",
    "                else:\n",
    "                    # If item is a Series, normalize only the series\n",
    "                    data_series = (data_series - data_series.min()) / (data_series.max() - data_series.min())\n",
    "\n",
    "            if exclude_outliers_multiplier is not None:\n",
    "                data_series = exclude_outliers(data_series, exclude_outliers_multiplier)\n",
    "\n",
    "        except Exception as e:\n",
    "            return pd.DataFrame(index=df.index)\n",
    "\n",
    "        return data_series\n",
    "\n",
    "    def get_trace(item, group, shape, mode, normalization, \n",
    "                columns_for_normalization=None, mma=None, \n",
    "                exclude_outliers_multiplier=None):\n",
    "        \"\"\"\n",
    "        Get trace(s) for the provided item with specified configurations.\n",
    "        \"\"\"\n",
    "        column_data = get_data_from_item(\n",
    "            item, normalization, columns_for_normalization, \n",
    "            exclude_outliers_multiplier\n",
    "        )\n",
    "        # Basic trace\n",
    "        try:\n",
    "            trace = {\n",
    "                'x': column_data.index,\n",
    "                'y': column_data,\n",
    "                'name': item.split(' - ')[1] if isinstance(item, str) else item.name,\n",
    "                'fill': 'tonexty' if shape == 'area' and mode == 'cumulative' else \n",
    "                        'tozeroy' if shape == 'area' else 'none',\n",
    "                'stackgroup': group if mode == 'cumulative' else None\n",
    "            }\n",
    "\n",
    "            traces = [trace]\n",
    "\n",
    "            # Statistics based on MMA\n",
    "            if mma:\n",
    "                window = int(21 * 12 * mma[0])\n",
    "                rolling_average = column_data.rolling(window=window).mean()\n",
    "                rolling_std = column_data.rolling(window=window).std()\n",
    "                \n",
    "                # MMA trace\n",
    "                traces.append({\n",
    "                    'x': column_data.index,\n",
    "                    'y': rolling_average,\n",
    "                    'mode': 'lines',\n",
    "                    'name': f'Média {(mma[0]):.0f}a ± {mma[1]}dp',\n",
    "                    'line': {'color': 'green'}, \n",
    "                    'legendgroup': 'mma', \n",
    "                })\n",
    "\n",
    "                # Traces for ± standard deviations from the MMA\n",
    "                traces.append({\n",
    "                    'x': column_data.index,\n",
    "                    'y': rolling_average + mma[1] * rolling_std,\n",
    "                    'mode': 'lines',\n",
    "                    'name': f'+{mma[1]} STD',\n",
    "                    'line': {'color': 'green', 'dash': 'dash'}, \n",
    "                    'legendgroup': 'mma', \n",
    "                    'showlegend': False, \n",
    "                })\n",
    "\n",
    "                traces.append({\n",
    "                    'x': column_data.index,\n",
    "                    'y': rolling_average - mma[1] * rolling_std,\n",
    "                    'mode': 'lines',\n",
    "                    'name': f'-{mma[1]} STD',\n",
    "                    'line': {'color': 'green', 'dash': 'dash'}, \n",
    "                    'legendgroup': 'mma', \n",
    "                    'showlegend': False, \n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            return []\n",
    "\n",
    "        return traces\n",
    "\n",
    "    def update_axis_bounds(fig, side, g_max, g_min, options, default_settings):\n",
    "        \"\"\"\n",
    "        ...\n",
    "        options : dict, optional\n",
    "            Contains visualization options for left and right data. Each side (left/right) can have:\n",
    "            ...\n",
    "            - 'range': bool or str, optional (default is False)\n",
    "                Determines the logic used to set the y-axis bounds:\n",
    "                - 'flexible': No custom logic, Plotly determines y-axis bounds.\n",
    "                - False: Upper bound is set to the nearest power of 10 above the maximum data value.\n",
    "                - 'half': Upper bound is set to the nearest multiple of 5 above the maximum data value.\n",
    "                - 'full': Upper bound is set to the nearest power of 10 above the maximum data value.\n",
    "        ...\n",
    "        \"\"\"\n",
    "        range_option = options.get(side, {}).get('range', default_settings['range'])\n",
    "        \n",
    "        # Check if range logic should be applied\n",
    "        if (\n",
    "            range_option not in ['flexible', 'full'] and \n",
    "            g_max != float('-inf') and \n",
    "            g_min != float('inf')\n",
    "        ):\n",
    "            # Determine upper bound\n",
    "            if range_option == 'half':\n",
    "                upper_bound = 5 * 10 ** math.ceil(math.log10(g_max) - 1)\n",
    "            elif range_option == False:  # or any other invalid value\n",
    "                upper_bound = 10 ** math.ceil(math.log10(g_max))\n",
    "            upper_bound = upper_bound if g_max > 0 else g_max\n",
    "            \n",
    "            # Determine lower bound\n",
    "            lower_bound = 10 ** math.floor(math.log10(g_min)) if g_min > 0 else g_min\n",
    "            \n",
    "            # Update layout\n",
    "            axis_key = 'yaxis' if side == 'left' else 'yaxis2'\n",
    "            fig.update_layout({axis_key: dict(range=[lower_bound, upper_bound])})\n",
    "\n",
    "   # Default settings for visualization\n",
    "    default_settings = {\n",
    "        'shape': 'line',\n",
    "        'mode': 'standalone',\n",
    "        'legendgroup': None,\n",
    "        'normalization': False, \n",
    "        'normalization_columns': None, \n",
    "        'mma': None, \n",
    "        'outliers': None, \n",
    "        'range': 'flexible', \n",
    "    }\n",
    "    \n",
    "    # Flags to determine if we have data on either side\n",
    "    left_data_exists = any(item.startswith('left') for item in data.keys())\n",
    "    right_data_exists = any(item.startswith('right') for item in data.keys())\n",
    "\n",
    "    # Initialize variables for storing the global max and min values for each side\n",
    "    global_max = {'left': float('-inf'), 'right': float('-inf')}\n",
    "    global_min = {'left': float('inf'), 'right': float('inf')}\n",
    "\n",
    "    # Process each side separately\n",
    "    for side, items in data.items():\n",
    "        # Skip if the side is 'title'\n",
    "        if side == 'title':\n",
    "            continue\n",
    "        \n",
    "        # Determine the base side (left or right)\n",
    "        side_base = 'left' if 'left' in side else 'right' if 'right' in side else None\n",
    "        \n",
    "        if side_base:\n",
    "            # Get the options for this side, if any\n",
    "            side_options = {**default_settings, **options.get(side, {})}\n",
    "            \n",
    "            # Generate traces for this side\n",
    "            for item in items:\n",
    "                traces = get_trace(item, side, \n",
    "                                   side_options['shape'],\n",
    "                                   side_options['mode'],\n",
    "                                   side_options['normalization'],\n",
    "                                   side_options['normalization_columns'] or items, \n",
    "                                   side_options['mma'],\n",
    "                                   side_options['outliers'],\n",
    "                                   )\n",
    "                for trace in traces:\n",
    "                    if side_options.get('legendgroup'):\n",
    "                        trace['legendgroup'] = side_options['legendgroup']\n",
    "                    \n",
    "                    # If side contains 'right', assign to yaxis2\n",
    "                    trace['yaxis'] = 'y2' if 'right' in side and left_data_exists else 'y1'\n",
    "\n",
    "                    # Update global min and max\n",
    "                    y_values = trace['y']\n",
    "                    if not y_values.empty:\n",
    "                        max_val = max(y_values)\n",
    "                        min_val = min(y_values)\n",
    "                        global_max[side_base] = max(global_max[side_base], max_val)\n",
    "                        global_min[side_base] = min(global_min[side_base], min_val)\n",
    "\n",
    "                    fig.add_trace(go.Scatter(**trace))\n",
    "\n",
    "    # Figure Update Layout\n",
    "    fig.update_layout(\n",
    "        template='plotly_white',\n",
    "        title_text=f'{ticker} ({company}) {data.get(\"title\", [\"\", \"\", \"\"])[0]}',\n",
    "\n",
    "        xaxis_title='Data',\n",
    "        yaxis_title=data.get('title', [\"\", \"\", \"\"])[1],\n",
    "        yaxis2={'title': data.get('title', [\"\", \"\", \"\"])[2], 'overlaying': 'y', 'side': 'right'} if left_data_exists and right_data_exists else {},\n",
    "\n",
    "        legend=dict(\n",
    "            orientation='h',\n",
    "            font_size=10,\n",
    "        ),\n",
    "        width=6.27 * 200,  # converting inches to 96 pixels for width\n",
    "        height=3.52 * 200,  # converting inches to 96 pixels for height\n",
    "    )\n",
    "    \n",
    "    # Applying the flexible_range logic. Note: The logic is NOT applied if flexible_range is True. If it's False, it IS applied.\n",
    "    update_axis_bounds(fig, 'left', global_max['left'], global_min['left'], options, default_settings)\n",
    "    update_axis_bounds(fig, 'right', global_max['right'], global_min['right'], options, default_settings)\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = '13.09.02 - Outros Ativos Não Circulantes de Longo Prazo por Faturamento'\n",
    "data = {\n",
    "    'title': [f'{item} - {plot}', 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': [item], \n",
    "    'right': [cagr(item, years), ofs(item, years)], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, 'mma': [years, 2], },\n",
    "    'right': {'shape': 'ine', 'mode': 'standalone', 'normalization': False, 'outliers': False, }, \n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company][item][plot] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dual_axis(df, data):\n",
    "    '''\n",
    "    data: Dicionário contendo chaves 'left' e 'right', com as colunas correspondentes.\n",
    "               Exemplo: {'left': [col1, col2], 'right': [col3, col4]}\n",
    "    df: DataFrame contendo os dados.\n",
    "    '''\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "    # Determine y-axis ranges\n",
    "    factor = 1.50\n",
    "    left_min = df[data['left']].min().min() if df[data['left']].min().min() < 0 else df[data['left']].min().min() * -1\n",
    "    left_min *= factor\n",
    "    left_max_abs = max(abs(df[data['left']].min().min()), abs(df[data['left']].max().max())) * factor\n",
    "\n",
    "    right_min = df[data['right']].min().min() if df[data['right']].min().min() < 0 else df[data['right']].min().min() * -1\n",
    "    right_min *= factor\n",
    "    right_max_abs = max(abs(df[data['right']].min().min()), abs(df[data['right']].max().max())) * factor\n",
    "\n",
    "    # Find the zero alignment factor\n",
    "    zero_factor = abs(left_min) / left_max_abs\n",
    "\n",
    "    # Adjust the right y-axis ranges to align the zeros\n",
    "    right_min_adj = -right_max_abs * zero_factor\n",
    "    right_max_adj = right_max_abs * (1 - zero_factor)\n",
    "\n",
    "    # Adicione os dados do eixo esquerdo\n",
    "    for column in data['right']:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=df.index, y=df[column], mode='lines', name=column.split(' - ')[1]),\n",
    "            secondary_y=True\n",
    "        )\n",
    "\n",
    "    # Adicione os dados do eixo direito\n",
    "    fill_mode = 'tozeroy'\n",
    "    for column in data['left']:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=df.index, y=df[column], fill=fill_mode, name=column.split(' - ')[1]),\n",
    "            secondary_y=False\n",
    "        )\n",
    "        fill_mode = 'tonexty'\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text=f'{company} - {data[\"title\"][0]}',\n",
    "        xaxis_title='Data',\n",
    "        yaxis_title=data['title'][1],\n",
    "        yaxis2_title=data['title'][2],\n",
    "        yaxis_range=[left_min, left_max_abs],\n",
    "        yaxis2_range=[right_min_adj, right_max_adj]\n",
    "    )\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stacked_area(df, data):\n",
    "    '''\n",
    "    df: DataFrame containing the data.\n",
    "    data: Dictionary containing the columns to be plotted.\n",
    "    '''\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Helper function to get data from column name or series\n",
    "    def get_data(item):\n",
    "        if isinstance(item, str):\n",
    "            return df[item]\n",
    "        return item\n",
    "\n",
    "    # For 'left' data\n",
    "    for item in data['left']:\n",
    "        data_values = get_data(item)\n",
    "        name = item.split(' - ')[1] if isinstance(item, str) else item.name\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df.index,\n",
    "                y=data_values,\n",
    "                name=name,\n",
    "                fill='tonexty', \n",
    "                stackgroup='left',\n",
    "                # legendgroup='left',\n",
    "                showlegend=True\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # For 'right' data\n",
    "    for item in data['right']:\n",
    "        data_values = get_data(item)\n",
    "        name = item.split(' - ')[1] if isinstance(item, str) else item.name\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df.index,\n",
    "                y=data_values,\n",
    "                name=name,\n",
    "                fill='tonexty', \n",
    "                stackgroup='right',\n",
    "                # legendgroup='right',\n",
    "                showlegend=True,\n",
    "                yaxis='y2'\n",
    "            )\n",
    "        )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text=f'{company} - {data[\"title\"][0]}',\n",
    "        xaxis_title='Data',\n",
    "        yaxis_title=data['title'][1],\n",
    "        yaxis2=dict(title=data['title'][2], overlaying='y', side='right')\n",
    "    )\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_100_stacked_area(df, data):\n",
    "    '''\n",
    "    df: DataFrame containing the data.\n",
    "    data: Dictionary containing the columns to be plotted.\n",
    "    '''\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Helper function to get data from column name or series\n",
    "    def get_data(item):\n",
    "        if isinstance(item, str):\n",
    "            return df[item]\n",
    "        return item\n",
    "\n",
    "    # Function to normalize data\n",
    "    def normalize_data(columns):\n",
    "        temp_df = df[columns].copy()\n",
    "        temp_df['total'] = temp_df.sum(axis=1)\n",
    "        for column in columns:\n",
    "            temp_df[column] = temp_df.apply(lambda row: row[column] / row['total'] * 100 if row['total'] != 0 else 0, axis=1)\n",
    "        return temp_df\n",
    "\n",
    "    left_normalized = normalize_data(data['left'])\n",
    "    right_normalized = normalize_data(data['right'])\n",
    "\n",
    "    # Plot 'left' data\n",
    "    for column in data['left']:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df.index,\n",
    "                y=left_normalized[column],\n",
    "                name=column.split(' - ')[1],\n",
    "                fill='tonexty',\n",
    "                stackgroup='left',\n",
    "                legendgroup='left',\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Plot 'right' data on secondary y-axis\n",
    "    for column in data['right']:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df.index,\n",
    "                y=right_normalized[column],\n",
    "                name=column.split(' - ')[1],\n",
    "                fill='tonexty',\n",
    "                stackgroup='right',\n",
    "                legendgroup='right',\n",
    "                yaxis='y2'\n",
    "            )\n",
    "        )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text=f'{company} - {data[\"title\"][0]}',\n",
    "        xaxis_title='Data',\n",
    "        yaxis_title=data['title'][1],\n",
    "        yaxis2=dict(title=data['title'][2], overlaying='y', side='right')\n",
    "    )\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lines(df, data):\n",
    "    '''\n",
    "    data: Dicionário contendo chaves 'left' e 'title'.\n",
    "               Exemplo: {'left': [col1, col2], 'title': 'Equity Multiplier'}\n",
    "    df: DataFrame contendo os dados.\n",
    "    '''\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Adicione os dados do eixo esquerdo\n",
    "    for column in data['left']:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=df.index, y=df[column], fill='none', name=column.split(' - ')[1])\n",
    "        )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text=f'{company} - {data[\"title\"][0]}',\n",
    "        xaxis_title='Data',\n",
    "        yaxis_title=data['title'][1],\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_basics(df, col, window):\n",
    "    figs = {}\n",
    "    if df[col].sum() != 0:\n",
    "\n",
    "        year_average = df[col].rolling(window=365).mean()\n",
    "\n",
    "        # Calculate rolling mean and standard deviation\n",
    "        rolling_average = df[col].rolling(window=window).mean()\n",
    "        rolling_std = df[col].rolling(window=window).std()\n",
    "\n",
    "        # Create a single line plot\n",
    "        title = f'A - Linha do Tempo'\n",
    "        fig_line = px.line(df, x=df.index, y=col, title=f'{company} - {col} - {title}',\n",
    "                            labels={'value': 'Valor (R$)', 'variable': f'{title}'})\n",
    "        fig_line.add_scatter(x=df.index, y=year_average, mode='lines', line=dict(color='blue'), name='Média Anual')\n",
    "        figs[title] = fig_line\n",
    "        # fig_line.show()\n",
    "\n",
    "        # Create a moving average plot with ±2 standard deviations\n",
    "        title = f'B - Média Móvel e ±2 Desvios Padrão'\n",
    "        fig_mma_std = px.area(df, x=df.index, y=col, title=f'{company} - {col} - {title}',\n",
    "                            labels={'value': 'Valor (R$)', 'variable': f'{title}'})\n",
    "        fig_mma_std.add_scatter(x=df.index, y=year_average, mode='lines', line=dict(color='blue'), name='Média Anual')\n",
    "        fig_mma_std.add_scatter(x=df.index, y=rolling_average, mode='lines', line=dict(color='green'), name='Média Móvel')\n",
    "        fig_mma_std.add_scatter(x=df.index, y=rolling_average + 2 * rolling_std, mode='lines', line=dict(color='green', dash='dash'), name='Média Móvel + 2 Desvios Padrão')\n",
    "        fig_mma_std.add_scatter(x=df.index, y=rolling_average - 2 * rolling_std, mode='lines', line=dict(color='green', dash='dash'), name='Média Móvel - 2 Desvios Padrão')\n",
    "        figs[title] = fig_mma_std\n",
    "        # fig_mma_std.show()\n",
    "\n",
    "    sub_cols = [c for c in df.columns if c.startswith(col.split(' - ')[0] + '.') and c.count('.') == col.count('.') + 1]\n",
    "    if sub_cols:\n",
    "        # Create a multi line plot\n",
    "        title =  f'C - Distribuição Individual'\n",
    "        fig_multiline = px.line(df, x=df.index, y=sub_cols, title=f'{company} - {col} - {title}',\n",
    "                            labels={'value': 'Valor (R$)', 'variable': f'{title}'})\n",
    "        figs[title] = fig_multiline\n",
    "        # fig_area.show()\n",
    "\n",
    "        # Create a cumulative distribution plot\n",
    "        title =  f'D - Distribuição Acumulada'\n",
    "        fig_area = px.area(df, x=df.index, y=sub_cols, title=f'{company} - {col} - {title}',\n",
    "                            labels={'value': 'Valor (R$)', 'variable': f'{title}'})\n",
    "        figs[title] = fig_area\n",
    "        # fig_area.show()\n",
    "\n",
    "        # Create a proportional distribution plot\n",
    "        title = f'E - Distribuição Proporcional'\n",
    "        fig_area_100_stacked = px.area(df, x=df.index, y=sub_cols, title=f'{company} - {col} - {title}',\n",
    "                            labels={'value': 'Porcentagem (%)', 'variable': f'{title}'},\n",
    "                            groupnorm='percent')\n",
    "        figs[title] = fig_area_100_stacked\n",
    "        # fig_area_100_stacked.show()\n",
    "\n",
    "    return figs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_figs(figs, base_dir='./company/'):\n",
    "    \"\"\"\n",
    "    Save figures to the specified directory.\n",
    "\n",
    "    Parameters:\n",
    "    - col_figs: Dictionary of figures to save\n",
    "    - col: Column for which figures were generated\n",
    "    - company: Company for which figures were generated\n",
    "    - base_dir: Base directory where the figures will be saved\n",
    "    \"\"\"\n",
    "    for company, col in figs.items():\n",
    "        path = os.path.join(base_dir, company)\n",
    "        \n",
    "        # Create company directory if it doesn't exist\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "        for col, plots in col.items():\n",
    "            for title, plot in plots.items():\n",
    "                try:\n",
    "                    file_name = f'{company} - {col} - {title}.png'\n",
    "                    file_path = os.path.join(path, file_name)\n",
    "                    plot.write_image(file_path)\n",
    "                    # plot.show()\n",
    "                    print(file_name)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "    return figs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = 3\n",
    "figs = {}\n",
    "figs[company] = {}\n",
    "df = df_ticker[0]\n",
    "for item in df.columns:\n",
    "    figs[company][item] = {}\n",
    "    print(item)\n",
    "    try:\n",
    "        if df[item].sum() != 0:\n",
    "            plot = 'Valores, Média, CAGR e OFS'\n",
    "            data = {\n",
    "                'title': [f'{item} - {plot}', 'Reais (R$)', 'Porcentagem (%)'], \n",
    "                'left': [item], \n",
    "                'right': [cagr(item, years), ofs(item, years)], \n",
    "            }\n",
    "            options = {\n",
    "                'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, 'mma': [years, 2], },\n",
    "                'right': {'shape': 'ine', 'mode': 'standalone', 'normalization': False, 'outliers': False, }, \n",
    "            }\n",
    "            fig = plot_tweak(df_ticker[0], data, options)\n",
    "            figs[company][item][plot] = fig\n",
    "            # fig.show()\n",
    "\n",
    "            sub_cols = [column for column in df.columns if column.startswith(item.split(' - ')[0] + '.') and column.count('.') == item.count('.') + 1]\n",
    "            if sub_cols:\n",
    "                plot = 'Composição Cumulativa'\n",
    "                data = {\n",
    "                    'title': [f'{item} - {plot}', 'Reais (R$)', 'Porcentagem (%)'], \n",
    "                    'left': sub_cols, \n",
    "                    'right': [], \n",
    "                }\n",
    "                options = {\n",
    "                    'left': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, },\n",
    "                    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, }, \n",
    "                }\n",
    "                fig = plot_tweak(df_ticker[0], data, options)\n",
    "                figs[company][item][plot] = fig\n",
    "                # fig.show()\n",
    "\n",
    "                plot = 'Composição Individual'\n",
    "                data = {\n",
    "                    'title': [f'{item} - {plot}', 'Reais (R$)', 'Porcentagem (%)'], \n",
    "                    'left': sub_cols, \n",
    "                    'right': [], \n",
    "                }\n",
    "                options = {\n",
    "                    'left': {'shape': 'line', 'mode': 'standalone', 'normalization': False, },\n",
    "                    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, }, \n",
    "                }\n",
    "                fig = plot_tweak(df_ticker[0], data, options)\n",
    "                figs[company][item][plot] = fig\n",
    "                # fig.show()\n",
    "\n",
    "                plot = 'Composição Relativa'\n",
    "                data = {\n",
    "                    'title': [f'{item} - {plot}', 'Reais (R$)', 'Porcentagem (%)'], \n",
    "                    'left': sub_cols, \n",
    "                    'right': [], \n",
    "                }\n",
    "                options = {\n",
    "                    'left': {'shape': 'line', 'mode': 'standalone', 'normalization': True, },\n",
    "                    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, }, \n",
    "                }\n",
    "                fig = plot_tweak(df_ticker[0], data, options)\n",
    "                figs[company][item][plot] = fig\n",
    "                # fig.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Equity Multiplier'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['01 - Ativo Total', '02.03 - Patrimônio Líquido'], \n",
    "    'right': [ '11.03.01 - Equity Multiplier (Ativos por Patrimônio Líquido)',], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'cumulative', 'normalization': True, 'range': 'flexible', },\n",
    "    'right': {'shape': 'ine', 'mode': 'standalone', 'normalization': False, }, \n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Proporção dos Ativos'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': [ '11.01.03 - Ativos Circulantes de Curto Prazo por Ativos', '11.01.04 - Ativos Não Circulantes de Longo Prazo por Ativos',], \n",
    "    'right': [], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'cumulative', 'normalization': True, 'range': 'flexible', },\n",
    "    'right': {'shape': 'ine', 'mode': 'standalone', 'normalization': True, }, \n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Proporção dos Passivos'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': [ '11.02.01 - Passivos Circulantes de Curto Prazo por Ativos', '11.02.02 - Passivos Não Circulantes de Longo Prazo por Ativos', '11.03 - Patrimônio Líquido por Ativos'], \n",
    "    'right': [], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'cumulative', 'normalization': True, 'range': 'flexible', },\n",
    "    'right': {'shape': 'ine', 'mode': 'standalone', 'normalization': False, }, \n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Passivos por Patrimônio Líquido'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': [ '11.03.02.01 - Passivos Circulantes de Curto Prazo por Patrimônio Líquido',  '11.03.02.02 - Passivos Não Circulantes de Longo Prazo por Patrimônio Líquido',], \n",
    "    'right': [], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'cumulative', 'normalization': True, 'range': 'flexible', },\n",
    "    'right': {'shape': 'ine', 'mode': 'standalone', 'normalization': False, 'outliers': True, }, \n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Ativos e Liquidez'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['01.01 - Ativo Circulante de Curto Prazo', '02.01 - Passivo Circulante de Curto Prazo'], \n",
    "    'right': ['11.01.02 - Liquidez (Ativos Circulantes por Passivos Circulantes)', ], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, },\n",
    "    'right': {'shape': 'ine', 'mode': 'standalone', 'normalization': False, 'mma': [3,2]}, \n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Ativos e Prazos'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': [df['01.01 - Ativo Circulante de Curto Prazo'], df['01.02 - Ativo Não Circulante de Longo Prazo']], \n",
    "    'right': ['11.01.03 - Ativos Circulantes de Curto Prazo por Ativos', '11.01.04 - Ativos Não Circulantes de Longo Prazo por Ativos', ], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': True, },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Capital de Giro'\n",
    "trace = (df['01.02 - Ativo Não Circulante de Longo Prazo']/df['02.02 - Passivo Não Circulante de Longo Prazo'])\n",
    "trace.name = 'Liquide de Longo Prazo (Ativos Não Circulantes por Passivos Não Circulantes)'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['11.01.02 - Liquidez (Ativos Circulantes por Passivos Circulantes)', trace], \n",
    "    'right': ['11.01.01 - Capital de Giro (Ativos Circulantes - Passivos Circulantes)'], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'range': 'flexible', },\n",
    "    'right': {'shape': 'area', 'mode': 'standalone', 'normalization': False, 'range': 'flexible', },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Contas a Receber e Faturamento'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['01.01.03 - Contas a Receber', '01.02.01.03 - Contas a Receber'], \n",
    "    'right': ['13.03 - Contas por Faturamento'], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'line', 'mode': 'standalone', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3,2], },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Estoques e Faturamento'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['01.01.04 - Estoques', '01.02.01.04 - Estoques'], \n",
    "    'right': ['13.04 - Estoques por Faturamento'], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, 'range': 'flexible', },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3,2], 'range': 'flexible', },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Ativos Biológicos e Faturamento'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['01.01.05 - Ativos Biológicos', '01.02.01.05 - Ativos Biológicos'], \n",
    "    'right': ['13.05 - Ativos Biológicos por Faturamento'], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3,2]},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Despesas e Faturamento'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['01.01.07 - Despesas', '01.02.01.07 - Despesas'], \n",
    "    'right': ['13.07 - Despesas por Faturamento'], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3,2]},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Tributos e Faturamento'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['01.01.06 - Tributos', '01.02.01.06 - Tributos'], \n",
    "    'right': ['13.06 - Tributos por Faturamento'], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3,2]},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Capex Ativos Imobilizados e Intangíveis'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['01.02.03 - Imobilizados', '01.02.04 - Intangível', '01.02.02 - Investimentos Não Capex'], \n",
    "    'right': ['01.02.03 - Imobilizados', '01.02.04 - Intangível', '01.02.02 - Investimentos Não Capex'], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': True, },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Imobilização do Patrimônio'\n",
    "trace = (df['11.03.04 - Patrimônio Imobilizado']/df['02.03 - Patrimônio Líquido'])\n",
    "trace.name = 'Patrimônio Imobilizado por Patrimônio Líquido'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['11.03.04 - Patrimônio Imobilizado', '02.03 - Patrimônio Líquido'], \n",
    "    'right': [trace], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'cumulative', 'normalization': False, 'mma': [3,2]},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Prazo da Dívida'\n",
    "trace = df['12.01.02.01 - Dívida Bruta Circulante de Curto Prazo']/df['12.01.02 - Dívida Bruta']\n",
    "trace.name = 'Dívida de Curto Prazo por Dívida '\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['12.01.02.01 - Dívida Bruta Circulante de Curto Prazo', '12.01.02.02 - Dívida Bruta Não Circulante de Longo Prazo Prazo'], \n",
    "    'right': [trace], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False,'mma': [3,2]},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Jurisdição da Dívida'\n",
    "trace = df['12.01.02.03 - Dívida Bruta em Moeda Nacional']/(df['12.01.02.03 - Dívida Bruta em Moeda Nacional']+df['12.01.02.04 - Dívida Bruta em Moeda Estrangeira'])\n",
    "trace.name = 'Nacionalização da Dívida'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['12.01.02.03 - Dívida Bruta em Moeda Nacional', '12.01.02.04 - Dívida Bruta em Moeda Estrangeira'], \n",
    "    'right': [trace], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False,'mma': [3,2], },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Dívida de Curto Prazo por Ativo de Curto Prazo'\n",
    "trace = df['12.01.02.01 - Dívida Bruta Circulante de Curto Prazo']/df['01.01 - Ativo Circulante de Curto Prazo']\n",
    "trace.name = 'Dívida de Curto Prazo por Ativo de Curto Prazo'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['02.01.04.01.01 - Empréstimos e Financiamentos em Moeda Nacional', '02.01.04.01.02 - Empréstimos e Financiamentos em Moeda Estrangeira', '02.01.04.02 - Debêntures', '02.01.04.03 - Arrendamentos', '02.01.04.09 - Outros empréstimos, financiamentos e debêntures', ], \n",
    "    'left_01': ['01.01 - Ativo Circulante de Curto Prazo'], \n",
    "    'right': [trace], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, },\n",
    "    'left_01': {'shape': 'line', 'mode': 'standalone', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2]},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Dívida de Longo Prazo por Ativo de Longo Prazo'\n",
    "trace = df['12.01.02.02 - Dívida Bruta Não Circulante de Longo Prazo Prazo']/df['01.02 - Ativo Não Circulante de Longo Prazo']\n",
    "trace.name = 'Dívida de Longo Prazo por Ativo de Longo Prazo'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['02.02.01.01.01 - Empréstimos e Financiamentos em Moeda Nacional', '02.02.01.01.02 - Empréstimos e Financiamentos em Moeda Estrangeira', '02.02.01.02 - Debêntures', '02.02.01.03 - Arrendamentos', '02.02.02.09 - Outros empréstimos, financiamentos e debêntures', ], \n",
    "    'left_01': ['01.02 - Ativo Não Circulante de Longo Prazo'], \n",
    "    'right': [trace], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, 'range': 'flexible'},\n",
    "    'left_01': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'range': 'flexible'},\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], 'range': 'flexible'},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Dívida por Patrimônio Líquido'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['12.01.02.01 - Dívida Bruta Circulante de Curto Prazo', '12.01.02.02 - Dívida Bruta Não Circulante de Longo Prazo Prazo', ], \n",
    "    'left_01': ['02.03 - Patrimônio Líquido'], \n",
    "    'right': ['12.02.01 - Dívida Bruta por Patrimônio Líquido'], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, },\n",
    "    'left_01': {'shape': 'line', 'mode': 'standalone', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3,2], },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Dívida Líquida'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': [df['12.01.02 - Dívida Bruta'], ], \n",
    "    'left_01': [df['01.01.01 - Caixa e Disponibilidades de Caixa']*-1], \n",
    "    'left_02': [df['12.01.03 - Dívida Líquida']], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, 'range': 'flexible'},\n",
    "    'left_01': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, 'range': 'flexible'},\n",
    "    'left_02': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'range': 'flexible'},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Dívida Líquida por EBITDA'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': [df['12.04.01 - Dívida Líquida por EBITDA']*-1, ], \n",
    "    'left_01': ['12.02.01 - Dívida Bruta por Patrimônio Líquido'],\n",
    "    'right': ['12.01.02 - Dívida Bruta', '02.03 - Patrimônio Líquido'], \n",
    "    # 'right': [ofs('12.04.01 - Dívida Líquida por EBITDA', 3), ]\n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'line', 'mode': 'cumulative', 'normalization': False, 'range': 'half'},\n",
    "    'left_01': {'shape': 'line', 'mode': 'cumulative', 'normalization': False, 'range': 'half'},\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'outliers': False, 'range': 'flexible'},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Endividamento Financeiro'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': [df['02.03 - Patrimônio Líquido'], df['12.01.02 - Dívida Bruta'], ], \n",
    "    'right': ['12.02.02 - Endividamento Financeiro'], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'cumulative', 'normalization': False, 'mma': [3, 2]},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Serviço da Dívida'\n",
    "trace = df['12.01.03 - Dívida Líquida']/df['03.11 - Lucro Líquido']\n",
    "trace.name = 'Serviço da Dívida'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['12.01.03 - Dívida Líquida', '03.11 - Lucro Líquido'], \n",
    "    'right': [trace], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Índice de Cobertura'\n",
    "trace = df['07.08.03.01 - Juros Pagos']/df['03.05 - LAJIR EBIT Resultado Antes do Resultado Financeiro e dos Tributos']\n",
    "trace.name = 'Juros por EBIT'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['07.08.03.01 - Juros Pagos', '03.05 - LAJIR EBIT Resultado Antes do Resultado Financeiro e dos Tributos', ], \n",
    "    'right': [trace], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Composição do Patrimônio Líquido'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['02.03.01 - Capital Social', '02.03.02 - Reservas de Capital', '02.03.03 - Reservas de Reavaliação', '02.03.04 - Reservas de Lucros', '02.03.05 - Lucros ou Prejuízos Acumulados', '02.03.06 - Ajustes de Avaliação Patrimonial', '02.03.07 - Ajustes Acumulados de Conversão', '02.03.08 - Outros Resultados Abrangentes', ], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, 'range': 'flexible', },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Composição do Patrimônio Líquido'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['02.03.01 - Capital Social', '02.03.02 - Reservas de Capital', '02.03.03 - Reservas de Reavaliação', '02.03.04 - Reservas de Lucros', '02.03.05 - Lucros ou Prejuízos Acumulados', '02.03.06 - Ajustes de Avaliação Patrimonial', '02.03.07 - Ajustes Acumulados de Conversão', '02.03.08 - Outros Resultados Abrangentes', ], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'line', 'mode': 'standalone', 'normalization': False, },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Margem Bruta'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left_1': [df['03.02 - Custo de Produção']*-1, df['03.03 - Resultado Bruto (Receita Líquida)'], ], \n",
    "    'right': [df['16.01 - Margem Bruta (Resultado Bruto (Receita Líquida) por Receita Bruto)'] * 100, ]\n",
    "}\n",
    "options = {\n",
    "    'left_1': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Margem Operacional'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left_1': [df['03.01 - Receita Bruta'], df['03.04 - Despesas Operacionais']*-1, ], \n",
    "    'right': [df['16.02 - Margem Operacional (Receitas Operacionais por Receita Bruta)'] * -100,]\n",
    "}\n",
    "options = {\n",
    "    'left_1': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, 'range': 'flexible', },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Margem EBIT'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left_1': [df['03.04 - Despesas Operacionais']*-1, df['03.05 - LAJIR EBIT Resultado Antes do Resultado Financeiro e dos Tributos'], ], \n",
    "    'right': [df['16.03.01 - Margem EBIT (EBIT por Resultado Bruto (Receita Líquida)'] * 100,]\n",
    "}\n",
    "options = {\n",
    "    'left_1': {'shape': 'area', 'mode': 'cumulative', 'normalization': False,},\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], 'range': 'flexible', },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Margem de Depreciação'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left_1': [df['03.01 - Receita Bruta'], df['07.04.01 - Depreciação e Amortização'] * -1, ], \n",
    "    'right': [df['16.03.02 - Margem de Depreciação por Resultado Bruto (Receita Líquida)'] * -100,]\n",
    "}\n",
    "options = {\n",
    "    'left_1': {'shape': 'area', 'mode': 'cumulative', 'normalization': False,},\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], 'range': 'flexible', },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Margem EBITDA'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left_1': [df['03.05 - LAJIR EBIT Resultado Antes do Resultado Financeiro e dos Tributos'], df['13.01 - LAJIDA EBITDA Resultado Antes do Resultado Financeiro e dos Tributos mais Depreciação e Amortização'], df['07.04.01 - Depreciação e Amortização'] * -1], \n",
    "    'right': [df['16.03 - Margem EBITDA (EBITDA por Resultado Bruto (Receita Líquida)'] * 100, df['16.03.02 - Margem de Depreciação por Resultado Bruto (Receita Líquida)'] * 100, ]\n",
    "}\n",
    "options = {\n",
    "    'left_1': {'shape': 'area', 'mode': 'cumulative', 'normalization': False,},\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], 'range': 'flexible', },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Resultado Financeiro'\n",
    "trace = df['03.06 - Resultado Financeiro (Não Operacional)']/df['03.05 - LAJIR EBIT Resultado Antes do Resultado Financeiro e dos Tributos']\n",
    "trace.name = 'Margem Financeira'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left_1': [df['03.05 - LAJIR EBIT Resultado Antes do Resultado Financeiro e dos Tributos'], df['03.06 - Resultado Financeiro (Não Operacional)']], \n",
    "    'right': [trace * 100, ]\n",
    "}\n",
    "options = {\n",
    "    'left_1': {'shape': 'area', 'mode': 'cumulative', 'normalization': False,},\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], 'range': 'flexible', },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Margem Líquida'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': [df['03.01 - Receita Bruta']], \n",
    "    'left_1': [df['03.02 - Custo de Produção'] * -1, df['03.04 - Despesas Operacionais'] * -1, df['03.06 - Resultado Financeiro (Não Operacional)'], df['03.08 - Impostos IRPJ e CSLL'] * -1, df['03.11 - Lucro Líquido']], \n",
    "    'right': [df['16.05 - Margem Líquida (Lucro Líquido por Receita Bruta)'] * 100, ]\n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'line', 'mode': 'standalone', 'normalization': False,'range': 'flexible', },\n",
    "    'left_1': {'shape': 'area', 'mode': 'cumulative', 'normalization': False,'range': 'flexible', },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], 'range': 'half', },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Resultado e Margem Líquida'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': [df['03.01 - Receita Bruta']], \n",
    "    'left_1': [df['03.11 - Lucro Líquido']], \n",
    "    'right': [df['16.05 - Margem Líquida (Lucro Líquido por Receita Bruta)'] * 100, ]\n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'line', 'mode': 'standalone', 'normalization': False,'range': 'flexible', },\n",
    "    'left_1': {'shape': 'area', 'mode': 'cumulative', 'normalization': False,'range': 'flexible', },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], 'range': 'half', },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Patrimônio e Resultado (ROE)'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': [df['02.03 - Patrimônio Líquido']], \n",
    "    'left_1': [df['03.11 - Lucro Líquido']], \n",
    "    'right': [df['14.04.01 - ROE (Resultado por Patrimônio)'] * 100, ]\n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, },\n",
    "    'left_1': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], 'range': 'flexible'},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Capital Investido e Resultado (ROIC)'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': [df['14.03 - Capital Investido']], \n",
    "    'left_1': [df['03.05 - LAJIR EBIT Resultado Antes do Resultado Financeiro e dos Tributos']], \n",
    "    'right': [df['14.03.01 - ROIC (Retorno por Capital Investido)'] * 100, ]\n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, },\n",
    "    'left_1': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], 'range': 'flexible'},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Ativos e Resultado (ROAS)'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': [df['01 - Ativo Total']], \n",
    "    'left_1': [df['03.05 - LAJIR EBIT Resultado Antes do Resultado Financeiro e dos Tributos']], \n",
    "    'right': [df['14.05.01 - ROAS (EBIT por Ativos)'], ]\n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, },\n",
    "    'left_1': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], 'range': 'flexible'},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Ativos e Resultado (Coeficiente de Retorno)'\n",
    "trace = df['03.11 - Lucro Líquido'] / df['01 - Ativo Total']\n",
    "trace.name = 'Coeficiente de Retorno'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': [df['01 - Ativo Total']], \n",
    "    'left_1': [df['03.11 - Lucro Líquido']], \n",
    "    'right': [trace * 100, ]\n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, },\n",
    "    'left_1': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], 'range': 'flexible'},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'ROE, ROIC, ROAS e Coeficiente de Retorno'\n",
    "trace = df['03.11 - Lucro Líquido'] / df['01 - Ativo Total']\n",
    "trace.name = 'Coeficiente de Retorno'\n",
    "data = {\n",
    "    'title': [title, 'Porcentagem (%)', 'Reais (R$)', ], \n",
    "    # 'left': [df['01 - Ativo Total']], \n",
    "    # 'left_1': [df['03.11 - Lucro Líquido']], \n",
    "    'right': [df['14.04.01 - ROE (Resultado por Patrimônio)'] * 100, df['14.03.01 - ROIC (Retorno por Capital Investido)'] * 100, df['14.05.01 - ROAS (EBIT por Ativos)'] * 100, trace * 100, ]\n",
    "}\n",
    "\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, 'range': 'half'},\n",
    "    'left_1': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'range': 'half'},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Price'\n",
    "if df.TICKER[0][-1] == '3':\n",
    "    acoes = df['00.01.01 - Ações ON']\n",
    "else:\n",
    "    acoes = df['00.02.01 - Ações PN']\n",
    "\n",
    "trace = df['Adj Close'] / df['00.01.01 - Ações ON']\n",
    "trace.name = 'Preço por Ação'\n",
    "data = {\n",
    "    'title': [title, 'Porcentagem (%)', 'Reais (R$)', ], \n",
    "    'left': [df['Adj Close']], \n",
    "    'left_1': [df['03.11 - Lucro Líquido']], \n",
    "    'left_2': [acoes], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'line', 'mode': 'standalone', 'normalization': True, 'range': 'flexible'},\n",
    "    'left_1': {'shape': 'line', 'mode': 'standalone', 'normalization': True, 'range': 'flexible'},\n",
    "    'left_2': {'shape': 'line', 'mode': 'standalone', 'normalization': True, 'range': 'flexible'},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs = save_figs(figs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DASHBOARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyter_dash import JupyterDash\n",
    "import dash\n",
    "from dash import dcc\n",
    "from dash import html\n",
    "from dash.dependencies import Input, Output\n",
    "import dash_bootstrap_components as dbc\n",
    "from dash_bootstrap_templates import ThemeSwitchAIO\n",
    "from dash import dash_table\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = run.load_pkl('dash_df_merged')\n",
    "df = run.load_pkl('dash_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = run.load_pkl(f'{b3.app_folder}quotes')\n",
    "fund = run.load_pkl(f'{b3.app_folder}fund')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['AERIS', 'ESTAPAR', 'ARMAC', 'ATMASA', 'AZUL', 'BARDELLA', 'CCR SA', 'ECORODOVIAS', 'ACO ALTONA', 'EMBPAR S/A', 'EMBRAER', 'ETERNIT', 'FRAS-LE', 'GPS', 'HAGA S/A', 'HIDROVIAS', 'ROMI', 'JSL', 'KEPLER WEBER', 'LOG-IN', 'MARCOPOLO', 'METALFRIO', 'RIOSULENSE', 'METISA', 'MILLS', 'MINASMAQUINA', 'NORDON MET', 'PORTOBELLO', 'PORTO VM', 'PRINER', 'RANDON PART', 'RECRUSUL', 'RUMO S.A.', 'SANTOS BRP', 'SCHULZ', 'SEQUOIA LOG', 'SONDOTECNICA', 'TAURUS ARMAS', 'TEGMA', 'TRIUNFO PART', 'TREVISA', 'VALID', 'WEG', 'WETZEL S/A', 'WILSON SONS', 'WLM IND COM', 'BRISANET', 'BRITANIA', 'DESKTOP', 'TELEBRAS', 'TELEF BRASIL', 'UNIFIQUE', 'ALLIED', 'ALPARGATAS', 'AMERICANAS', 'ANIMA', 'AREZZO CO', 'BAHEMA', 'BAHIAPCH', 'BIC MONARK', 'ZAMP S.A.', 'CEA MODAS', 'CEABS', 'CAMBUCI', 'CEDRO', 'COTEMINAS', 'SANTANENSE', 'COGNA ON', 'TENDA', 'TENDA ATACAD', 'FICA', 'CRUZEIRO EDU', 'CURY S/A', 'CYRELA REALT', 'DIRECIONAL', 'DOHLER', 'DOTZ SA', 'EVEN', 'EZTEC', 'GRENDENE', 'GRUPO SOMA', 'GRUPO SBF', 'GUARARAPES', 'GUARUPART', 'HELBOR', 'HERCULES', 'HOTEIS OTHON', 'IMC S/A', 'IOCHP-MAXION', 'JHSF PART', 'JOAO FORTES', 'KARSTEN', 'LAVVI', 'LOCALIZA', 'QUERO-QUERO', 'LOJAS RENNER', 'MAGAZ LUIZA', 'METAL LEVE', 'ESTRELA', 'LOJAS MARISA', 'MELNICK', 'MITRE REALTY', 'MOBLY', 'MOURA DUBEUX', 'MOVIDA', 'ESPACOLASER', 'MRV', 'MUNDIAL', 'PDG REALT', 'PETZ', 'PETTENATI', 'PLANOEPLANO', 'PLASCAR PART', 'VESTE', 'RNI', 'ROSSI RESID', 'SPTURIS', 'SARAIVA LIVR', 'SER EDUCA', 'SMART FIT', 'SPRINGS', 'TIME FOR FUN', 'TECHNOS', 'TECNISA', 'TEKA', 'TEX RENAUX', 'TRACK FIELD', 'TRISUL', 'UNICASA', 'VAMOS', 'VIA', 'VIVARA S.A.', 'VIVER', 'VULCABRAS', 'WHIRLPOOL', 'YDUQS PART', 'AGROGALAXY', 'AMBEV S/A', 'CARREFOUR BR', 'BOA SAFRA', 'BOMBRIL', 'BRASILAGRO', 'BRF SA', 'CAMIL', 'EXCELSIOR', 'GRUPO MATEUS', 'JBS', 'JOSAPAR', 'MARFRIG', 'M.DIASBRANCO', 'MINERVA', 'MINUPAR', 'GRUPO NATURA', 'POMIFRUTAS', 'RAIZEN', 'SAO MARTINHO', 'ASSAI', 'SLC AGRICOLA', 'TERRASANTAPA', '3TENTOS', 'ALFA HOLDING', 'ALPER S.A.', 'APERAM', 'B3', 'BANCO BMG', 'BANESTES', 'BBSEGURIDADE', 'ALFA INVEST', 'AMAZONIA', 'BRADESCO', 'BTGP BANCO', 'BANESE', 'BANRISUL', 'MERC INVEST', 'MERCANTIL', 'NORD BRASIL', 'SANTANDER BR', 'BR PARTNERS', 'BR PROPERT', 'NEXPE', 'BRB BANCO', 'CAIXA SEGURI', 'PAR AL BAHIA', 'SEG AL BAHIA', 'CIELO', 'CLEARSALE', 'ALFA CONSORC', 'COR RIBEIRO', 'CORREDOR LOG', 'MERC FINANC', 'MERCANTII', 'MERCATO EXPR', 'MERCEDESBENZ', 'CSU DIGITAL', 'SYN PROP TEC', 'DMFINANCEIRA', 'ALFA FINANC', 'G2D INVEST', 'GENERALSHOPP', 'GP INVEST', 'HBR REALTY', 'INTER CO', 'IRBBRASIL RE', 'LOG COM PROP', 'LOPES BRASIL', 'MONT ARANHA', 'MULTIPLAN', 'MULTITERMINA', 'PORTO SEGURO', 'PPLA', 'SAO CARLOS', 'SIMPAR', 'WIZ CO', 'AURA 360', 'AURATUS', 'BRADESPAR', 'BRASKEM', 'FERBASA', 'MELHOR SP', 'SID NACIONAL', 'CBA', 'CSNMINERACAO', 'DEXCO', 'DEXXOS PAR', 'EUCATEX', 'FER HERINGER', 'GERDAU', 'IRANI', 'KLABIN S/A', 'MANGELS INDL', 'GERDAU MET', 'NUTRIPLANT', 'PANATLANTICA', 'PARANAPANEMA', 'SANSUY', 'SUZANO S.A.', 'TEKNO', 'CRISTAL', 'UNIPAR', 'USIMINAS', 'VITTIA', 'ATOMPAR', 'CEMEPE', 'INVEST BEMGE', 'POLPAR', '3R PETROLEUM', 'COSAN', 'ENAUTA PART', 'OCEANPACT', 'OSX BRASIL', 'PETRORIO', 'VIBRA', 'PET MANGUINH', 'ULTRAPAR', 'ALLIAR', 'BAUMER', 'BLAU', 'VIVEO', 'D1000VFARMA', 'DIMED', 'FLEURY', 'MATER DEI', 'HYPERA', 'KORA SAUDE', 'ODONTOPREV', 'ONCOCLINICAS', 'ONCOMED', 'OUROFINO S/A', 'PROFARMA', 'QUALICORP', 'QUALICORSEG', 'QUALITY SOFT', 'RAIADROGASIL', 'REDE D OR', 'BEMOBI TECH', 'ENJOEI', 'GETNINJAS', 'INFRACOMM', 'INTELBRAS', 'WDC NETWORKS', 'LOCAWEB', 'MELIUZ', 'MULTILASER', 'NEOGRID', 'PADTEC', 'POSITIVO TEC', 'SINQIA', 'TRADEMASTER', 'TRADIMAQ', 'TOTVS', 'WESTWING', 'AES BRASIL', 'AFLUENTE T', 'ALUPAR', 'AMBIPAR', 'AUREN', 'ELETROBRAS', 'EBRASIL', 'ELETROPAR', 'ELETROMIDIA', 'ELETROPAULO', 'ELETRORIVERS', 'ELETROZEMA', 'CELESC', 'CASAN', 'CELGPAR', 'CEG', 'CEB', 'CEMIG', 'COELCE', 'CEEE-D', 'COPEL', 'SABESP', 'SANEPAR', 'CPFL ENERGIA', 'ELEKTRO', 'EMAE', 'ENEVA', 'EQUATORIAL', 'EQTL PARA', 'LIGHT S/A', 'NEOENERGIA', 'OMEGAENERGIA', 'ORIZON', 'REDE ENERGIA', 'REDE INTEGRA', 'RENOVA', 'GER PARANAP']),\n",
       " dict_keys(['BENS INDUSTRIAIS', 'COMUNICACOES', 'CONSUMO CICLICO', 'CONSUMO NAO CICLICO', 'FINANCEIRO', 'MATERIAIS BASICOS', 'NAO CLASSIFICADOS', 'Nenhum', 'OUTROS', 'PETROLEO GAS E BIOCOMBUSTIVEIS', 'SAUDE', 'TECNOLOGIA DA INFORMACAO', 'UTILIDADE PUBLICA']))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes.keys(), fund.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fund = pd.concat(fund.values(), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fund['SETOR'].unique()\n",
    "mask_setor = df_fund['SETOR'] == 'BENS INDUSTRIAIS'\n",
    "df_fund[mask_setor]['SUBSETOR'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('BENS INDUSTRIAIS',\n",
       " 'MAQUINAS E EQUIPAMENTOS',\n",
       " 'MOTORES  COMPRESSORES E OUTROS')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company = df_merged['PREGAO'].iloc[0]\n",
    "company = 'WEG'\n",
    "setor, subsetor, segmento = df[['SETOR', 'SUBSETOR', 'SEGMENTO']].iloc[0]\n",
    "\n",
    "m_cia = df_merged['PREGAO'] != company\n",
    "m_segmento = df_merged['SEGMENTO'] == segmento\n",
    "m_subsetor = df_merged['SUBSETOR'] == subsetor\n",
    "m_setor = df_merged['SETOR'] == setor\n",
    "\n",
    "cias_segmento = [cia for cia in df_merged[m_cia & m_segmento]['PREGAO'].unique().tolist()]\n",
    "cias_subsetor = [cia for cia in df_merged[m_cia & m_subsetor]['PREGAO'].unique().tolist() if cia not in cias_segmento]\n",
    "cias_setor = [cia for cia in df_merged[m_cia & m_setor]['PREGAO'].unique().tolist() if cia not in cias_subsetor and cia not in cias_segmento]\n",
    "\n",
    "setor, subsetor, segmento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['SETOR'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "awsome = [\"https://use.fontawesome.com/releases/v5.10.2/css/all.css\"]\n",
    "# app = dash.Dash(__name__, external_stylesheets=awsome)\n",
    "app = JupyterDash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP, awsome])\n",
    "\n",
    "# Initialize setup\n",
    "tab_card = {'height': '100%'}\n",
    "main_config = {\n",
    "    'hover_mode': 'x unified', \n",
    "    'legend': \n",
    "        {\n",
    "        'yanchor': 'top',\n",
    "        'y': 0.9, \n",
    "        'xanchor': 'left', \n",
    "        'x': 0.1, \n",
    "        'title': {'text': None, }, \n",
    "        'font': {'color': 'white', }, \n",
    "        'bgcolor': 'rgba(0,0,0,0.5)', \n",
    "        }, \n",
    "    'margin': {'l':10, 'r':10, 't':10, 'b':10}, \n",
    "}\n",
    "graph_config = {\n",
    "    'displayModeBar': False, \n",
    "    'showTips': False, \n",
    "}\n",
    "template_theme_1 = 'flatly'\n",
    "template_theme_2 = 'darkly'\n",
    "url_theme_1 = dbc.themes.FLATLY\n",
    "url_theme_2 = dbc.themes.DARKLY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the layout of the app\n",
    "app.layout = dbc.Container(children=[\n",
    "    dbc.Row([ # Row 1\n",
    "        dbc.Col([ # Row 1, Col 1\n",
    "            dbc.Card([\n",
    "                dbc.CardBody([\n",
    "                    dbc.Row([ # Row 1, Col 1, Card 1 / Row 1\n",
    "                        dbc.Col([ # Row 1, Col 1, Card 1 / Row 1, Col 1\n",
    "                            html.Legend('Sobre')\n",
    "                        ], sm=8), \n",
    "                        dbc.Col([ # Row 1, Col 1, Card 1 / Row 1, Col 2\n",
    "                            html.I(className='fa fa-balance-scale', style={'font-size': '300%'})\n",
    "                        ] , sm=4, align='center'), \n",
    "                    ], style={'margin-top': '10px', }), \n",
    "                    dbc.Row([ # Row 1, Col 1, Card 1 / Row 2\n",
    "                        dbc.Col([ # Row 1, Col 1, Card 1 / Row 2, Col 1\n",
    "                            ThemeSwitchAIO(aio_id='theme', themes=[url_theme_1, url_theme_2]), \n",
    "                            html.Legend('MLGS'), \n",
    "                        ]), \n",
    "                    ], style={'margin-top': '10px', }), \n",
    "                    dbc.Row([\n",
    "                        dbc.Button('Site da B3', href='https://www.google.com', target='b3')\n",
    "                    ]), \n",
    "                ], style=tab_card), \n",
    "            ]), \n",
    "        ], sm=12, lg=3), \n",
    "        dbc.Col([ # Row 1, Col 2\n",
    "            dbc.Card([\n",
    "                dbc.CardBody([\n",
    "                    dbc.Row([ # Row 1, Col 1, Card 2 / Row 2\n",
    "                        html.Legend(f'Companhia {company}'), \n",
    "                    ]), \n",
    "                    dbc.Row([ # Row 1, Col 1, Card 2 / Row 1\n",
    "                        dbc.Col([# Row 1, Col 1, Card 2 / Row 1, Col 1\n",
    "                            html.Legend(f'Setor {setor}: Companhias {\", \".join(cias_setor)}'), \n",
    "                        ]), \n",
    "                        dbc.Col([# Row 1, Col 1, Card 2 / Row 1, Col 2\n",
    "                            html.Legend(f'SubSetor {subsetor}: Companhias {\", \".join(cias_subsetor)}'), \n",
    "                        ]), \n",
    "                        dbc.Col([# Row 1, Col 1, Card 2 / Row 1, Col 3\n",
    "                            html.Legend(f'Segmento {segmento}: Companhias {\", \".join(cias_segmento)}'), \n",
    "                        ]), \n",
    "                    ]), \n",
    "                ]), \n",
    "            ]), \n",
    "        ]), \n",
    "    ], className='g-2 my-auto', style={'matgin-top': '7px'}, ), \n",
    "], fluid=True, style={'height': '100vh'})\n",
    "\n",
    "# Run the app\n",
    "app.run_server(mode='external')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# App layout\n",
    "app.layout = dbc.Container([\n",
    "    # Row 1\n",
    "    dbc.Row([\n",
    "        # Row 1, Col 1\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    dbc.Row([ # Card Row 1\n",
    "                        dbc.Row(html.H2('Análise Fundamentalista')),\n",
    "                        dbc.Col(html.I(className='fa fa-balance-scale', style={'font-size': '300%'}), width=4, align='center'),\n",
    "                    ], style={'margin-top': '10px'}),\n",
    "                    dbc.Row([ # Card Row 2\n",
    "                        dbc.Col([\n",
    "                            ThemeSwitchAIO(aio_id='theme', themes=[url_theme_1, url_theme_2]), \n",
    "                        ]),\n",
    "                    ], style={'margin-top': '10px'}),\n",
    "                    dbc.Row([\n",
    "                        dbc.Col([\n",
    "                            dcc.Dropdown(\n",
    "                                id='setor-dropdown',\n",
    "                                options=[{'label': i, 'value': i} for i in df_fund['SETOR'].unique()],\n",
    "                                value=None,  # No default value\n",
    "                                multi=False,\n",
    "                                placeholder=\"Select a SETOR\"\n",
    "                            ),\n",
    "                        ]),\n",
    "                        dbc.Col([\n",
    "                            dcc.Dropdown(\n",
    "                                id='subsetor-dropdown',\n",
    "                                multi=False,\n",
    "                                placeholder=\"Select a SUBSETOR\"\n",
    "                            ),\n",
    "                        ]),\n",
    "                        dbc.Col([\n",
    "                            dcc.Dropdown(\n",
    "                                id='segmento-dropdown',\n",
    "                                multi=False,\n",
    "                                placeholder=\"Select a SEGMENTO\"\n",
    "                            ),\n",
    "                        ]),\n",
    "                    ]),\n",
    "                ]),\n",
    "            ),\n",
    "            width=3  # 1/4 of the width\n",
    "        ),\n",
    "        # Row 1, Col 2\n",
    "        dbc.Col(\n",
    "            [\n",
    "                # Row 1, Col 2 / Row 1\n",
    "                dbc.Row(html.H2(f'{company} {df[\"LISTAGEM\"].iloc[0]}')),\n",
    "                # Row 1, Col 2 / Row 2\n",
    "                dbc.Row([\n",
    "                    html.P([\n",
    "                        f\"{df['ATIVIDADE'].iloc[0]}\",\n",
    "                    ]), \n",
    "                    html.P([\n",
    "                        f\"{df['ESCRITURADOR'].iloc[0]}\", \" / \", \n",
    "                        html.A(f\"{df['CNPJ'].iloc[0]}\", href=f\"https://www.google.com/search?q={df['CNPJ'].iloc[0]}\", target='_blank'), \n",
    "                    ]), \n",
    "                ]),\n",
    "                # Row 2\n",
    "                dbc.Row([\n",
    "                    dbc.Col([\n",
    "                        html.Span('Setor'), html.Br(),\n",
    "                        html.Strong(f'{setor}'), html.Br(),\n",
    "                        html.P(f'{\", \".join(cias_setor)}')\n",
    "                    ]),\n",
    "                    dbc.Col([\n",
    "                        html.Span('SubSetor'), html.Br(),\n",
    "                        html.Strong(f'{subsetor}'), html.Br(),\n",
    "                        html.P(f'{\", \".join(cias_subsetor)}')\n",
    "                    ]),\n",
    "                    dbc.Col([\n",
    "                        html.Span('Segmento'), html.Br(),\n",
    "                        html.Strong(f'{segmento}'), html.Br(),\n",
    "                        html.P(f'{\", \".join(cias_segmento)}')\n",
    "                    ]),\n",
    "                ]),\n",
    "            ],\n",
    "            width=9  # 3/4 of the width\n",
    "        ),\n",
    "    ]),\n",
    "\n",
    "    # Row with 1 column\n",
    "    dbc.Row([\n",
    "        # Column 1\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    # Table to display companies\n",
    "                    dbc.Row([\n",
    "                        dbc.Col([\n",
    "                            dash_table.DataTable(\n",
    "                                id='company-table',\n",
    "                                columns=[\n",
    "                                    {\"name\": \"PREGAO\", \"id\": \"PREGAO\"},\n",
    "                                    {\"name\": \"TICKER\", \"id\": \"TICKER\"}\n",
    "                                ]\n",
    "                            )\n",
    "                        ])\n",
    "                    ])\n",
    "                ])\n",
    "            ),\n",
    "            width=12  # Full width\n",
    "        ),\n",
    "    ], style={'margin-top': '20px'}),\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Row with 1 column\n",
    "    dbc.Row([\n",
    "        # Column 1\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 1', className='card-title'),\n",
    "                    html.P('Content for column 1...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=12  # Full width\n",
    "        ),\n",
    "    ], style={'margin-top': '20px'}),\n",
    "\n",
    "    # Row with 2 columns\n",
    "    dbc.Row([\n",
    "        # Column 1\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 1', className='card-title'),\n",
    "                    html.P('Content for column 1...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=6  # Half of the width\n",
    "        ),\n",
    "        # Column 2\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 2', className='card-title'),\n",
    "                    html.P('Content for column 2...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=6  # Half of the width\n",
    "        ),\n",
    "    ], style={'margin-top': '20px'}),\n",
    "\n",
    "    # Row with 3 columns\n",
    "    dbc.Row([\n",
    "        # Row 2, Col 1\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 1', className='card-title'),\n",
    "                    html.P('Content for column 1...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=4  # 1/3 of the width\n",
    "        ),\n",
    "        # Row 2, Col 2\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 2', className='card-title'),\n",
    "                    html.P('Content for column 2...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=4  # 1/3 of the width\n",
    "        ),\n",
    "        # Row 2, Col 3\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 3', className='card-title'),\n",
    "                    html.P('Content for column 3...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=4  # 1/3 of the width\n",
    "        ),\n",
    "    ], style={'margin-top': '20px'}),  # Added margin for better visual separation of the rows\n",
    "\n",
    "    # Row with 4 columns\n",
    "    dbc.Row([\n",
    "        # Column 1\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 1', className='card-title'),\n",
    "                    html.P('Content for column 1...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=3  # 1/4 of the width\n",
    "        ),\n",
    "        # Column 2\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 2', className='card-title'),\n",
    "                    html.P('Content for column 2...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=3  # 1/4 of the width\n",
    "        ),\n",
    "        # Column 3\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 3', className='card-title'),\n",
    "                    html.P('Content for column 3...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=3  # 1/4 of the width\n",
    "        ),\n",
    "        # Column 4\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 4', className='card-title'),\n",
    "                    html.P('Content for column 4...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=3  # 1/4 of the width\n",
    "        ),\n",
    "    ], style={'margin-top': '20px'}),\n",
    "\n",
    "    # Row with 5 columns\n",
    "    dbc.Row([\n",
    "        # Column 1\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 1', className='card-title'),\n",
    "                    html.P('Content for column 1...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "        ),\n",
    "        # Column 2\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 2', className='card-title'),\n",
    "                    html.P('Content for column 2...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "        ),\n",
    "        # Column 3\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 3', className='card-title'),\n",
    "                    html.P('Content for column 3...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "        ),\n",
    "        # Column 4\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 4', className='card-title'),\n",
    "                    html.P('Content for column 4...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "        ),\n",
    "        # Column 5\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 5', className='card-title'),\n",
    "                    html.P('Content for column 5...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "        ),\n",
    "    ], style={'margin-top': '20px'}),\n",
    "\n",
    "    # Row with 6 columns\n",
    "    dbc.Row([\n",
    "        # Column 1\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 1', className='card-title'),\n",
    "                    html.P('Content for column 1...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=2  # 1/6 of the width\n",
    "        ),\n",
    "        # Column 2\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 2', className='card-title'),\n",
    "                    html.P('Content for column 2...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=2  # 1/6 of the width\n",
    "        ),\n",
    "        # Column 3\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 3', className='card-title'),\n",
    "                    html.P('Content for column 3...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=2  # 1/6 of the width\n",
    "        ),\n",
    "        # Column 4\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 4', className='card-title'),\n",
    "                    html.P('Content for column 4...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=2  # 1/6 of the width\n",
    "        ),\n",
    "        # Column 5\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 5', className='card-title'),\n",
    "                    html.P('Content for column 5...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=2  # 1/6 of the width\n",
    "        ),\n",
    "        # Column 6\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 6', className='card-title'),\n",
    "                    html.P('Content for column 6...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=2  # 1/6 of the width\n",
    "        ),\n",
    "    ], style={'margin-top': '20px'}),\n",
    "\n",
    "], fluid=True)\n",
    "\n",
    "\n",
    "# Update SUBSETOR options based on SETOR\n",
    "@app.callback(\n",
    "    Output('subsetor-dropdown', 'options'),\n",
    "    Input('setor-dropdown', 'value')\n",
    ")\n",
    "def update_subsetor_options(selected_setor):\n",
    "    try:  # Add error handling\n",
    "        if selected_setor:\n",
    "            mask = df_fund['SETOR'] == selected_setor\n",
    "            options = [{'label': i, 'value': i} for i in df_fund[mask]['SUBSETOR'].unique()]\n",
    "        else:\n",
    "            options = []\n",
    "        return options\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")  # Log error\n",
    "        return []  # Return empty options in case of error\n",
    "\n",
    "\n",
    "# Update SEGMENTO options based on SUBSETOR\n",
    "@app.callback(\n",
    "    Output('segmento-dropdown', 'options'),\n",
    "    Input('subsetor-dropdown', 'value')\n",
    ")\n",
    "def update_segmento_options(selected_subsetor):\n",
    "    try:\n",
    "        if selected_subsetor:\n",
    "            mask = df_fund['SUBSETOR'] == selected_subsetor\n",
    "            options = [{'label': i, 'value': i} for i in df_fund[mask]['SEGMENTO'].unique()]\n",
    "        else:\n",
    "            options = []\n",
    "        return options\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "# Update company table based on SETOR, SUBSETOR, and SEGMENTO\n",
    "@app.callback(\n",
    "    Output('company-table', 'data'),\n",
    "    [\n",
    "        Input('setor-dropdown', 'value'),\n",
    "        Input('subsetor-dropdown', 'value'),\n",
    "        Input('segmento-dropdown', 'value'),\n",
    "    ]\n",
    ")\n",
    "def update_table(selected_setor, selected_subsetor, selected_segmento):\n",
    "    try:\n",
    "        mask = ((df_fund['SETOR'] == selected_setor) if selected_setor else True) & \\\n",
    "               ((df_fund['SUBSETOR'] == selected_subsetor) if selected_subsetor else True) & \\\n",
    "               ((df_fund['SEGMENTO'] == selected_segmento) if selected_segmento else True)\n",
    "        data = df_fund[mask][[\"PREGAO\", \"TICKER\"]].to_dict('records')  # Only show specified columns\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "# Run the app\n",
    "app.run_server(mode='external')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create the fundamental analysis card\n",
    "def fundamental_analysis_card():\n",
    "    return dbc.Card(\n",
    "        dbc.CardBody([\n",
    "            dbc.Row([ \n",
    "                dbc.Col(html.H2('Análise Fundamentalista'), width=8),\n",
    "                dbc.Col(html.I(className='fa fa-balance-scale', style={'font-size': '300%'}), width=4, align='center'),\n",
    "            ], style={'margin-top': '10px'}),\n",
    "            dbc.Row([\n",
    "                dbc.Col([\n",
    "                    ThemeSwitchAIO(aio_id='theme', themes=[\"url_theme_1\", \"url_theme_2\"]), \n",
    "                ]),\n",
    "            ], style={'margin-top': '10px'}),\n",
    "            dbc.Row([\n",
    "                dbc.Col([\n",
    "                    dbc.Button(f'MAIS INFO SOBRE', href=f\"#\", target='_blank'), \n",
    "                ]),\n",
    "            ], style={'margin-top': '10px'}),\n",
    "        ])\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create the setor and subsetor dropdown selectors\n",
    "def selectors():\n",
    "    return dbc.Row([\n",
    "        dbc.Col([\n",
    "            dcc.Dropdown(\n",
    "                id='setor-dropdown',\n",
    "                options=[{'label': i, 'value': i} for i in df_fund['SETOR'].unique()],\n",
    "                value=None,  \n",
    "                multi=False,\n",
    "                placeholder=\"Select a SETOR\"\n",
    "            ),\n",
    "        ]),\n",
    "        dbc.Col([\n",
    "            dcc.Dropdown(\n",
    "                id='subsetor-dropdown',\n",
    "                multi=False,\n",
    "                placeholder=\"Select a SUBSETOR\"\n",
    "            ),\n",
    "        ]),\n",
    "        dbc.Col([\n",
    "            dcc.Dropdown(\n",
    "                id='segmento-dropdown',\n",
    "                multi=False,\n",
    "                placeholder=\"Select a SEGMENTO\"\n",
    "            ),\n",
    "        ]),\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_creator(content_dict):\n",
    "    \"\"\"\n",
    "    Create a list of Dash HTML components.\n",
    "\n",
    "    Parameters:\n",
    "        content_dict (dict): A dictionary containing 'title' and 'content' keys.\n",
    "        'content' can be a string or a list of strings, each of which is rendered as a new paragraph.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list containing Dash HTML components.\n",
    "    \"\"\"\n",
    "    # Ensure content is a list using a ternary expression\n",
    "    content = content_dict['content'] if isinstance(content_dict['content'], list) else [content_dict['content']]\n",
    "    \n",
    "    # Create a paragraph for each item in content\n",
    "    paragraphs = [html.P(item, className='card-text') for item in content]\n",
    "    \n",
    "    # Concatenate title and paragraphs and return\n",
    "    return [html.H5(content_dict['title'], className='card-title')] + paragraphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_2_left(col1_content, col2_content):\n",
    "    return dbc.Row([\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody(col1_content)\n",
    "            ),\n",
    "            width=3\n",
    "        ),\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody(col2_content)\n",
    "            ),\n",
    "            width=9\n",
    "        ),\n",
    "    ], style={'margin-top': '20px'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create the company information card\n",
    "def company_info_card(company, df, setor, cias_setor, subsetor, cias_subsetor, segmento, cias_segmento):\n",
    "    return dbc.Card(\n",
    "        dbc.CardBody([\n",
    "            dbc.Row(html.H2(f'{company} {df[\"LISTAGEM\"].iloc[0]}')),\n",
    "            dbc.Row([\n",
    "                html.P([\n",
    "                    f\"{df['ATIVIDADE'].iloc[0]}\",\n",
    "                ]), \n",
    "                html.P([\n",
    "                    f\"{df['ESCRITURADOR'].iloc[0]}\", \" / \", \n",
    "                    html.A(f\"{df['CNPJ'].iloc[0]}\", href=f\"https://www.google.com/search?q={df['CNPJ'].iloc[0]}\", target='_blank'), \n",
    "                ]), \n",
    "            ]),\n",
    "            dbc.Row([\n",
    "                dbc.Col([\n",
    "                    html.Span('Setor'), html.Br(),\n",
    "                    html.Strong(f'{setor}'), html.Br(),\n",
    "                    html.P(f'{\", \".join(cias_setor)}')\n",
    "                ]),\n",
    "                dbc.Col([\n",
    "                    html.Span('SubSetor'), html.Br(),\n",
    "                    html.Strong(f'{subsetor}'), html.Br(),\n",
    "                    html.P(f'{\", \".join(cias_subsetor)}')\n",
    "                ]),\n",
    "                dbc.Col([\n",
    "                    html.Span('Segmento'), html.Br(),\n",
    "                    html.Strong(f'{segmento}'), html.Br(),\n",
    "                    html.P(f'{\", \".join(cias_segmento)}')\n",
    "                ]),\n",
    "            ]),\n",
    "        ])\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "content_1_1 = {\n",
    "    'title': 'Análise Fundamentalista',\n",
    "    'content': [\n",
    "        'Dark/Light Theme', \n",
    "        'Select 1', \n",
    "        'Select 2', \n",
    "        'Select 3', \n",
    "        ]\n",
    "}\n",
    "\n",
    "content_1_2 = {\n",
    "    'title': f'{company}',\n",
    "    'content': [\n",
    "    f\"{df['ATIVIDADE'].iloc[0]}\", \n",
    "    f\"{setor} > {subsetor} > {segmento}\", \n",
    "\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def card(content):\n",
    "    # Check if header exists and create CardHeader if it does\n",
    "    header = dbc.CardHeader(content['header']) if 'header' in content else None\n",
    "    \n",
    "    # Check if body exists and create CardBody if it does\n",
    "    body = dbc.CardBody(content['body']) if 'body' in content else None\n",
    "    \n",
    "    # Check if footer exists and create CardFooter if it does\n",
    "    footer = dbc.CardFooter(content['footer']) if 'footer' in content else None\n",
    "    \n",
    "    # Return dbc.Card with available components\n",
    "    return dbc.Card([component for component in [header, body, footer] if component is not None])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = {\n",
    "    'header': [\n",
    "        html.H2('Header', className='card-title'),\n",
    "    ], \n",
    "    'body': [\n",
    "        html.H5('Subheader', className='card-title'),\n",
    "        html.P('Some paragraph text'),\n",
    "        html.P('Another paragraph'),\n",
    "        dbc.Button('Click me', color='primary'),\n",
    "    ], \n",
    "    'footer': [\n",
    "        html.A('Go to Google', href='https://www.google.com', target='_blank'), \n",
    "    ], \n",
    "}\n",
    "example_2 = {\n",
    "    # 'header': [\n",
    "    #     html.H2('Header', className='card-title'),\n",
    "    # ], \n",
    "    'body': [\n",
    "        html.H5('Subheader', className='card-title'),\n",
    "        html.P('Some paragraph text'),\n",
    "        html.P('Another paragraph'),\n",
    "        dbc.Button('Click me', color='primary'),\n",
    "    ], \n",
    "    # 'footer': [\n",
    "    #     html.A('Go to Google', href='https://www.google.com', target='_blank'), \n",
    "    # ], \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8050/\n"
     ]
    }
   ],
   "source": [
    "# App layout\n",
    "app.layout = dbc.Container([\n",
    "    card(example), \n",
    "    card(example), \n",
    "], fluid=True)\n",
    "\n",
    "# Run the app\n",
    "app.run_server(mode='external')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8050/\n"
     ]
    }
   ],
   "source": [
    "# App layout\n",
    "app.layout = dbc.Container([\n",
    "    # Example Row 1 with 1 column\n",
    "    dbc.Row([\n",
    "        dbc.Col(card(example), width=12)\n",
    "    ], style={'margin-top': '20px'}),\n",
    "    \n",
    "    # Example Row 2 with 2 columns\n",
    "    dbc.Row([\n",
    "        dbc.Col(card(example), width=6),\n",
    "        dbc.Col(card(example_2), width=6),\n",
    "    ], style={'margin-top': '20px'}),\n",
    "    \n",
    "    # Example Row 3 with 3 columns\n",
    "    dbc.Row([\n",
    "        dbc.Col(card(example), width=4),\n",
    "        dbc.Col(card(example), width=4),\n",
    "        dbc.Col(card(example_2), width=4),\n",
    "    ], style={'margin-top': '20px'}),\n",
    "    \n",
    "    # Example Row 4 with 4 columns\n",
    "    dbc.Row([\n",
    "        dbc.Col(card(example), width=3),\n",
    "        dbc.Col(card(example), width=3),\n",
    "        dbc.Col(card(example), width=3),\n",
    "        dbc.Col(card(example_2), width=3),\n",
    "    ], style={'margin-top': '20px'}),\n",
    "    \n",
    "    # Example Row 5 with 5 columns\n",
    "    dbc.Row([\n",
    "        dbc.Col(card(example),),\n",
    "        dbc.Col(card(example),),\n",
    "        dbc.Col(card(example),),\n",
    "        dbc.Col(card(example),),\n",
    "        dbc.Col(card(example_2),),\n",
    "    ], style={'margin-top': '20px'}),\n",
    "\n",
    "    # Example Row 6 with 6 columns\n",
    "    dbc.Row([\n",
    "        dbc.Col(card(example), width=2),\n",
    "        dbc.Col(card(example), width=2),\n",
    "        dbc.Col(card(example), width=2),\n",
    "        dbc.Col(card(example), width=2),\n",
    "        dbc.Col(card(example), width=2),\n",
    "        dbc.Col(card(example_2), width=2),\n",
    "    ], style={'margin-top': '20px'}),\n",
    "], fluid=True)\n",
    "\n",
    "# Run the app\n",
    "app.run_server(mode='external')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.layout = dbc.Container([\n",
    "   # Row with 1 column\n",
    "    dbc.Row([\n",
    "        # Column 1\n",
    "        dbc.Col(\n",
    "            card(example), \n",
    "            width=12  # Full width\n",
    "        ),\n",
    "    ], style={'margin-top': '20px'}),\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Row with 1 column\n",
    "    dbc.Row([\n",
    "        # Column 1\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 1', className='card-title'),\n",
    "                    html.P('Content for column 1...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=12  # Full width\n",
    "        ),\n",
    "    ], style={'margin-top': '20px'}),\n",
    "\n",
    "    # Row with 2 columns\n",
    "    dbc.Row([\n",
    "        # Column 1\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 1', className='card-title'),\n",
    "                    html.P('Content for column 1...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=6  # Half of the width\n",
    "        ),\n",
    "        # Column 2\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 2', className='card-title'),\n",
    "                    html.P('Content for column 2...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=6  # Half of the width\n",
    "        ),\n",
    "    ], style={'margin-top': '20px'}),\n",
    "\n",
    "    # Row with 3 columns\n",
    "    dbc.Row([\n",
    "        # Row 2, Col 1\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 1', className='card-title'),\n",
    "                    html.P('Content for column 1...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=4  # 1/3 of the width\n",
    "        ),\n",
    "        # Row 2, Col 2\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 2', className='card-title'),\n",
    "                    html.P('Content for column 2...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=4  # 1/3 of the width\n",
    "        ),\n",
    "        # Row 2, Col 3\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 3', className='card-title'),\n",
    "                    html.P('Content for column 3...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=4  # 1/3 of the width\n",
    "        ),\n",
    "    ], style={'margin-top': '20px'}),  # Added margin for better visual separation of the rows\n",
    "\n",
    "    # Row with 4 columns\n",
    "    dbc.Row([\n",
    "        # Column 1\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 1', className='card-title'),\n",
    "                    html.P('Content for column 1...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=3  # 1/4 of the width\n",
    "        ),\n",
    "        # Column 2\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 2', className='card-title'),\n",
    "                    html.P('Content for column 2...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=3  # 1/4 of the width\n",
    "        ),\n",
    "        # Column 3\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 3', className='card-title'),\n",
    "                    html.P('Content for column 3...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=3  # 1/4 of the width\n",
    "        ),\n",
    "        # Column 4\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 4', className='card-title'),\n",
    "                    html.P('Content for column 4...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=3  # 1/4 of the width\n",
    "        ),\n",
    "    ], style={'margin-top': '20px'}),\n",
    "\n",
    "    # Row with 5 columns\n",
    "    dbc.Row([\n",
    "        # Column 1\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 1', className='card-title'),\n",
    "                    html.P('Content for column 1...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "        ),\n",
    "        # Column 2\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 2', className='card-title'),\n",
    "                    html.P('Content for column 2...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "        ),\n",
    "        # Column 3\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 3', className='card-title'),\n",
    "                    html.P('Content for column 3...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "        ),\n",
    "        # Column 4\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 4', className='card-title'),\n",
    "                    html.P('Content for column 4...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "        ),\n",
    "        # Column 5\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 5', className='card-title'),\n",
    "                    html.P('Content for column 5...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "        ),\n",
    "    ], style={'margin-top': '20px'}),\n",
    "\n",
    "    # Row with 6 columns\n",
    "    dbc.Row([\n",
    "        # Column 1\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 1', className='card-title'),\n",
    "                    html.P('Content for column 1...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=2  # 1/6 of the width\n",
    "        ),\n",
    "        # Column 2\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 2', className='card-title'),\n",
    "                    html.P('Content for column 2...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=2  # 1/6 of the width\n",
    "        ),\n",
    "        # Column 3\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 3', className='card-title'),\n",
    "                    html.P('Content for column 3...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=2  # 1/6 of the width\n",
    "        ),\n",
    "        # Column 4\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 4', className='card-title'),\n",
    "                    html.P('Content for column 4...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=2  # 1/6 of the width\n",
    "        ),\n",
    "        # Column 5\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 5', className='card-title'),\n",
    "                    html.P('Content for column 5...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=2  # 1/6 of the width\n",
    "        ),\n",
    "        # Column 6\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 6', className='card-title'),\n",
    "                    html.P('Content for column 6...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=2  # 1/6 of the width\n",
    "        ),\n",
    "    ], style={'margin-top': '20px'}),\n",
    "\n",
    "], fluid=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
