{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import assets.helper as b3\n",
    "import assets.functions as run\n",
    "\n",
    "from typing import Dict, Union, List, Optional, Any\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import os\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "import plotly.graph_objects as go\n",
    "from plotly.graph_objs import Figure\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge Mix and Match all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    math = run.load_pkl(f'{b3.app_folder}math')\n",
    "except Exception as e:\n",
    "    math = run.get_math()\n",
    "    math = run.save_pkl(math, f'{b3.app_folder}math')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    setorial = run.load_pkl(f'{b3.app_folder}setorial')\n",
    "except Exception as e:\n",
    "    setorial = run.get_classificacao_setorial(setorial='')\n",
    "    setorial = run.save_pkl(setorial, f'{b3.app_folder}setorial')\n",
    "# setorial.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    b3_cvm = run.load_pkl(f'{b3.app_folder}b3_cvm')\n",
    "except Exception as e:\n",
    "    b3_cvm = run.b3_grab(b3.search_url)\n",
    "    b3_cvm = run.save_pkl(b3_cvm, f'{b3.app_folder}b3_cvm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETOR: O setor econômico mais amplo ao qual a empresa pertence.\n",
    "# SUBSETOR: Uma categorização mais específica dentro do setor mais amplo.\n",
    "# SEGMENTO: Uma classificação ainda mais granular do negócio da empresa.\n",
    "# DENOM_CIA: Esta é a denominação ou nome da empresa.\n",
    "# COMPANHIA: Nome ou denominação oficial da empresa listada.\n",
    "# PREGAO: Refere-se ao nome pelo qual a empresa é conhecida no pregão da bolsa de valores.\n",
    "# LISTAGEM: Categoria ou segmento de listagem da empresa na bolsa de valores, que pode indicar o nível de governança corporativa ou outros critérios.\n",
    "# TICK: Abreviação ou símbolo da empresa usada no mercado de ações.\n",
    "# TICKERS: Símbolos de negociação da empresa em diferentes mercados ou plataformas.\n",
    "# CD_CVM: Este poderia ser um código ou identificador único relacionado à empresa, possivelmente relacionado à Comissão de Valores Mobiliários do Brasil (CVM).\n",
    "# CVM: Código ou identificador relacionado à empresa na Comissão de Valores Mobiliários, o órgão regulador do mercado de capitais no Brasil.\n",
    "# ISIN: Número de Identificação Internacional de Valores Mobiliários – um identificador único para valores mobiliários.\n",
    "# CNPJ_CIA: Este é o número do Cadastro Nacional da Pessoa Jurídica (CNPJ) da empresa, um identificador único para empresas no Brasil.\n",
    "# CNPJ: Cadastro Nacional da Pessoa Jurídica – é o número de identificação das empresas brasileiras.\n",
    "# SITE: Site oficial ou página relevante da empresa.\n",
    "# ATIVIDADE: Descreve a principal atividade de negócios da empresa.\n",
    "\n",
    "# ANO: Este é o ano ao qual os dados se referem.\n",
    "# DT_REFER: Esta é a data de referência para a entrada de dados.\n",
    "# DT_FIM_EXERC: Esta é a data final para o exercício ou período de relato financeiro.\n",
    "# DT_INI_EXERC: Esta poderia ser a data inicial para o exercício ou período de relato financeiro.\n",
    "\n",
    "# AGRUPAMENTO: Isso descreve o nível de agregação dos dados. Por exemplo, 'con' pode indicar dados consolidados.\n",
    "# BALANCE_SHEET: Isso indica a seção específica da demonstração financeira, como Balanço Patrimonial ('BPA').\n",
    "# GRUPO_DFP: Isso representa o tipo de grupo de demonstração financeira. Por exemplo, 'DF Consolidado - Balanço Patrimonial Ativo' sugere que é um balanço patrimonial consolidado focado em ativos.\n",
    "# CD_CONTA: Este poderia ser um código ou identificador único relacionado a uma conta específica ou item de linha na demonstração financeira.\n",
    "# DS_CONTA: Descreve a conta específica ou item de linha na demonstração financeira, como 'Ativo Total'.\n",
    "\n",
    "# VL_CONTA: Representa o valor associado à conta específica ou item de linha.\n",
    "# MOEDA: Isso indica a moeda na qual os valores são representados. 'REAL' sugere Real Brasileiro.\n",
    "# ESCALA_MOEDA: Isso fornece a escala ou unidade para os valores monetários. 'MIL' pode indicar que os valores estão em milhares.\n",
    "\n",
    "# ST_CONTA_FIXA: Pode indicar o status ou tipo de conta. O significado de valores como 'S' dependeria do contexto dos dados.\n",
    "# COLUNA_DF: O propósito desta coluna não é imediatamente claro a partir da amostra. Pode representar algum tipo de classificação ou categorização relacionada aos dados financeiros.\n",
    "\n",
    "# ESCRITURADOR: Entidade ou empresa responsável por registrar ou gerenciar os valores mobiliários da empresa.\n",
    "# ACIONISTAS: Informações ou identificadores relacionados aos acionistas da empresa.\n",
    "\n",
    "# FILENAME: Este é o arquivo de onde os dados são originados. Ele fornece o nome do arquivo que contém a respectiva entrada de dados.\n",
    "# DEMONSTRATIVO: Este representa o tipo de demonstração financeira. Pode indicar se os dados são de um relatório intermediário (como 'itr') ou de outro tipo de relatório financeiro.\n",
    "# VERSAO: Isso pode representar a versão ou iteração dos dados/relatórios financeiros.\n",
    "\n",
    "columns = [\n",
    "    'SETOR_x',\n",
    "    'SUBSETOR_x',\n",
    "    'SEGMENTO_x',\n",
    "    'DENOM_CIA',\n",
    "        # 'COMPANHIA',\n",
    "    'PREGAO',\n",
    "    'LISTAGEM',\n",
    "    'TICK',\n",
    "    'TICKERS',\n",
    "    'CD_CVM',\n",
    "        # 'CVM',\n",
    "        # 'ISIN',\n",
    "    'CNPJ_CIA',\n",
    "        # 'CNPJ',\n",
    "    'SITE',\n",
    "    'ATIVIDADE',\n",
    "        # 'ANO',\n",
    "    'DT_REFER',\n",
    "        # 'DT_FIM_EXERC',\n",
    "        # 'DT_INI_EXERC',\n",
    "    'AGRUPAMENTO',\n",
    "    'BALANCE_SHEET',\n",
    "    # 'GRUPO_DFP',\n",
    "    'CD_CONTA',\n",
    "    'DS_CONTA',\n",
    "    'VL_CONTA',\n",
    "    # 'MOEDA',\n",
    "    # 'ESCALA_MOEDA',\n",
    "    # 'ST_CONTA_FIXA',\n",
    "    # 'COLUNA_DF',\n",
    "    'ESCRITURADOR',\n",
    "    'ACIONISTAS', \n",
    "    # 'FILENAME', \n",
    "    # 'DEMONSTRATIVO', \n",
    "    # 'VERSAO',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b3_cvm.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['FILENAME', 'DEMONSTRATIVO', 'BALANCE_SHEET', 'ANO', 'AGRUPAMENTO',\n",
    "       'CNPJ_CIA', 'DT_REFER', 'VERSAO', 'DENOM_CIA', 'CD_CVM', 'GRUPO_DFP',\n",
    "       'MOEDA', 'ESCALA_MOEDA', 'DT_FIM_EXERC', 'CD_CONTA', 'DS_CONTA',\n",
    "       'VL_CONTA', 'ST_CONTA_FIXA', 'DT_INI_EXERC', 'COLUNA_DF', 'COMPANHIA',\n",
    "       'PREGAO', 'TICK', 'LISTAGEM', 'TICKERS', 'ISIN', \n",
    "       'ATIVIDADE', 'SETOR', 'SUBSETOR', 'SEGMENTO', 'SITE', 'ESCRITURADOR',]\n",
    "df = b3_cvm['CONSUMO CICLICO'][columns].set_index('DT_REFER')\n",
    "df = convert_columns(df)\n",
    "df['DENOM_CIA'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acoes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acoes = run.load_pkl(f'{b3.app_folder}acoes')\n",
    "# Process the data and return the result\n",
    "acoes['Trimestre'] = pd.to_datetime(acoes['Trimestre'], errors='coerce', dayfirst=True)\n",
    "acoes['BALANCE_SHEET'] = 'STK'\n",
    "column_mapping = {\n",
    "    'Ações ON': '00.01.01',\n",
    "    'Ações PN': '00.02.01',\n",
    "    'Ações ON em Tesouraria': '00.01.02',\n",
    "    'Ações PN em Tesouraria': '00.02.02'\n",
    "}\n",
    "acoes = acoes.rename(columns={\"Companhia\": \"DENOM_CIA\", \"Trimestre\": \"DT_REFER\"})\n",
    "\n",
    "acoes = acoes.melt(id_vars=['DENOM_CIA', 'DT_REFER', 'BALANCE_SHEET'], \n",
    "                        value_vars=['Ações ON', 'Ações PN', 'Ações ON em Tesouraria', 'Ações PN em Tesouraria'],\n",
    "                        var_name='DS_CONTA', value_name='VL_CONTA').sort_values(by=['DENOM_CIA', 'DT_REFER', 'DS_CONTA'])\n",
    "\n",
    "acoes['CD_CONTA'] = acoes['DS_CONTA'].map(column_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intel_b3 = run.load_pkl(f'{b3.app_folder}intel_b3')\n",
    "df = intel_b3['BENS INDUSTRIAIS']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company = 'ARMAC LOCACAO LOGISTICA E SERVICOS SA'\n",
    "quarter = '2019-12-31'\n",
    "mc = acoes['DENOM_CIA'] == company\n",
    "mc &= acoes['DT_REFER'] == quarter\n",
    "acoesc = acoes[mc]\n",
    "\n",
    "mc = df['DENOM_CIA'] == company\n",
    "mc &= df['DT_REFER'] == quarter\n",
    "dfc = df[mc]\n",
    "\n",
    "df_ffill = pd.concat([dfc, acoesc], ignore_index=True).ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_stock_data(group):\n",
    "    company, quarter = group.name\n",
    "    \n",
    "    # Filter acoes based on company and quarter\n",
    "    mc = acoes['DENOM_CIA'] == company\n",
    "    mc &= acoes['DT_REFER'] == quarter\n",
    "    acoesc = acoes[mc]\n",
    "\n",
    "    # Concatenate and ffill\n",
    "    return pd.concat([group, acoesc], ignore_index=True).ffill()\n",
    "\n",
    "result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_ffill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intelacoes = {}\n",
    "for setor, df in intel_b3.items():\n",
    "    print(setor)\n",
    "    df_concat = pd.concat([df.set_index(['DENOM_CIA', 'DT_REFER']), acoes.set_index(['DENOM_CIA', 'DT_REFER'])], axis=0, sort=False).reset_index()\n",
    "    filled_df = df_concat.groupby(['DENOM_CIA', 'DT_REFER'], group_keys=False).apply(lambda group: group.ffill().bfill()).reset_index()\n",
    "    intelacoes[setor] = filled_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate them vertically\n",
    "df_concat = pd.concat([df.set_index(['DENOM_CIA', 'DT_REFER']), acoes.set_index(['DENOM_CIA', 'DT_REFER'])], axis=0, sort=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_df = df_concat.groupby(['DENOM_CIA', 'DT_REFER'], group_keys=False).apply(lambda group: group.ffill().bfill()).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = filled_df['DENOM_CIA'] == 'ARMAC LOCACAO LOGISTICA E SERVICOS SA'\n",
    "m &= filled_df['DT_REFER'] == '2019-12-31'\n",
    "m &= filled_df['BALANCE_SHEET'] == 'STK'\n",
    "\n",
    "filled_df[m][cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b3_cvm = run.load_pkl(f'{b3.app_folder}b3_cvm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_types = {'index': 'int',\n",
    " 'FILENAME': 'category',\n",
    " 'DEMONSTRATIVO': 'category',\n",
    " 'BALANCE_SHEET': 'category',\n",
    " 'ANO': 'category',\n",
    " 'AGRUPAMENTO': 'category',\n",
    " 'CNPJ_CIA': 'category',\n",
    " 'DT_REFER': 'object',\n",
    " 'VERSAO': 'category',\n",
    " 'DENOM_CIA': 'category',\n",
    " 'CD_CVM': 'category',\n",
    " 'GRUPO_DFP': 'category',\n",
    " 'MOEDA': 'category',\n",
    " 'ESCALA_MOEDA': 'category',\n",
    " 'DT_FIM_EXERC': 'object',\n",
    " 'CD_CONTA': 'category',\n",
    " 'DS_CONTA': 'category',\n",
    " 'VL_CONTA': 'float',\n",
    " 'ST_CONTA_FIXA': 'category',\n",
    " 'DT_INI_EXERC': 'object',\n",
    " 'COLUNA_DF': 'category',\n",
    " 'COMPANHIA': 'category',\n",
    " 'PREGAO': 'category',\n",
    " 'TICK': 'category',\n",
    " 'LISTAGEM': 'category',\n",
    " 'CVM': 'category',\n",
    " 'TICKERS': 'category',\n",
    " 'ISIN': 'category',\n",
    " 'CNPJ': 'category',\n",
    " 'ATIVIDADE': 'category',\n",
    " 'SETOR': 'category',\n",
    " 'SUBSETOR': 'category',\n",
    " 'SEGMENTO': 'category',\n",
    " 'SITE': 'category',\n",
    " 'ESCRITURADOR': 'category',\n",
    " 'CD_CONTA_original': 'category',\n",
    " 'DS_CONTA_original': 'category'}\n",
    "date_columns = ['DT_REFER', 'DT_FIM_EXERC', 'DT_INI_EXERC']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('BENS INDUSTRIAIS_intel.csv', dtype=column_types, index_col='Unnamed: 0', parse_dates=True)\n",
    "# df = pd.read_csv('COMUNICACOES_df.csv')\n",
    "# df_typed = pd.read_csv(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um dicionário onde as chaves são os nomes das colunas e os valores são os valores únicos para cada coluna\n",
    "col_dict = {col: df[col].unique().tolist() for col in df.columns}\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_dict['BALANCE_SHEET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['CNPJ_CIA', 'DENOM_CIA', 'DT_REFER', 'CD_CONTA', 'DS_CONTA', 'VL_CONTA', 'SETOR', 'SUBSETOR', 'SEGMENTO', 'DT_INI_EXERC', 'ATIVIDADE', 'SITE', 'ESCRITURADOR', 'FILENAME', 'DEMONSTRATIVO', 'BALANCE_SHEET', 'ANO', 'AGRUPAMENTO', 'VERSAO', 'GRUPO_DFP', 'MOEDA', 'ESCALA_MOEDA', 'ST_CONTA_FIXA', 'COLUNA_DF', 'COMPANHIA', 'TICKERS', 'CVM', 'ISIN', 'DT_FIM_EXERC', ]]\n",
    "# 'PREGAO', 'TICK', 'CD_CVM', 'LISTAGEM', # 'CD_CONTA_original', 'DS_CONTA_original', \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formulas_old = [\n",
    "    # Relações Entre Ativos e Passivos\n",
    "    ('_020302_reservas_de_capital', '_020303_reservas_de_reavaliacao', '_020304_reservas_de_lucros'),\n",
    "    # Dívida\n",
    "    ('_0201040101_emprestimos_e_financiamentos_em_moeda_nacional', '_0201040102_emprestimos_e_financiamentos_em_moeda_estrangeira', '_02010402_debentures', '_02010403_arrendamentos', '_02010409_outros_emprestimos_financiamentos_e_debentures'),\n",
    "    ('_0202010101_emprestimos_e_financiamentos_em_moeda_nacional', '_0202010102_emprestimos_e_financiamentos_em_moeda_estrangeira', '_02020102_debentures', '_02020103_arrendamentos', '_02020209_outros_emprestimos_financiamentos_e_debentures'),\n",
    "    ('_0201040102_emprestimos_e_financiamentos_em_moeda_estrangeira', '_0202010102_emprestimos_e_financiamentos_em_moeda_estrangeira'),\n",
    "    ('_010101_caixa_e_disponibilidades_de_caixa',),\n",
    "    ('_010202_investimentos_nao_capex', '_010203_imobilizados', '_010204_intangivel'),\n",
    "    ('_0305_lajir_ebit_resultado_antes_do_resultado_financeiro_e_dos_tributos', '_070401_depreciacao_e_amortizacao'),\n",
    "    # Resultados Fundamentalistas\n",
    "    ('_0203_patrimonio_liquido',),\n",
    "    ('_010101_caixa_e_disponibilidades_de_caixa',),\n",
    "    ('_070803_remuneracao_de_capital_de_terceiros', '_070804_remuneracao_de_capital_proprio'),\n",
    "    # Análise do Fluxo de Caixa\n",
    "    ('_0601_caixa_das_operacoes', '_0602_caixa_de_investimentos_capex'),\n",
    "    ('_0603_caixa_de_financiamento',),\n",
    "    ('_060201_investimentos', '_060202_imobilizado_e_intangivel'),\n",
    "]\n",
    "\n",
    "def de_transform_corrected(key):\n",
    "    # Strip the leading underscore and split at the first underscore\n",
    "    parts = key[1:].split('_', 1)\n",
    "\n",
    "    # Adjust code by inserting periods every two characters\n",
    "    code = '.'.join([parts[0][i:i+2] for i in range(0, len(parts[0]), 2)])\n",
    "    \n",
    "    # Adjust description capitalization\n",
    "    description = ' '.join([word.capitalize() if word not in ['e', 'de', 'do', 'dos', 'da', 'das', 'em'] else word.lower() for word in parts[1].split('_')])\n",
    "    \n",
    "    return code, description\n",
    "\n",
    "# De-transform the formulas using the corrected function\n",
    "formulas = []\n",
    "for group in formulas_old:\n",
    "    new_group = []\n",
    "    for key in group:\n",
    "        new_group.append(de_transform_corrected(key))\n",
    "    formulas.append(tuple(new_group))\n",
    "\n",
    "formulas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_sheet = df.groupby(['CNPJ_CIA', 'DT_REFER'], group_keys=True)\n",
    "balance_sheet.groups.keys()\n",
    "df_ = balance_sheet.get_group(('00.242.184/0001-04', '2019-12-31'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (, 'Emprestimos e Financiamentos em Moeda Estrangeira'),\n",
    "m = df['CD_CONTA'] == '07.08.04'\n",
    "df[m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dados Abertos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(file):\n",
    "    path = \"C:\\\\Users\\\\faust\\\\OneDrive\\\\Área de Trabalho\\\\dados abertos\\\\\"\n",
    "    df = pd.read_csv(path+file+\".csv\", sep=';', encoding='latin1')\n",
    "    return df.head(25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fca_cia_aberta_2010\"\n",
    "fca_cia_aberta_2010 = read(file)\n",
    "# link para o NSD do formulário cadastral\n",
    "fca_cia_aberta_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fca_cia_aberta_auditor_2010\"\n",
    "fca_cia_aberta_auditor_2010 = read(file)\n",
    "# informações dos auditores CNPJ e CPF, datas dos auditores CPF\n",
    "fca_cia_aberta_auditor_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fca_cia_aberta_canal_divulgacao_2010\"\n",
    "fca_cia_aberta_canal_divulgacao_2010 = read(file)\n",
    "# Onde as DRE são divulgadas\n",
    "fca_cia_aberta_canal_divulgacao_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fca_cia_aberta_departamento_acionistas_2010\"\n",
    "fca_cia_aberta_departamento_acionistas_2010 = read(file)\n",
    "# Endereços dos DRI\n",
    "fca_cia_aberta_departamento_acionistas_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fca_cia_aberta_dri_2010\"\n",
    "fca_cia_aberta_dri_2010 = read(file)\n",
    "# NOMES e endereços dos DRI\n",
    "fca_cia_aberta_dri_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fca_cia_aberta_endereco_2010\"\n",
    "fca_cia_aberta_endereco_2010 = read(file)\n",
    "# Endereço completo do DRI\n",
    "fca_cia_aberta_endereco_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fca_cia_aberta_geral_2010\"\n",
    "fca_cia_aberta_geral_2010 = read(file)\n",
    "# Cadastro CVM, Atividade, Descrição e Controle Acionário\n",
    "fca_cia_aberta_geral_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fca_cia_aberta_pais_estrangeiro_negociacao_2010\"\n",
    "fca_cia_aberta_pais_estrangeiro_negociacao_2010 = read(file)\n",
    "# País estrangeiro... ?\n",
    "fca_cia_aberta_pais_estrangeiro_negociacao_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fca_cia_aberta_valor_mobiliario_2010\"\n",
    "fca_cia_aberta_valor_mobiliario_2010 = read(file)\n",
    "# Valor mobiliário, Mercado e Segmento\n",
    "fca_cia_aberta_valor_mobiliario_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_2023\"\n",
    "fre_cia_aberta_2023 = read(file)\n",
    "# Link do Documento\n",
    "fre_cia_aberta_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_acao_entregue_2023\"\n",
    "fre_cia_aberta_acao_entregue_2023 = read(file)\n",
    "# Remuneração da Diretoria\n",
    "fre_cia_aberta_acao_entregue_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_administrador_declaracao_genero_2023\"\n",
    "fre_cia_aberta_administrador_declaracao_genero_2023 = read(file)\n",
    "# Gênero dos administradores\n",
    "fre_cia_aberta_administrador_declaracao_genero_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_administrador_declaracao_raca_2023\"\n",
    "fre_cia_aberta_administrador_declaracao_raca_2023 = read(file)\n",
    "# Raça dos administradores\n",
    "fre_cia_aberta_administrador_declaracao_raca_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_administrador_membro_conselho_fiscal_2023\"\n",
    "fre_cia_aberta_administrador_membro_conselho_fiscal_2023 = read(file)\n",
    "# Membros do Conselho Fiscal\n",
    "fre_cia_aberta_administrador_membro_conselho_fiscal_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_ativo_imobilizado_2023\"\n",
    "fre_cia_aberta_ativo_imobilizado_2023 = read(file)\n",
    "# Ativos e Propriedades por empresa\n",
    "fre_cia_aberta_ativo_imobilizado_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_ativo_intangivel_2023\"\n",
    "fre_cia_aberta_ativo_intangivel_2023 = read(file)\n",
    "# Ativos e Propriedades por empresa\n",
    "fre_cia_aberta_ativo_intangivel_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_auditor_2023\"\n",
    "fre_cia_aberta_auditor_2023 = read(file)\n",
    "# Remuneração por auditor\n",
    "fre_cia_aberta_auditor_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_auditor_responsavel_2023\"\n",
    "fre_cia_aberta_auditor_responsavel_2023 = read(file)\n",
    "# Endereço do Auditor\n",
    "fre_cia_aberta_auditor_responsavel_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_capital_social_2023\"\n",
    "fre_cia_aberta_capital_social_2023 = read(file)\n",
    "# Modificações no Capital Social e Ações\n",
    "fre_cia_aberta_capital_social_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_capital_social_aumento_2023\"\n",
    "fre_cia_aberta_capital_social_aumento_2023 = read(file)\n",
    "# Idem\n",
    "fre_cia_aberta_capital_social_aumento_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_capital_social_aumento_classe_acao_2023\"\n",
    "fre_cia_aberta_capital_social_aumento_classe_acao_2023 = read(file)\n",
    "# Em branco\n",
    "fre_cia_aberta_capital_social_aumento_classe_acao_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_capital_social_classe_acao_2023\"\n",
    "fre_cia_aberta_capital_social_classe_acao_2023 = read(file)\n",
    "# Preferencial Classe A, B e C\n",
    "fre_cia_aberta_capital_social_classe_acao_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_capital_social_desdobramento_2023\"\n",
    "fre_cia_aberta_capital_social_desdobramento_2023 = read(file)\n",
    "# Desdobramentos de Ações\n",
    "fre_cia_aberta_capital_social_desdobramento_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_capital_social_desdobramento_classe_acao_2023\"\n",
    "fre_cia_aberta_capital_social_desdobramento_classe_acao_2023 = read(file)\n",
    "# em branco\n",
    "fre_cia_aberta_capital_social_desdobramento_classe_acao_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_capital_social_reducao_2023\"\n",
    "fre_cia_aberta_capital_social_reducao_2023 = read(file)\n",
    "# Redução de capital\n",
    "fre_cia_aberta_capital_social_reducao_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_capital_social_titulo_conversivel_2023\"\n",
    "fre_cia_aberta_capital_social_titulo_conversivel_2023 = read(file)\n",
    "# Redução de capital\n",
    "fre_cia_aberta_capital_social_titulo_conversivel_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_direito_acao_2023\"\n",
    "fre_cia_aberta_direito_acao_2023 = read(file)\n",
    "# ?\n",
    "fre_cia_aberta_direito_acao_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_historico_emissor_2023\"\n",
    "fre_cia_aberta_historico_emissor_2023 = read(file)\n",
    "# Constituição do emissor e local\n",
    "fre_cia_aberta_historico_emissor_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_informacao_financeira_2023\"\n",
    "fre_cia_aberta_informacao_financeira_2023 = read(file)\n",
    "# DRE Resumido\n",
    "fre_cia_aberta_informacao_financeira_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_membro_comite_2023\"\n",
    "fre_cia_aberta_membro_comite_2023 = read(file)\n",
    "# CPF e Remuneração\n",
    "fre_cia_aberta_membro_comite_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_obrigacao_2023\"\n",
    "fre_cia_aberta_obrigacao_2023 = read(file)\n",
    "# Obrigações e Dívidas\n",
    "fre_cia_aberta_obrigacao_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_outro_valor_mobiliario_2023\"\n",
    "fre_cia_aberta_outro_valor_mobiliario_2023 = read(file)\n",
    "# ?\n",
    "fre_cia_aberta_outro_valor_mobiliario_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_participacao_sociedade_2023\"\n",
    "fre_cia_aberta_participacao_sociedade_2023 = read(file)\n",
    "# Participações em outras empresas\n",
    "fre_cia_aberta_participacao_sociedade_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_participacao_sociedade_valorizacao_acao_2023\"\n",
    "fre_cia_aberta_participacao_sociedade_valorizacao_acao_2023 = read(file)\n",
    "# ?\n",
    "fre_cia_aberta_participacao_sociedade_valorizacao_acao_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_posicao_acionaria_2023\"\n",
    "fre_cia_aberta_posicao_acionaria_2023 = read(file)\n",
    "# Composição acionária por acionista majoritário\n",
    "fre_cia_aberta_posicao_acionaria_2023[['CNPJ_Companhia', 'Data_Referencia', 'Versao', 'ID_Documento',\n",
    "       'ID_Acionista', 'Acionista', 'Tipo_Pessoa_Acionista',\n",
    "       'CPF_CNPJ_Acionista', 'ID_Acionista_Relacionado',\n",
    "       'Acionista_Relacionado', 'Tipo_Pessoa_Acionista_Relacionado',\n",
    "       'CPF_CNPJ_Acionista_Relacionado',\n",
    "       'Quantidade_Acao_Ordinaria_Circulacao',\n",
    "       'Percentual_Acao_Ordinaria_Circulacao',\n",
    "       'Quantidade_Acao_Preferencial_Circulacao',\n",
    "       'Percentual_Acao_Preferencial_Circulacao',\n",
    "       'Quantidade_Total_Acoes_Circulacao',\n",
    "       'Percentual_Total_Acoes_Circulacao', ]]\n",
    "# fre_cia_aberta_posicao_acionaria_2023.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_relacao_familiar_2023\"\n",
    "fre_cia_aberta_relacao_familiar_2023 = read(file)\n",
    "# Parentescos\n",
    "fre_cia_aberta_relacao_familiar_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_relacao_subordinacao_2023\"\n",
    "fre_cia_aberta_relacao_subordinacao_2023 = read(file)\n",
    "# Subordnicação \n",
    "fre_cia_aberta_relacao_subordinacao_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_transacao_parte_relacionada_2023\"\n",
    "fre_cia_aberta_transacao_parte_relacionada_2023 = read(file)\n",
    "# Partes relacionadas\n",
    "fre_cia_aberta_transacao_parte_relacionada_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"fre_cia_aberta_2023\"\n",
    "fre_cia_aberta_2023 = read(file)\n",
    "# Link do Documento\n",
    "fre_cia_aberta_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_group(cias_por_setor, window):\n",
    "    for company, group_df in cias_por_setor:\n",
    "        try:\n",
    "            # Calculate the moving average for the last 4 periods\n",
    "            group_df['MA'] = group_df['VL_CONTA'].rolling(window=window).mean()\n",
    "            \n",
    "            # Calculate the rolling sum for the last 4 periods\n",
    "            group_df['Rolling_Sum'] = group_df['VL_CONTA'].rolling(window=window).sum()\n",
    "            \n",
    "            # Calculate the lifelong cumulative sum\n",
    "            group_df['Cumulative_Sum'] = group_df['VL_CONTA'].cumsum()\n",
    "            \n",
    "            # Plot raw data\n",
    "            # group_df['VL_CONTA'].plot(label='Raw Data', legend=True)\n",
    "\n",
    "            # Plot moving average\n",
    "            group_df['MA'].plot(label=f'{window} Quarters Moving Average', legend=True, linestyle='--')\n",
    "            \n",
    "            # Plot rolling sum\n",
    "            group_df['Rolling_Sum'].plot(label=f'{window} Quarters Sum', legend=True, linestyle='-.')\n",
    "            \n",
    "            # Plot lifelong cumulative sum\n",
    "            group_df['Cumulative_Sum'].plot(label='Lifelong Cumulative Sum', legend=True, linestyle='-.')\n",
    "\n",
    "            plt.title(f\"{group_df['CD_CVM'].iloc[-1]} {group_df['DENOM_CIA'].iloc[-1]}\")\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"Error plotting for {company}: {e}\")\n",
    "    return True\n",
    "\n",
    "cias_por_setor = df[(df['AGRUPAMENTO'] == 'con') & (df['CD_CONTA'] == '3.11')].groupby('CD_CVM')\n",
    "plot_group(cias_por_setor, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cias_por_setor = df[(df['AGRUPAMENTO'] == 'con') & (df['CD_CONTA'] == '2.03')].groupby('DENOM_CIA')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "for company, group_df in cias_por_setor:\n",
    "    try:\n",
    "        group_df[['VL_CONTA']].plot(ax=ax, label=company)\n",
    "    except:\n",
    "        print(company)\n",
    "\n",
    "ax.set_title(\"VL_CONTA by Company\")\n",
    "ax.set_ylabel(\"VL_CONTA\")\n",
    "ax.set_xlabel(\"Index\")\n",
    "ax.legend(loc=\"best\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intelacoes Fundamentalista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intelacoes = run.load_pkl(f'{b3.app_folder}intelacoes')\n",
    "intelacoes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('BENS INDUSTRIAIS_intelacoes.pkl')\n",
    "# df.to_csv('BENS INDUSTRIAIS_intelacoes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Unnamed: 0', 'FILENAME', 'DEMONSTRATIVO', 'BALANCE_SHEET', 'ANO',\n",
    "       'AGRUPAMENTO', 'CNPJ_CIA', 'DT_REFER', 'VERSAO', 'DENOM_CIA', 'CD_CVM',\n",
    "       'GRUPO_DFP', 'MOEDA', 'ESCALA_MOEDA', 'DT_FIM_EXERC', 'CD_CONTA',\n",
    "       'DS_CONTA', 'VL_CONTA', 'ST_CONTA_FIXA', 'DT_INI_EXERC', 'COLUNA_DF',\n",
    "       'COMPANHIA', 'PREGAO', 'TICK', 'LISTAGEM', 'CVM', 'TICKERS', 'ISIN',\n",
    "       'CNPJ', 'ATIVIDADE', 'SETOR', 'SUBSETOR', 'SEGMENTO', 'SITE',\n",
    "       'ESCRITURADOR', 'CD_CONTA_original', 'DS_CONTA_original', 'Companhia',\n",
    "       'Trimestre', 'Ações ON', 'Ações PN', 'Ações ON em Tesouraria',\n",
    "       'Ações PN em Tesouraria', 'URL']\n",
    "cols = ['SETOR', 'SUBSETOR', 'SEGMENTO', 'CNPJ_CIA', 'DENOM_CIA', 'CD_CVM',  'PREGAO', 'TICK', 'LISTAGEM', 'TICKERS', 'DT_REFER', 'BALANCE_SHEET', 'CD_CONTA', 'DS_CONTA', 'VL_CONTA', ]\n",
    "datetime_cols = ['DT_REFER', 'DT_FIM_EXERC', 'DT_INI_EXERC', 'Trimestre']\n",
    "company_cols = ['SETOR', 'SUBSETOR', 'SEGMENTO', 'CNPJ_CIA', 'DENOM_CIA', 'CD_CVM']\n",
    "dateseries_col = ['DT_REFER']\n",
    "sheet_cols = ['BALANCE_SHEET', 'CD_CONTA', 'DS_CONTA', 'VL_CONTA']\n",
    "stocks_cols = ['Ações ON', 'Ações PN', 'Ações ON em Tesouraria', 'Ações PN em Tesouraria']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by 'SETOR', 'SUBSETOR', and 'SEGMENTO' to count unique companies and aggregate their TICK values\n",
    "ticks_by_setor = df.groupby(['SETOR', 'SUBSETOR', 'SEGMENTO']).agg({\n",
    "    'DENOM_CIA': 'nunique',\n",
    "    'TICK': lambda x: list(set(x.dropna()))\n",
    "}).reset_index()\n",
    "\n",
    "# Renaming columns for clarity\n",
    "ticks_by_setor.rename(columns={'DENOM_CIA': 'TOTAL DE COMPANHIAS'}, inplace=True)\n",
    "\n",
    "ticks_by_setor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conta = '02.03'\n",
    "\n",
    "# Filtering the data for the account 'CD_CONTA' with value '02.03' and the latest quarter\n",
    "conta_by_setor = df[df['DT_REFER'] == df['DT_REFER'].max()]\n",
    "conta_by_setor = conta_by_setor[conta_by_setor['CD_CONTA'] == conta]\n",
    "\n",
    "# Grouping by 'SETOR', 'SUBSETOR', and 'SEGMENTO' to aggregate 'VL_CONTA' values\n",
    "conta_by_setor = conta_by_setor.groupby(['SETOR', 'SUBSETOR', 'SEGMENTO', ]).agg({\n",
    "    'VL_CONTA': ['nunique', 'sum', 'max', 'min', 'mean', 'std', 'skew', lambda x: x.kurt()]\n",
    "}).reset_index()\n",
    "\n",
    "conta_by_setor.rename(columns={'VL_CONTA': conta}, inplace=True)\n",
    "\n",
    "conta_by_setor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = df\n",
    "# dfc = dfc.set_index('DT_REFER')\n",
    "company = 'WEG SA'\n",
    "quarter = '2020-12-31'\n",
    "conta = '01.01.01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = dfc['DENOM_CIA'] != 'nothing'\n",
    "mask &= dfc['DT_REFER'] == quarter\n",
    "mask &= dfc['DENOM_CIA'] == company\n",
    "# mask &= dfc['PREGAO'] == ''\n",
    "# mask &= dfc['TICK'] == ''\n",
    "# mask &= dfc['BALANCE_SHEET'] == ''\n",
    "mask &= dfc['CD_CONTA'] == conta\n",
    "# mask &= dfc['DS_CONTA'] == ''\n",
    "\n",
    "# dfc[mask][cols]\n",
    "data = dfc[mask][['DENOM_CIA', 'DT_REFER', 'CD_CONTA', 'DS_CONTA', 'VL_CONTA']].set_index('DT_REFER')\n",
    "sheet = df[(df['DENOM_CIA'] == company) & (df['DT_REFER'] == quarter)]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = pd.concat([dfc, rows], ignore_index=True).ffill().drop_duplicates()\n",
    "m = dfc['BALANCE_SHEET'].isin(sh)\n",
    "dfc[m][cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fund"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund = load_pkl(f'{b3.app_folder}fund')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('BENS INDUSTRIAIS_fund.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('BENS INDUSTRIAIS_fund.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TICKERS'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Macro Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install yfinance -q -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baixando Cotações do Índice Bovespa\n",
    "ibov = yf.download('^BVSP')\n",
    "df = yf.download(['WEGE3.SA','BBDC4.SA', 'PETR4.SA'], group_by='ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df['WEGE3.SA']['Adj Close']))\n",
    "tickers = df.columns.get_level_values(0).unique().tolist()\n",
    "tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tick in tickers:\n",
    "    df[tick]['Adj Close'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q alpha_vantage\n",
    "# Importando a classe Timeseries de alpha_vantage.timeseries\n",
    "from alpha_vantage.timeseries import TimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHAVANTAGE_API_KEY = 'KR3OMFL1CLANZUXP'\n",
    "# Criando o objeto ts\n",
    "ts = TimeSeries(key=ALPHAVANTAGE_API_KEY, output_format='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados, meta_dados = ts.get_symbol_search('alphabet')\n",
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtendo os dados semanais do IBOV usando get_weekly\n",
    "dados, meta_dados = ts.get_daily(symbol='AAPL', )\n",
    "dados['4. close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install quandl -q -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quandl\n",
    "mydata = quandl.get(\"FRED/GDP\")\n",
    "api = 'LpAz8JCUosdwhHqnWnA4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = quandl.get_table('ZACKS/FC', ticker='AAPL',)\n",
    "mydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas datareader\n",
    "import os\n",
    "import pandas_datareader as pdr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIINGO_API_KEY = '591375a6e5852ca48f778902fec322581511c89a'\n",
    "import tiingo\n",
    "\n",
    "config = {}\n",
    "config['session'] = True\n",
    "config['api_key'] = TIINGO_API_KEY\n",
    "client = tiingo.TiingoClient(config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "TIINGO_API_KEY = '591375a6e5852ca48f778902fec322581511c89a'\n",
    "url = 'https://api.tiingo.com/tiingo/fundamentals/definitions'\n",
    "url = 'https://api.tiingo.com/tiingo/daily/AAPL/prices?startDate=2012-1-1'\n",
    "# url = 'https://api.tiingo.com/tiingo/daily/AAPL/prices'\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': 'Token ' + TIINGO_API_KEY\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "data = response.json()\n",
    "data = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['close'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pdr.DataReader('GE', 'yahoo')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Yahoo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iterrow in fund and get same key from both dict to concat both and remove duplicates\n",
    "\n",
    "save quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get BCB Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.alert import Alert\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromedriver_path = \"D:\\\\Fausto Stangler\\\\Documentos\\\\Python\\\\DSH\\\\chromedriver-win64\\\\chromedriver.exe\"\n",
    "driver_wait_time = 5\n",
    "\n",
    "driver, wait = run.load_browser(chromedriver_path, driver_wait_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_bcb = 'https://www3.bcb.gov.br/sgspub/'\n",
    "url_bcb = 'https://www3.bcb.gov.br/sgspub/localizarseries/localizarSeries.do?method=prepararTelaPesquisaAvancada'\n",
    "\n",
    "driver.get(url_bcb)\n",
    "\n",
    "try:\n",
    "    alert = Alert(driver)\n",
    "    alert.accept()\n",
    "except Exception as e:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "element_xpath = '/html/body/table[1]/tbody/tr/td[3]/a'\n",
    "element = wait.until(EC.presence_of_element_located((By.XPATH, element_xpath)))\n",
    "# Get elements in Português\n",
    "if 'Português' in element.text.splitlines():\n",
    "    element.click()\n",
    "# # Get elements in English\n",
    "# if 'English' in element.text.splitlines():\n",
    "#     element.click()\n",
    "\n",
    "# Click on the first element\n",
    "element = wait.until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"tabLCS\"]/tbody/tr/td[1]/table/tbody/tr[12]/td')))\n",
    "element.click()\n",
    "\n",
    "# Switch to the iframe\n",
    "iframe_id = 'iCorpo'\n",
    "wait.until(EC.frame_to_be_available_and_switch_to_it((By.ID, iframe_id)))\n",
    "\n",
    "# Click on the second element\n",
    "element = wait.until(EC.element_to_be_clickable((By.XPATH, '/html/body/center/form/table[1]/tbody/tr[5]/td[2]/input')))\n",
    "element.click()\n",
    "\n",
    "# Click on the third element\n",
    "element = wait.until(EC.element_to_be_clickable((By.XPATH, '/html/body/center/form/input[9]')))\n",
    "element.click()\n",
    "\n",
    "# Grab the number of items for pagination\n",
    "pagination_xpath = '/html/body/form/span[1]/span[1]/b'\n",
    "num_items = int(wait.until(EC.presence_of_element_located((By.XPATH, pagination_xpath))).text)\n",
    "\n",
    "# Read the table\n",
    "table_xpath = '//*[@id=\"tabelaSeries\"]'  # or '//*[@id=\"tabelaConjunto\"]'\n",
    "table_html = wait.until(EC.presence_of_element_located((By.XPATH, table_xpath))).get_attribute('outerHTML')\n",
    "df = pd.read_html(table_html)[0]\n",
    "\n",
    "# Determine the number of pages for pagination (assuming 10 items per page)\n",
    "items_per_page = len(df)  # Adjust as per actual items per page\n",
    "num_pages = -(-num_items // items_per_page)  # Ceiling division\n",
    "items_per_page, num_pages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the pages and extract data\n",
    "start_time = run.time.time()\n",
    "for i, page_number in enumerate(range(num_pages - 1)):  # Already have data for first page\n",
    "        # Execute the JavaScript function for pagination\n",
    "    driver.execute_script(f'getPagina({page_number})')\n",
    "    \n",
    "    # Read the table on the new page\n",
    "    table_html = wait.until(EC.presence_of_element_located((By.XPATH, table_xpath))).get_attribute('outerHTML')\n",
    "    new_df = pd.read_html(table_html)[0]\n",
    "    \n",
    "    # Loop through each row of the new data\n",
    "    for _, row in new_df.iterrows():\n",
    "        # Extract the relevant parameter for JavaScript function from the row\n",
    "        series = row['Cód.']  # replace 'YourColumnName' with the actual column name\n",
    "        \n",
    "        # Execute the JavaScript function\n",
    "        driver.execute_script(f\"parent.pesquisarPorDocn('../localizarseries/localizarSeries.do?method=recuperarMetadadosPorDocn', '{series}', 'Dados básicos/Metadados');\")\n",
    "        print('grab the table xpath and save into new_df')\n",
    "        # Grab the data you need after executing the JavaScript\n",
    "        # Your code for grabbing data goes here...\n",
    "        \n",
    "        # NOTE: Be sure to implement appropriate waiting and checking for elements to ensure data is loaded before you try to grab it.\n",
    "\n",
    "    # Append the new data to the existing dataframe\n",
    "    df = pd.concat([df, new_df], ignore_index=True)\n",
    "    print(run.remaining_time(start_time, (num_pages - 1), i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get each series data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integrate fund to quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrate funds to quotes, so each TICK contains quotes and also also all financial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = run.load_pkl(f'{b3.app_folder}quotes')\n",
    "fund = run.load_pkl(f'{b3.app_folder}fund')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes.keys(), quotes['AERIS'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdata = []\n",
    "for pregao, d in quotes.items():\n",
    "    for ticker, df in d.items():\n",
    "        try:\n",
    "            df.insert(0, 'PREGAO', pregao)\n",
    "        except Exception as e:\n",
    "            df['PREGAO'] = pregao  # Update 'PREGAO' column\n",
    "        \n",
    "        try:\n",
    "            df['TICKER'] = ticker  # Update 'TICKER' column\n",
    "        except Exception as e:\n",
    "            df.insert(1, 'TICKER', ticker)\n",
    "\n",
    "        bigdata.append(df)\n",
    "bigdata = pd.concat(bigdata, ignore_index=False)\n",
    "bigdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data subset\n",
    "df_fund = fund['BENS INDUSTRIAIS']\n",
    "\n",
    "# Data preprocessing\n",
    "# Convert specific columns to object type\n",
    "df_fund[['VERSAO', 'CD_CVM']] = df_fund[['VERSAO', 'CD_CVM']].astype('object')\n",
    "\n",
    "# Convert 'DT_REFER' to datetime format\n",
    "df_fund['DT_REFER'] = pd.to_datetime(df_fund['DT_REFER'])\n",
    "\n",
    "# Pivot for CD_CONTA\n",
    "df_cd_conta = df_fund.pivot_table(index=['DT_REFER', 'PREGAO'], \n",
    "                                  columns=['CD_CONTA', 'DS_CONTA'], \n",
    "                                  values='VL_CONTA', \n",
    "                                  aggfunc='sum').reset_index()\n",
    "\n",
    "# Flatten the multi-level columns after pivot\n",
    "df_cd_conta.columns = [' - '.join(col).strip(' - ') for col in df_cd_conta.columns.values]\n",
    "\n",
    "# Extract unique combinations of DT_REFER and PREGAO without the account details and get an unique mapping between the dates, PREGAO, and the pivoted account data.\n",
    "df_unique = df_fund.reset_index(drop=True).drop_duplicates(subset=['DT_REFER', 'PREGAO']).drop(['CD_CONTA', 'DS_CONTA', 'VL_CONTA'], axis=1)\n",
    "df_merged = pd.merge(df_unique, df_cd_conta, on=['DT_REFER', 'PREGAO'])\n",
    "\n",
    "# Set index and handle missing values\n",
    "df_merged = df_merged.set_index(['DT_REFER', 'PREGAO'], drop=True)\n",
    "\n",
    "# Group by 'PREGAO' and apply resampling\n",
    "df_resampled = (\n",
    "    df_merged\n",
    "    .reset_index()\n",
    "    .groupby('PREGAO')\n",
    "    .apply(lambda group: group.set_index('DT_REFER').resample('D').asfreq().ffill().bfill().fillna(0))\n",
    "    .drop('PREGAO', axis=1)  # Drop the redundant 'PREGAO' column introduced by `groupby`\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdata = bigdata.reset_index()\n",
    "bigdata['Date'] = pd.to_datetime(bigdata['Date'])\n",
    "df_resampled = df_resampled.reset_index()\n",
    "df_resampled['DT_REFER'] = pd.to_datetime(df_resampled['DT_REFER'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Get unique PREGAO values from df_resampled\n",
    "companies = df_resampled['PREGAO'].unique()\n",
    "\n",
    "# Step 2: Filter bigdata\n",
    "filtered_bigdata = bigdata[bigdata['PREGAO'].isin(companies)]\n",
    "\n",
    "df_merged = pd.merge(filtered_bigdata, df_resampled, left_on=['Date', 'PREGAO'], right_on=['DT_REFER', 'PREGAO'], how='outer')\n",
    "\n",
    "# Sort the dataframe by 'PREGAO' and 'Date'\n",
    "df_merged = df_merged.sort_values(by=['PREGAO', 'Date'])\n",
    "\n",
    "# Group by 'PREGAO', then apply the fill methods within each group\n",
    "df_merged = df_merged.groupby('PREGAO', group_keys=False).apply(lambda group: group.ffill().bfill()).fillna(0).reset_index(drop=True)\n",
    "\n",
    "# Fill any remaining NaN values in the entire dataframe (outside of groups)\n",
    "df_merged = df_merged.set_index('Date', drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_metrics(df):\n",
    "    # Ensure no division by zero for all columns\n",
    "    df.replace(0, np.nan, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged.groupby('PREGAO', group_keys=False).apply(add_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company = companies[0]\n",
    "company = 'WEG'\n",
    "df = df_merged[df_merged['PREGAO'] == company]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setor, subsetor, segmento = df[['SETOR', 'SUBSETOR', 'SEGMENTO']].iloc[0]\n",
    "setor, subsetor, segmento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_cia = df_merged['PREGAO'] != company\n",
    "m_segmento = df_merged['SEGMENTO'] == segmento\n",
    "m_subsetor = df_merged['SUBSETOR'] == subsetor\n",
    "m_setor = df_merged['SETOR'] == setor\n",
    "\n",
    "cias_segmento = [cia for cia in df_merged[m_cia & m_segmento]['PREGAO'].unique().tolist()]\n",
    "cias_subsetor = [cia for cia in df_merged[m_cia & m_subsetor]['PREGAO'].unique().tolist() if cia not in cias_segmento]\n",
    "cias_setor = [cia for cia in df_merged[m_cia & m_setor]['PREGAO'].unique().tolist() if cia not in cias_subsetor and cia not in cias_segmento]\n",
    "cias_segmento, cias_subsetor, cias_setor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = np.sort(df['TICKER'].unique())\n",
    "df_ticker = []\n",
    "for ticker in tickers:\n",
    "    df_ticker.append(df[df['TICKER'] == ticker])\n",
    "df = df_ticker[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv('dash_df_merged.csv')\n",
    "df.to_csv('dash_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = run.save_pkl(df_merged, 'dash_df_merged')\n",
    "df = run.save_pkl(df, 'dash_df')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(df, subcolumns):\n",
    "    \"\"\"\n",
    "    Normalize data columns in a dataframe to their percentage of row-wise total.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Dataframe containing data to be normalized.\n",
    "    subcolumns : list of str\n",
    "        List of column names to be normalized.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    normalized_df : pd.DataFrame\n",
    "        Dataframe with normalized columns.\n",
    "    \"\"\"\n",
    "    # Filter subcolumns to include only columns that actually exist in df\n",
    "    subcolumns = [col for col in subcolumns if col in df.columns]\n",
    "\n",
    "    # Make a copy of the specified columns to prevent modifying the original dataframe\n",
    "    temp_df = df[subcolumns].copy()\n",
    "    \n",
    "    # Ensure there are no NaN values at the start of the columns\n",
    "    # [You might adapt this as per your requirement]\n",
    "    temp_df = temp_df.dropna(subset=subcolumns, how='all')\n",
    "    \n",
    "    # Calculate the total of the specified columns row-wise\n",
    "    temp_df['total'] = temp_df.sum(axis=1)\n",
    "\n",
    "    # Normalize each specified column by its percentage of the row-wise total\n",
    "    for column in subcolumns:\n",
    "        temp_df[column] = temp_df.apply(\n",
    "            lambda row: round(row[column] / row['total'] * 100, 2) if row['total'] != 0 else 0, \n",
    "            axis=1\n",
    "        )\n",
    "    \n",
    "    # Drop the total column and return the normalized dataframe\n",
    "    normalized_df = temp_df.drop(columns=['total'])\n",
    "    \n",
    "    return normalized_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclude_outliers(item, multiplier=1.5):\n",
    "    \"\"\"\n",
    "    Exclude outliers from a data series using \n",
    "    the Interquartile Range (IQR) method and a personalized multiplier.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_series : pd.Series\n",
    "        The original data series from which outliers will be excluded.\n",
    "    multiplier : float\n",
    "        The multiplier for the IQR. Outliers are defined as values below \n",
    "        Q1 - (multiplier * IQR) or above Q3 + (multiplier * IQR).\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    inliers : pd.Series\n",
    "        The data series with outliers excluded.\n",
    "    \"\"\"\n",
    "    data_series = df[item] if isinstance(item, str) else item\n",
    "\n",
    "    # Calculate the first (Q1) and third (Q3) quartiles\n",
    "    Q1 = data_series.quantile(0.25)\n",
    "    Q3 = data_series.quantile(0.75)\n",
    "    \n",
    "    # Calculate the Interquartile Range (IQR)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Define lower and upper bounds for inliers\n",
    "    lower_bound = Q1 - multiplier * IQR\n",
    "    upper_bound = Q3 + multiplier * IQR\n",
    "    \n",
    "    # Identify and return inliers\n",
    "    inliers = data_series[(data_series > lower_bound) & (data_series < upper_bound)]\n",
    "    \n",
    "    return inliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cagr(item, years=3):\n",
    "    \"\"\"\n",
    "    Calculate the Compound Annual Growth Rate (CAGR) for a given data series.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    item : str or pd.Series\n",
    "        The actual values for which the CAGR will be calculated. \n",
    "        Can be a string (column name) or a pandas Series.\n",
    "    years : int\n",
    "        The number of years over which the CAGR will be calculated.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    data_series : pd.Series\n",
    "        The CAGR values.\n",
    "    \"\"\"\n",
    "    # Retrieve the data series from the dataframe if item is a string (column name)\n",
    "    data_series = df[item] if isinstance(item, str) else item\n",
    "    \n",
    "    # Calculate the CAGR: [ (Ending Value / Beginning Value) ^ (1 / Number of Years) ] - 1\n",
    "    # Shift the original data series by the number of periods to calculate the growth rate\n",
    "    data_series = ((data_series / data_series.shift(periods=round(21*12*years))) ** (1/years)) - 1\n",
    "    \n",
    "    # Convert CAGR to percentage and smooth (accordingly to year) the series by taking a moving average, and round the series to two decimal places\n",
    "    data_series = data_series * 100\n",
    "    data_series = data_series.rolling(window=int(years*4)).mean()\n",
    "    data_series = data_series.round(2)\n",
    "    \n",
    "    # Name it appropriately\n",
    "    data_series.name = f'CAGR {years}a - {data_series.name.split(\" - \")[1]}'\n",
    "    \n",
    "    return data_series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ofs(item, years=3):\n",
    "    \"\"\"\n",
    "    Calculate the Oscillator Following the Stock (OFS) for a given data series.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_serie : pd.Series\n",
    "        The actual values for which the OFS oscillator will be calculated.\n",
    "    window : int\n",
    "        The window size for calculating the moving average and standard deviation.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    ofs : pd.Series\n",
    "        The OFS oscillator values, smoothed with a moving average.\n",
    "    \"\"\"\n",
    "    data_series = df[item] if isinstance(item, str) else item\n",
    "\n",
    "    # Calculate the moving average (mma) and standard deviation (std)\n",
    "    mma = data_series.rolling(window=int(21*12*years)).mean()\n",
    "    std = data_series.rolling(window=int(21*12*years)).std()\n",
    "    \n",
    "    # Define the high and low levels\n",
    "    high_level = mma + 2 * std\n",
    "    low_level = mma - 2 * std\n",
    "    \n",
    "    # Calculate the OFS oscillator, where +2 std=100 and -2 std=-100\n",
    "    data_series = ((data_series - low_level) / (high_level - low_level)) * 20 - 10\n",
    "    \n",
    "    # Smooth the OFS oscillator with a moving average\n",
    "    data_series = data_series.rolling(window=int(years*4)).mean()\n",
    "\n",
    "    # Name the series appropriately\n",
    "    data_series.name = f'OFS {years}a - {data_series.name.split(\" - \")[1]}'\n",
    "\n",
    "    return data_series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tweak(df: pd.DataFrame, data: Dict[str, Any], \n",
    "               options: Optional[Dict[str, Dict[str, Any]]] = {}) -> go.Figure:\n",
    "    \"\"\"\n",
    "    Generates a custom Plotly figure based on the provided data and visualization options.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The primary data source containing the columns to be plotted.\n",
    "        \n",
    "    data : dict\n",
    "        Contains metadata and column names/series for plotting. The dictionary should have the keys:\n",
    "        - 'title' : List containing the main title, left y-axis title, and right y-axis title.\n",
    "        - 'left' : List containing columns or series to be plotted on the left y-axis.\n",
    "        - 'right' : List containing columns or series to be plotted on the right y-axis.\n",
    "        \n",
    "    options : dict, optional\n",
    "        Contains visualization options for left and right data. Each side (left/right) can have:\n",
    "        - 'shape' : str, optional (default is 'line')\n",
    "            Shape of the plot, either 'line' or 'area'.\n",
    "        - 'mode' : str, optional (default is 'standalone')\n",
    "            Data representation mode, either 'standalone' or 'cumulative'.\n",
    "        - 'legendgroup' : str, optional\n",
    "            String to combine legend items into a group.\n",
    "        - 'normalization' : bool, optional (default is False)\n",
    "            Indicates if the data should be normalized.\n",
    "        - 'mma': tuple of (float, float), optional\n",
    "            Contains values for a moving average and its multiplier for standard deviation. \n",
    "            Format is (moving_average_period, standard_deviation_multiplier). None by default.\n",
    "        - 'outliers': bool, optional (default is False)\n",
    "            Indicates if outliers should be excluded.\n",
    "        - 'flexible_range': bool, optional (default is False)\n",
    "            If True, the max_min range logic is not applied. If False, it is applied.\n",
    "            \n",
    "    Returns:\n",
    "    -------\n",
    "    plotly.graph_objs.Figure\n",
    "        The generated Plotly figure.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the figure object and variables\n",
    "    company, ticker = df[['PREGAO', 'TICKER']].iloc[0]\n",
    "    fig = go.Figure()\n",
    "\n",
    "    def get_data_from_item(item, normalize=False, columns_for_normalization=None, \n",
    "                        exclude_outliers_multiplier=None, ofs=None):\n",
    "        \"\"\"\n",
    "        Retrieve data from either dataframe columns or directly from a pandas Series, \n",
    "        with optional outlier exclusion and z-score calculation.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            data_series = df[item] if isinstance(item, str) else item\n",
    "        \n",
    "            if normalize:\n",
    "                if isinstance(item, str):\n",
    "                    # If item is a string (column name), normalize using other columns if provided\n",
    "                    data_series = normalize_data(df, columns_for_normalization or [item])[item]\n",
    "                else:\n",
    "                    # If item is a Series, normalize only the series\n",
    "                    data_series = (data_series - data_series.min()) / (data_series.max() - data_series.min())\n",
    "\n",
    "            if exclude_outliers_multiplier is not None:\n",
    "                data_series = exclude_outliers(data_series, exclude_outliers_multiplier)\n",
    "\n",
    "        except Exception as e:\n",
    "            return pd.DataFrame(index=df.index)\n",
    "\n",
    "        return data_series\n",
    "\n",
    "    def get_trace(item, group, shape, mode, normalization, \n",
    "                columns_for_normalization=None, mma=None, \n",
    "                exclude_outliers_multiplier=None):\n",
    "        \"\"\"\n",
    "        Get trace(s) for the provided item with specified configurations.\n",
    "        \"\"\"\n",
    "        column_data = get_data_from_item(\n",
    "            item, normalization, columns_for_normalization, \n",
    "            exclude_outliers_multiplier\n",
    "        )\n",
    "        # Basic trace\n",
    "        try:\n",
    "            trace = {\n",
    "                'x': column_data.index,\n",
    "                'y': column_data,\n",
    "                'name': item.split(' - ')[1] if isinstance(item, str) else item.name,\n",
    "                'fill': 'tonexty' if shape == 'area' and mode == 'cumulative' else \n",
    "                        'tozeroy' if shape == 'area' else 'none',\n",
    "                'stackgroup': group if mode == 'cumulative' else None\n",
    "            }\n",
    "\n",
    "            traces = [trace]\n",
    "\n",
    "            # Statistics based on MMA\n",
    "            if mma:\n",
    "                window = int(21 * 12 * mma[0])\n",
    "                rolling_average = column_data.rolling(window=window).mean()\n",
    "                rolling_std = column_data.rolling(window=window).std()\n",
    "                \n",
    "                # MMA trace\n",
    "                traces.append({\n",
    "                    'x': column_data.index,\n",
    "                    'y': rolling_average,\n",
    "                    'mode': 'lines',\n",
    "                    'name': f'Média {(mma[0]):.0f}a ± {mma[1]}dp',\n",
    "                    'line': {'color': 'green'}, \n",
    "                    'legendgroup': 'mma', \n",
    "                })\n",
    "\n",
    "                # Traces for ± standard deviations from the MMA\n",
    "                traces.append({\n",
    "                    'x': column_data.index,\n",
    "                    'y': rolling_average + mma[1] * rolling_std,\n",
    "                    'mode': 'lines',\n",
    "                    'name': f'+{mma[1]} STD',\n",
    "                    'line': {'color': 'green', 'dash': 'dash'}, \n",
    "                    'legendgroup': 'mma', \n",
    "                    'showlegend': False, \n",
    "                })\n",
    "\n",
    "                traces.append({\n",
    "                    'x': column_data.index,\n",
    "                    'y': rolling_average - mma[1] * rolling_std,\n",
    "                    'mode': 'lines',\n",
    "                    'name': f'-{mma[1]} STD',\n",
    "                    'line': {'color': 'green', 'dash': 'dash'}, \n",
    "                    'legendgroup': 'mma', \n",
    "                    'showlegend': False, \n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            return []\n",
    "\n",
    "        return traces\n",
    "\n",
    "    def update_axis_bounds(fig, side, g_max, g_min, options, default_settings):\n",
    "        \"\"\"\n",
    "        ...\n",
    "        options : dict, optional\n",
    "            Contains visualization options for left and right data. Each side (left/right) can have:\n",
    "            ...\n",
    "            - 'range': bool or str, optional (default is False)\n",
    "                Determines the logic used to set the y-axis bounds:\n",
    "                - 'flexible': No custom logic, Plotly determines y-axis bounds.\n",
    "                - False: Upper bound is set to the nearest power of 10 above the maximum data value.\n",
    "                - 'half': Upper bound is set to the nearest multiple of 5 above the maximum data value.\n",
    "                - 'full': Upper bound is set to the nearest power of 10 above the maximum data value.\n",
    "        ...\n",
    "        \"\"\"\n",
    "        range_option = options.get(side, {}).get('range', default_settings['range'])\n",
    "        \n",
    "        # Check if range logic should be applied\n",
    "        if (\n",
    "            range_option not in ['flexible', 'full'] and \n",
    "            g_max != float('-inf') and \n",
    "            g_min != float('inf')\n",
    "        ):\n",
    "            # Determine upper bound\n",
    "            if range_option == 'half':\n",
    "                upper_bound = 5 * 10 ** math.ceil(math.log10(g_max) - 1)\n",
    "            elif range_option == False:  # or any other invalid value\n",
    "                upper_bound = 10 ** math.ceil(math.log10(g_max))\n",
    "            upper_bound = upper_bound if g_max > 0 else g_max\n",
    "            \n",
    "            # Determine lower bound\n",
    "            lower_bound = 10 ** math.floor(math.log10(g_min)) if g_min > 0 else g_min\n",
    "            \n",
    "            # Update layout\n",
    "            axis_key = 'yaxis' if side == 'left' else 'yaxis2'\n",
    "            fig.update_layout({axis_key: dict(range=[lower_bound, upper_bound])})\n",
    "\n",
    "   # Default settings for visualization\n",
    "    default_settings = {\n",
    "        'shape': 'line',\n",
    "        'mode': 'standalone',\n",
    "        'legendgroup': None,\n",
    "        'normalization': False, \n",
    "        'normalization_columns': None, \n",
    "        'mma': None, \n",
    "        'outliers': None, \n",
    "        'range': 'flexible', \n",
    "    }\n",
    "    \n",
    "    # Flags to determine if we have data on either side\n",
    "    left_data_exists = any(item.startswith('left') for item in data.keys())\n",
    "    right_data_exists = any(item.startswith('right') for item in data.keys())\n",
    "\n",
    "    # Initialize variables for storing the global max and min values for each side\n",
    "    global_max = {'left': float('-inf'), 'right': float('-inf')}\n",
    "    global_min = {'left': float('inf'), 'right': float('inf')}\n",
    "\n",
    "    # Process each side separately\n",
    "    for side, items in data.items():\n",
    "        # Skip if the side is 'title'\n",
    "        if side == 'title':\n",
    "            continue\n",
    "        \n",
    "        # Determine the base side (left or right)\n",
    "        side_base = 'left' if 'left' in side else 'right' if 'right' in side else None\n",
    "        \n",
    "        if side_base:\n",
    "            # Get the options for this side, if any\n",
    "            side_options = {**default_settings, **options.get(side, {})}\n",
    "            \n",
    "            # Generate traces for this side\n",
    "            for item in items:\n",
    "                traces = get_trace(item, side, \n",
    "                                   side_options['shape'],\n",
    "                                   side_options['mode'],\n",
    "                                   side_options['normalization'],\n",
    "                                   side_options['normalization_columns'] or items, \n",
    "                                   side_options['mma'],\n",
    "                                   side_options['outliers'],\n",
    "                                   )\n",
    "                for trace in traces:\n",
    "                    if side_options.get('legendgroup'):\n",
    "                        trace['legendgroup'] = side_options['legendgroup']\n",
    "                    \n",
    "                    # If side contains 'right', assign to yaxis2\n",
    "                    trace['yaxis'] = 'y2' if 'right' in side and left_data_exists else 'y1'\n",
    "\n",
    "                    # Update global min and max\n",
    "                    y_values = trace['y']\n",
    "                    if not y_values.empty:\n",
    "                        max_val = max(y_values)\n",
    "                        min_val = min(y_values)\n",
    "                        global_max[side_base] = max(global_max[side_base], max_val)\n",
    "                        global_min[side_base] = min(global_min[side_base], min_val)\n",
    "\n",
    "                    fig.add_trace(go.Scatter(**trace))\n",
    "\n",
    "    # Figure Update Layout\n",
    "    fig.update_layout(\n",
    "        template='plotly_white',\n",
    "        title_text=f'{ticker} ({company}) {data.get(\"title\", [\"\", \"\", \"\"])[0]}',\n",
    "\n",
    "        xaxis_title='Data',\n",
    "        yaxis_title=data.get('title', [\"\", \"\", \"\"])[1],\n",
    "        yaxis2={'title': data.get('title', [\"\", \"\", \"\"])[2], 'overlaying': 'y', 'side': 'right'} if left_data_exists and right_data_exists else {},\n",
    "\n",
    "        legend=dict(\n",
    "            orientation='h',\n",
    "            font_size=10,\n",
    "        ),\n",
    "        width=6.27 * 200,  # converting inches to 96 pixels for width\n",
    "        height=3.52 * 200,  # converting inches to 96 pixels for height\n",
    "    )\n",
    "    \n",
    "    # Applying the flexible_range logic. Note: The logic is NOT applied if flexible_range is True. If it's False, it IS applied.\n",
    "    update_axis_bounds(fig, 'left', global_max['left'], global_min['left'], options, default_settings)\n",
    "    update_axis_bounds(fig, 'right', global_max['right'], global_min['right'], options, default_settings)\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = '13.09.02 - Outros Ativos Não Circulantes de Longo Prazo por Faturamento'\n",
    "data = {\n",
    "    'title': [f'{item} - {plot}', 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': [item], \n",
    "    'right': [cagr(item, years), ofs(item, years)], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, 'mma': [years, 2], },\n",
    "    'right': {'shape': 'ine', 'mode': 'standalone', 'normalization': False, 'outliers': False, }, \n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company][item][plot] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dual_axis(df, data):\n",
    "    '''\n",
    "    data: Dicionário contendo chaves 'left' e 'right', com as colunas correspondentes.\n",
    "               Exemplo: {'left': [col1, col2], 'right': [col3, col4]}\n",
    "    df: DataFrame contendo os dados.\n",
    "    '''\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "    # Determine y-axis ranges\n",
    "    factor = 1.50\n",
    "    left_min = df[data['left']].min().min() if df[data['left']].min().min() < 0 else df[data['left']].min().min() * -1\n",
    "    left_min *= factor\n",
    "    left_max_abs = max(abs(df[data['left']].min().min()), abs(df[data['left']].max().max())) * factor\n",
    "\n",
    "    right_min = df[data['right']].min().min() if df[data['right']].min().min() < 0 else df[data['right']].min().min() * -1\n",
    "    right_min *= factor\n",
    "    right_max_abs = max(abs(df[data['right']].min().min()), abs(df[data['right']].max().max())) * factor\n",
    "\n",
    "    # Find the zero alignment factor\n",
    "    zero_factor = abs(left_min) / left_max_abs\n",
    "\n",
    "    # Adjust the right y-axis ranges to align the zeros\n",
    "    right_min_adj = -right_max_abs * zero_factor\n",
    "    right_max_adj = right_max_abs * (1 - zero_factor)\n",
    "\n",
    "    # Adicione os dados do eixo esquerdo\n",
    "    for column in data['right']:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=df.index, y=df[column], mode='lines', name=column.split(' - ')[1]),\n",
    "            secondary_y=True\n",
    "        )\n",
    "\n",
    "    # Adicione os dados do eixo direito\n",
    "    fill_mode = 'tozeroy'\n",
    "    for column in data['left']:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=df.index, y=df[column], fill=fill_mode, name=column.split(' - ')[1]),\n",
    "            secondary_y=False\n",
    "        )\n",
    "        fill_mode = 'tonexty'\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text=f'{company} - {data[\"title\"][0]}',\n",
    "        xaxis_title='Data',\n",
    "        yaxis_title=data['title'][1],\n",
    "        yaxis2_title=data['title'][2],\n",
    "        yaxis_range=[left_min, left_max_abs],\n",
    "        yaxis2_range=[right_min_adj, right_max_adj]\n",
    "    )\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stacked_area(df, data):\n",
    "    '''\n",
    "    df: DataFrame containing the data.\n",
    "    data: Dictionary containing the columns to be plotted.\n",
    "    '''\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Helper function to get data from column name or series\n",
    "    def get_data(item):\n",
    "        if isinstance(item, str):\n",
    "            return df[item]\n",
    "        return item\n",
    "\n",
    "    # For 'left' data\n",
    "    for item in data['left']:\n",
    "        data_values = get_data(item)\n",
    "        name = item.split(' - ')[1] if isinstance(item, str) else item.name\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df.index,\n",
    "                y=data_values,\n",
    "                name=name,\n",
    "                fill='tonexty', \n",
    "                stackgroup='left',\n",
    "                # legendgroup='left',\n",
    "                showlegend=True\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # For 'right' data\n",
    "    for item in data['right']:\n",
    "        data_values = get_data(item)\n",
    "        name = item.split(' - ')[1] if isinstance(item, str) else item.name\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df.index,\n",
    "                y=data_values,\n",
    "                name=name,\n",
    "                fill='tonexty', \n",
    "                stackgroup='right',\n",
    "                # legendgroup='right',\n",
    "                showlegend=True,\n",
    "                yaxis='y2'\n",
    "            )\n",
    "        )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text=f'{company} - {data[\"title\"][0]}',\n",
    "        xaxis_title='Data',\n",
    "        yaxis_title=data['title'][1],\n",
    "        yaxis2=dict(title=data['title'][2], overlaying='y', side='right')\n",
    "    )\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_100_stacked_area(df, data):\n",
    "    '''\n",
    "    df: DataFrame containing the data.\n",
    "    data: Dictionary containing the columns to be plotted.\n",
    "    '''\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Helper function to get data from column name or series\n",
    "    def get_data(item):\n",
    "        if isinstance(item, str):\n",
    "            return df[item]\n",
    "        return item\n",
    "\n",
    "    # Function to normalize data\n",
    "    def normalize_data(columns):\n",
    "        temp_df = df[columns].copy()\n",
    "        temp_df['total'] = temp_df.sum(axis=1)\n",
    "        for column in columns:\n",
    "            temp_df[column] = temp_df.apply(lambda row: row[column] / row['total'] * 100 if row['total'] != 0 else 0, axis=1)\n",
    "        return temp_df\n",
    "\n",
    "    left_normalized = normalize_data(data['left'])\n",
    "    right_normalized = normalize_data(data['right'])\n",
    "\n",
    "    # Plot 'left' data\n",
    "    for column in data['left']:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df.index,\n",
    "                y=left_normalized[column],\n",
    "                name=column.split(' - ')[1],\n",
    "                fill='tonexty',\n",
    "                stackgroup='left',\n",
    "                legendgroup='left',\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Plot 'right' data on secondary y-axis\n",
    "    for column in data['right']:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df.index,\n",
    "                y=right_normalized[column],\n",
    "                name=column.split(' - ')[1],\n",
    "                fill='tonexty',\n",
    "                stackgroup='right',\n",
    "                legendgroup='right',\n",
    "                yaxis='y2'\n",
    "            )\n",
    "        )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text=f'{company} - {data[\"title\"][0]}',\n",
    "        xaxis_title='Data',\n",
    "        yaxis_title=data['title'][1],\n",
    "        yaxis2=dict(title=data['title'][2], overlaying='y', side='right')\n",
    "    )\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lines(df, data):\n",
    "    '''\n",
    "    data: Dicionário contendo chaves 'left' e 'title'.\n",
    "               Exemplo: {'left': [col1, col2], 'title': 'Equity Multiplier'}\n",
    "    df: DataFrame contendo os dados.\n",
    "    '''\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Adicione os dados do eixo esquerdo\n",
    "    for column in data['left']:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=df.index, y=df[column], fill='none', name=column.split(' - ')[1])\n",
    "        )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text=f'{company} - {data[\"title\"][0]}',\n",
    "        xaxis_title='Data',\n",
    "        yaxis_title=data['title'][1],\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_basics(df, col, window):\n",
    "    figs = {}\n",
    "    if df[col].sum() != 0:\n",
    "\n",
    "        year_average = df[col].rolling(window=365).mean()\n",
    "\n",
    "        # Calculate rolling mean and standard deviation\n",
    "        rolling_average = df[col].rolling(window=window).mean()\n",
    "        rolling_std = df[col].rolling(window=window).std()\n",
    "\n",
    "        # Create a single line plot\n",
    "        title = f'A - Linha do Tempo'\n",
    "        fig_line = px.line(df, x=df.index, y=col, title=f'{company} - {col} - {title}',\n",
    "                            labels={'value': 'Valor (R$)', 'variable': f'{title}'})\n",
    "        fig_line.add_scatter(x=df.index, y=year_average, mode='lines', line=dict(color='blue'), name='Média Anual')\n",
    "        figs[title] = fig_line\n",
    "        # fig_line.show()\n",
    "\n",
    "        # Create a moving average plot with ±2 standard deviations\n",
    "        title = f'B - Média Móvel e ±2 Desvios Padrão'\n",
    "        fig_mma_std = px.area(df, x=df.index, y=col, title=f'{company} - {col} - {title}',\n",
    "                            labels={'value': 'Valor (R$)', 'variable': f'{title}'})\n",
    "        fig_mma_std.add_scatter(x=df.index, y=year_average, mode='lines', line=dict(color='blue'), name='Média Anual')\n",
    "        fig_mma_std.add_scatter(x=df.index, y=rolling_average, mode='lines', line=dict(color='green'), name='Média Móvel')\n",
    "        fig_mma_std.add_scatter(x=df.index, y=rolling_average + 2 * rolling_std, mode='lines', line=dict(color='green', dash='dash'), name='Média Móvel + 2 Desvios Padrão')\n",
    "        fig_mma_std.add_scatter(x=df.index, y=rolling_average - 2 * rolling_std, mode='lines', line=dict(color='green', dash='dash'), name='Média Móvel - 2 Desvios Padrão')\n",
    "        figs[title] = fig_mma_std\n",
    "        # fig_mma_std.show()\n",
    "\n",
    "    sub_cols = [c for c in df.columns if c.startswith(col.split(' - ')[0] + '.') and c.count('.') == col.count('.') + 1]\n",
    "    if sub_cols:\n",
    "        # Create a multi line plot\n",
    "        title =  f'C - Distribuição Individual'\n",
    "        fig_multiline = px.line(df, x=df.index, y=sub_cols, title=f'{company} - {col} - {title}',\n",
    "                            labels={'value': 'Valor (R$)', 'variable': f'{title}'})\n",
    "        figs[title] = fig_multiline\n",
    "        # fig_area.show()\n",
    "\n",
    "        # Create a cumulative distribution plot\n",
    "        title =  f'D - Distribuição Acumulada'\n",
    "        fig_area = px.area(df, x=df.index, y=sub_cols, title=f'{company} - {col} - {title}',\n",
    "                            labels={'value': 'Valor (R$)', 'variable': f'{title}'})\n",
    "        figs[title] = fig_area\n",
    "        # fig_area.show()\n",
    "\n",
    "        # Create a proportional distribution plot\n",
    "        title = f'E - Distribuição Proporcional'\n",
    "        fig_area_100_stacked = px.area(df, x=df.index, y=sub_cols, title=f'{company} - {col} - {title}',\n",
    "                            labels={'value': 'Porcentagem (%)', 'variable': f'{title}'},\n",
    "                            groupnorm='percent')\n",
    "        figs[title] = fig_area_100_stacked\n",
    "        # fig_area_100_stacked.show()\n",
    "\n",
    "    return figs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_figs(figs, base_dir='./company/'):\n",
    "    \"\"\"\n",
    "    Save figures to the specified directory.\n",
    "\n",
    "    Parameters:\n",
    "    - col_figs: Dictionary of figures to save\n",
    "    - col: Column for which figures were generated\n",
    "    - company: Company for which figures were generated\n",
    "    - base_dir: Base directory where the figures will be saved\n",
    "    \"\"\"\n",
    "    for company, col in figs.items():\n",
    "        path = os.path.join(base_dir, company)\n",
    "        \n",
    "        # Create company directory if it doesn't exist\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "        for col, plots in col.items():\n",
    "            for title, plot in plots.items():\n",
    "                try:\n",
    "                    file_name = f'{company} - {col} - {title}.png'\n",
    "                    file_path = os.path.join(path, file_name)\n",
    "                    plot.write_image(file_path)\n",
    "                    # plot.show()\n",
    "                    print(file_name)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "    return figs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = 3\n",
    "figs = {}\n",
    "figs[company] = {}\n",
    "df = df_ticker[0]\n",
    "for item in df.columns:\n",
    "    figs[company][item] = {}\n",
    "    print(item)\n",
    "    try:\n",
    "        if df[item].sum() != 0:\n",
    "            plot = 'Valores, Média, CAGR e OFS'\n",
    "            data = {\n",
    "                'title': [f'{item} - {plot}', 'Reais (R$)', 'Porcentagem (%)'], \n",
    "                'left': [item], \n",
    "                'right': [cagr(item, years), ofs(item, years)], \n",
    "            }\n",
    "            options = {\n",
    "                'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, 'mma': [years, 2], },\n",
    "                'right': {'shape': 'ine', 'mode': 'standalone', 'normalization': False, 'outliers': False, }, \n",
    "            }\n",
    "            fig = plot_tweak(df_ticker[0], data, options)\n",
    "            figs[company][item][plot] = fig\n",
    "            # fig.show()\n",
    "\n",
    "            sub_cols = [column for column in df.columns if column.startswith(item.split(' - ')[0] + '.') and column.count('.') == item.count('.') + 1]\n",
    "            if sub_cols:\n",
    "                plot = 'Composição Cumulativa'\n",
    "                data = {\n",
    "                    'title': [f'{item} - {plot}', 'Reais (R$)', 'Porcentagem (%)'], \n",
    "                    'left': sub_cols, \n",
    "                    'right': [], \n",
    "                }\n",
    "                options = {\n",
    "                    'left': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, },\n",
    "                    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, }, \n",
    "                }\n",
    "                fig = plot_tweak(df_ticker[0], data, options)\n",
    "                figs[company][item][plot] = fig\n",
    "                # fig.show()\n",
    "\n",
    "                plot = 'Composição Individual'\n",
    "                data = {\n",
    "                    'title': [f'{item} - {plot}', 'Reais (R$)', 'Porcentagem (%)'], \n",
    "                    'left': sub_cols, \n",
    "                    'right': [], \n",
    "                }\n",
    "                options = {\n",
    "                    'left': {'shape': 'line', 'mode': 'standalone', 'normalization': False, },\n",
    "                    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, }, \n",
    "                }\n",
    "                fig = plot_tweak(df_ticker[0], data, options)\n",
    "                figs[company][item][plot] = fig\n",
    "                # fig.show()\n",
    "\n",
    "                plot = 'Composição Relativa'\n",
    "                data = {\n",
    "                    'title': [f'{item} - {plot}', 'Reais (R$)', 'Porcentagem (%)'], \n",
    "                    'left': sub_cols, \n",
    "                    'right': [], \n",
    "                }\n",
    "                options = {\n",
    "                    'left': {'shape': 'line', 'mode': 'standalone', 'normalization': True, },\n",
    "                    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, }, \n",
    "                }\n",
    "                fig = plot_tweak(df_ticker[0], data, options)\n",
    "                figs[company][item][plot] = fig\n",
    "                # fig.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Equity Multiplier'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['01 - Ativo Total', '02.03 - Patrimônio Líquido'], \n",
    "    'right': [ '11.03.01 - Equity Multiplier (Ativos por Patrimônio Líquido)',], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'cumulative', 'normalization': True, 'range': 'flexible', },\n",
    "    'right': {'shape': 'ine', 'mode': 'standalone', 'normalization': False, }, \n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Proporção dos Ativos'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': [ '11.01.03 - Ativos Circulantes de Curto Prazo por Ativos', '11.01.04 - Ativos Não Circulantes de Longo Prazo por Ativos',], \n",
    "    'right': [], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'cumulative', 'normalization': True, 'range': 'flexible', },\n",
    "    'right': {'shape': 'ine', 'mode': 'standalone', 'normalization': True, }, \n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Proporção dos Passivos'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': [ '11.02.01 - Passivos Circulantes de Curto Prazo por Ativos', '11.02.02 - Passivos Não Circulantes de Longo Prazo por Ativos', '11.03 - Patrimônio Líquido por Ativos'], \n",
    "    'right': [], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'cumulative', 'normalization': True, 'range': 'flexible', },\n",
    "    'right': {'shape': 'ine', 'mode': 'standalone', 'normalization': False, }, \n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Passivos por Patrimônio Líquido'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': [ '11.03.02.01 - Passivos Circulantes de Curto Prazo por Patrimônio Líquido',  '11.03.02.02 - Passivos Não Circulantes de Longo Prazo por Patrimônio Líquido',], \n",
    "    'right': [], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'cumulative', 'normalization': True, 'range': 'flexible', },\n",
    "    'right': {'shape': 'ine', 'mode': 'standalone', 'normalization': False, 'outliers': True, }, \n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Ativos e Liquidez'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['01.01 - Ativo Circulante de Curto Prazo', '02.01 - Passivo Circulante de Curto Prazo'], \n",
    "    'right': ['11.01.02 - Liquidez (Ativos Circulantes por Passivos Circulantes)', ], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, },\n",
    "    'right': {'shape': 'ine', 'mode': 'standalone', 'normalization': False, 'mma': [3,2]}, \n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Ativos e Prazos'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': [df['01.01 - Ativo Circulante de Curto Prazo'], df['01.02 - Ativo Não Circulante de Longo Prazo']], \n",
    "    'right': ['11.01.03 - Ativos Circulantes de Curto Prazo por Ativos', '11.01.04 - Ativos Não Circulantes de Longo Prazo por Ativos', ], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': True, },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Capital de Giro'\n",
    "trace = (df['01.02 - Ativo Não Circulante de Longo Prazo']/df['02.02 - Passivo Não Circulante de Longo Prazo'])\n",
    "trace.name = 'Liquide de Longo Prazo (Ativos Não Circulantes por Passivos Não Circulantes)'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['11.01.02 - Liquidez (Ativos Circulantes por Passivos Circulantes)', trace], \n",
    "    'right': ['11.01.01 - Capital de Giro (Ativos Circulantes - Passivos Circulantes)'], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'range': 'flexible', },\n",
    "    'right': {'shape': 'area', 'mode': 'standalone', 'normalization': False, 'range': 'flexible', },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Contas a Receber e Faturamento'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['01.01.03 - Contas a Receber', '01.02.01.03 - Contas a Receber'], \n",
    "    'right': ['13.03 - Contas por Faturamento'], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'line', 'mode': 'standalone', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3,2], },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Estoques e Faturamento'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['01.01.04 - Estoques', '01.02.01.04 - Estoques'], \n",
    "    'right': ['13.04 - Estoques por Faturamento'], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, 'range': 'flexible', },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3,2], 'range': 'flexible', },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Ativos Biológicos e Faturamento'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['01.01.05 - Ativos Biológicos', '01.02.01.05 - Ativos Biológicos'], \n",
    "    'right': ['13.05 - Ativos Biológicos por Faturamento'], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3,2]},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Despesas e Faturamento'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['01.01.07 - Despesas', '01.02.01.07 - Despesas'], \n",
    "    'right': ['13.07 - Despesas por Faturamento'], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3,2]},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Tributos e Faturamento'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['01.01.06 - Tributos', '01.02.01.06 - Tributos'], \n",
    "    'right': ['13.06 - Tributos por Faturamento'], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3,2]},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Capex Ativos Imobilizados e Intangíveis'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['01.02.03 - Imobilizados', '01.02.04 - Intangível', '01.02.02 - Investimentos Não Capex'], \n",
    "    'right': ['01.02.03 - Imobilizados', '01.02.04 - Intangível', '01.02.02 - Investimentos Não Capex'], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': True, },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Imobilização do Patrimônio'\n",
    "trace = (df['11.03.04 - Patrimônio Imobilizado']/df['02.03 - Patrimônio Líquido'])\n",
    "trace.name = 'Patrimônio Imobilizado por Patrimônio Líquido'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['11.03.04 - Patrimônio Imobilizado', '02.03 - Patrimônio Líquido'], \n",
    "    'right': [trace], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'cumulative', 'normalization': False, 'mma': [3,2]},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Prazo da Dívida'\n",
    "trace = df['12.01.02.01 - Dívida Bruta Circulante de Curto Prazo']/df['12.01.02 - Dívida Bruta']\n",
    "trace.name = 'Dívida de Curto Prazo por Dívida '\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['12.01.02.01 - Dívida Bruta Circulante de Curto Prazo', '12.01.02.02 - Dívida Bruta Não Circulante de Longo Prazo Prazo'], \n",
    "    'right': [trace], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False,'mma': [3,2]},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Jurisdição da Dívida'\n",
    "trace = df['12.01.02.03 - Dívida Bruta em Moeda Nacional']/(df['12.01.02.03 - Dívida Bruta em Moeda Nacional']+df['12.01.02.04 - Dívida Bruta em Moeda Estrangeira'])\n",
    "trace.name = 'Nacionalização da Dívida'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['12.01.02.03 - Dívida Bruta em Moeda Nacional', '12.01.02.04 - Dívida Bruta em Moeda Estrangeira'], \n",
    "    'right': [trace], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False,'mma': [3,2], },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Dívida de Curto Prazo por Ativo de Curto Prazo'\n",
    "trace = df['12.01.02.01 - Dívida Bruta Circulante de Curto Prazo']/df['01.01 - Ativo Circulante de Curto Prazo']\n",
    "trace.name = 'Dívida de Curto Prazo por Ativo de Curto Prazo'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['02.01.04.01.01 - Empréstimos e Financiamentos em Moeda Nacional', '02.01.04.01.02 - Empréstimos e Financiamentos em Moeda Estrangeira', '02.01.04.02 - Debêntures', '02.01.04.03 - Arrendamentos', '02.01.04.09 - Outros empréstimos, financiamentos e debêntures', ], \n",
    "    'left_01': ['01.01 - Ativo Circulante de Curto Prazo'], \n",
    "    'right': [trace], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, },\n",
    "    'left_01': {'shape': 'line', 'mode': 'standalone', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2]},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Dívida de Longo Prazo por Ativo de Longo Prazo'\n",
    "trace = df['12.01.02.02 - Dívida Bruta Não Circulante de Longo Prazo Prazo']/df['01.02 - Ativo Não Circulante de Longo Prazo']\n",
    "trace.name = 'Dívida de Longo Prazo por Ativo de Longo Prazo'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['02.02.01.01.01 - Empréstimos e Financiamentos em Moeda Nacional', '02.02.01.01.02 - Empréstimos e Financiamentos em Moeda Estrangeira', '02.02.01.02 - Debêntures', '02.02.01.03 - Arrendamentos', '02.02.02.09 - Outros empréstimos, financiamentos e debêntures', ], \n",
    "    'left_01': ['01.02 - Ativo Não Circulante de Longo Prazo'], \n",
    "    'right': [trace], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, 'range': 'flexible'},\n",
    "    'left_01': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'range': 'flexible'},\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], 'range': 'flexible'},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Dívida por Patrimônio Líquido'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['12.01.02.01 - Dívida Bruta Circulante de Curto Prazo', '12.01.02.02 - Dívida Bruta Não Circulante de Longo Prazo Prazo', ], \n",
    "    'left_01': ['02.03 - Patrimônio Líquido'], \n",
    "    'right': ['12.02.01 - Dívida Bruta por Patrimônio Líquido'], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, },\n",
    "    'left_01': {'shape': 'line', 'mode': 'standalone', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3,2], },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Dívida Líquida'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': [df['12.01.02 - Dívida Bruta'], ], \n",
    "    'left_01': [df['01.01.01 - Caixa e Disponibilidades de Caixa']*-1], \n",
    "    'left_02': [df['12.01.03 - Dívida Líquida']], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, 'range': 'flexible'},\n",
    "    'left_01': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, 'range': 'flexible'},\n",
    "    'left_02': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'range': 'flexible'},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Dívida Líquida por EBITDA'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': [df['12.04.01 - Dívida Líquida por EBITDA']*-1, ], \n",
    "    'left_01': ['12.02.01 - Dívida Bruta por Patrimônio Líquido'],\n",
    "    'right': ['12.01.02 - Dívida Bruta', '02.03 - Patrimônio Líquido'], \n",
    "    # 'right': [ofs('12.04.01 - Dívida Líquida por EBITDA', 3), ]\n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'line', 'mode': 'cumulative', 'normalization': False, 'range': 'half'},\n",
    "    'left_01': {'shape': 'line', 'mode': 'cumulative', 'normalization': False, 'range': 'half'},\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'outliers': False, 'range': 'flexible'},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Endividamento Financeiro'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': [df['02.03 - Patrimônio Líquido'], df['12.01.02 - Dívida Bruta'], ], \n",
    "    'right': ['12.02.02 - Endividamento Financeiro'], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'cumulative', 'normalization': False, 'mma': [3, 2]},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Serviço da Dívida'\n",
    "trace = df['12.01.03 - Dívida Líquida']/df['03.11 - Lucro Líquido']\n",
    "trace.name = 'Serviço da Dívida'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['12.01.03 - Dívida Líquida', '03.11 - Lucro Líquido'], \n",
    "    'right': [trace], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Índice de Cobertura'\n",
    "trace = df['07.08.03.01 - Juros Pagos']/df['03.05 - LAJIR EBIT Resultado Antes do Resultado Financeiro e dos Tributos']\n",
    "trace.name = 'Juros por EBIT'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['07.08.03.01 - Juros Pagos', '03.05 - LAJIR EBIT Resultado Antes do Resultado Financeiro e dos Tributos', ], \n",
    "    'right': [trace], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Composição do Patrimônio Líquido'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['02.03.01 - Capital Social', '02.03.02 - Reservas de Capital', '02.03.03 - Reservas de Reavaliação', '02.03.04 - Reservas de Lucros', '02.03.05 - Lucros ou Prejuízos Acumulados', '02.03.06 - Ajustes de Avaliação Patrimonial', '02.03.07 - Ajustes Acumulados de Conversão', '02.03.08 - Outros Resultados Abrangentes', ], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, 'range': 'flexible', },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Composição do Patrimônio Líquido'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': ['02.03.01 - Capital Social', '02.03.02 - Reservas de Capital', '02.03.03 - Reservas de Reavaliação', '02.03.04 - Reservas de Lucros', '02.03.05 - Lucros ou Prejuízos Acumulados', '02.03.06 - Ajustes de Avaliação Patrimonial', '02.03.07 - Ajustes Acumulados de Conversão', '02.03.08 - Outros Resultados Abrangentes', ], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'line', 'mode': 'standalone', 'normalization': False, },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Margem Bruta'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left_1': [df['03.02 - Custo de Produção']*-1, df['03.03 - Resultado Bruto (Receita Líquida)'], ], \n",
    "    'right': [df['16.01 - Margem Bruta (Resultado Bruto (Receita Líquida) por Receita Bruto)'] * 100, ]\n",
    "}\n",
    "options = {\n",
    "    'left_1': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Margem Operacional'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left_1': [df['03.01 - Receita Bruta'], df['03.04 - Despesas Operacionais']*-1, ], \n",
    "    'right': [df['16.02 - Margem Operacional (Receitas Operacionais por Receita Bruta)'] * -100,]\n",
    "}\n",
    "options = {\n",
    "    'left_1': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, 'range': 'flexible', },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Margem EBIT'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left_1': [df['03.04 - Despesas Operacionais']*-1, df['03.05 - LAJIR EBIT Resultado Antes do Resultado Financeiro e dos Tributos'], ], \n",
    "    'right': [df['16.03.01 - Margem EBIT (EBIT por Resultado Bruto (Receita Líquida)'] * 100,]\n",
    "}\n",
    "options = {\n",
    "    'left_1': {'shape': 'area', 'mode': 'cumulative', 'normalization': False,},\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], 'range': 'flexible', },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Margem de Depreciação'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left_1': [df['03.01 - Receita Bruta'], df['07.04.01 - Depreciação e Amortização'] * -1, ], \n",
    "    'right': [df['16.03.02 - Margem de Depreciação por Resultado Bruto (Receita Líquida)'] * -100,]\n",
    "}\n",
    "options = {\n",
    "    'left_1': {'shape': 'area', 'mode': 'cumulative', 'normalization': False,},\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], 'range': 'flexible', },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Margem EBITDA'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left_1': [df['03.05 - LAJIR EBIT Resultado Antes do Resultado Financeiro e dos Tributos'], df['13.01 - LAJIDA EBITDA Resultado Antes do Resultado Financeiro e dos Tributos mais Depreciação e Amortização'], df['07.04.01 - Depreciação e Amortização'] * -1], \n",
    "    'right': [df['16.03 - Margem EBITDA (EBITDA por Resultado Bruto (Receita Líquida)'] * 100, df['16.03.02 - Margem de Depreciação por Resultado Bruto (Receita Líquida)'] * 100, ]\n",
    "}\n",
    "options = {\n",
    "    'left_1': {'shape': 'area', 'mode': 'cumulative', 'normalization': False,},\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], 'range': 'flexible', },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Resultado Financeiro'\n",
    "trace = df['03.06 - Resultado Financeiro (Não Operacional)']/df['03.05 - LAJIR EBIT Resultado Antes do Resultado Financeiro e dos Tributos']\n",
    "trace.name = 'Margem Financeira'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left_1': [df['03.05 - LAJIR EBIT Resultado Antes do Resultado Financeiro e dos Tributos'], df['03.06 - Resultado Financeiro (Não Operacional)']], \n",
    "    'right': [trace * 100, ]\n",
    "}\n",
    "options = {\n",
    "    'left_1': {'shape': 'area', 'mode': 'cumulative', 'normalization': False,},\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], 'range': 'flexible', },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Margem Líquida'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': [df['03.01 - Receita Bruta']], \n",
    "    'left_1': [df['03.02 - Custo de Produção'] * -1, df['03.04 - Despesas Operacionais'] * -1, df['03.06 - Resultado Financeiro (Não Operacional)'], df['03.08 - Impostos IRPJ e CSLL'] * -1, df['03.11 - Lucro Líquido']], \n",
    "    'right': [df['16.05 - Margem Líquida (Lucro Líquido por Receita Bruta)'] * 100, ]\n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'line', 'mode': 'standalone', 'normalization': False,'range': 'flexible', },\n",
    "    'left_1': {'shape': 'area', 'mode': 'cumulative', 'normalization': False,'range': 'flexible', },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], 'range': 'half', },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Resultado e Margem Líquida'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': [df['03.01 - Receita Bruta']], \n",
    "    'left_1': [df['03.11 - Lucro Líquido']], \n",
    "    'right': [df['16.05 - Margem Líquida (Lucro Líquido por Receita Bruta)'] * 100, ]\n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'line', 'mode': 'standalone', 'normalization': False,'range': 'flexible', },\n",
    "    'left_1': {'shape': 'area', 'mode': 'cumulative', 'normalization': False,'range': 'flexible', },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], 'range': 'half', },\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Patrimônio e Resultado (ROE)'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': [df['02.03 - Patrimônio Líquido']], \n",
    "    'left_1': [df['03.11 - Lucro Líquido']], \n",
    "    'right': [df['14.04.01 - ROE (Resultado por Patrimônio)'] * 100, ]\n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, },\n",
    "    'left_1': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], 'range': 'flexible'},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Capital Investido e Resultado (ROIC)'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': [df['14.03 - Capital Investido']], \n",
    "    'left_1': [df['03.05 - LAJIR EBIT Resultado Antes do Resultado Financeiro e dos Tributos']], \n",
    "    'right': [df['14.03.01 - ROIC (Retorno por Capital Investido)'] * 100, ]\n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, },\n",
    "    'left_1': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], 'range': 'flexible'},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Ativos e Resultado (ROAS)'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': [df['01 - Ativo Total']], \n",
    "    'left_1': [df['03.05 - LAJIR EBIT Resultado Antes do Resultado Financeiro e dos Tributos']], \n",
    "    'right': [df['14.05.01 - ROAS (EBIT por Ativos)'], ]\n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, },\n",
    "    'left_1': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], 'range': 'flexible'},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Ativos e Resultado (Coeficiente de Retorno)'\n",
    "trace = df['03.11 - Lucro Líquido'] / df['01 - Ativo Total']\n",
    "trace.name = 'Coeficiente de Retorno'\n",
    "data = {\n",
    "    'title': [title, 'Reais (R$)', 'Porcentagem (%)'], \n",
    "    'left': [df['01 - Ativo Total']], \n",
    "    'left_1': [df['03.11 - Lucro Líquido']], \n",
    "    'right': [trace * 100, ]\n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, },\n",
    "    'left_1': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'mma': [3, 2], 'range': 'flexible'},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'ROE, ROIC, ROAS e Coeficiente de Retorno'\n",
    "trace = df['03.11 - Lucro Líquido'] / df['01 - Ativo Total']\n",
    "trace.name = 'Coeficiente de Retorno'\n",
    "data = {\n",
    "    'title': [title, 'Porcentagem (%)', 'Reais (R$)', ], \n",
    "    # 'left': [df['01 - Ativo Total']], \n",
    "    # 'left_1': [df['03.11 - Lucro Líquido']], \n",
    "    'right': [df['14.04.01 - ROE (Resultado por Patrimônio)'] * 100, df['14.03.01 - ROIC (Retorno por Capital Investido)'] * 100, df['14.05.01 - ROAS (EBIT por Ativos)'] * 100, trace * 100, ]\n",
    "}\n",
    "\n",
    "options = {\n",
    "    'left': {'shape': 'area', 'mode': 'standalone', 'normalization': False, 'range': 'half'},\n",
    "    'left_1': {'shape': 'area', 'mode': 'cumulative', 'normalization': False, },\n",
    "    'right': {'shape': 'line', 'mode': 'standalone', 'normalization': False, 'range': 'half'},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Price'\n",
    "if df.TICKER[0][-1] == '3':\n",
    "    acoes = df['00.01.01 - Ações ON']\n",
    "else:\n",
    "    acoes = df['00.02.01 - Ações PN']\n",
    "\n",
    "trace = df['Adj Close'] / df['00.01.01 - Ações ON']\n",
    "trace.name = 'Preço por Ação'\n",
    "data = {\n",
    "    'title': [title, 'Porcentagem (%)', 'Reais (R$)', ], \n",
    "    'left': [df['Adj Close']], \n",
    "    'left_1': [df['03.11 - Lucro Líquido']], \n",
    "    'left_2': [acoes], \n",
    "}\n",
    "options = {\n",
    "    'left': {'shape': 'line', 'mode': 'standalone', 'normalization': True, 'range': 'flexible'},\n",
    "    'left_1': {'shape': 'line', 'mode': 'standalone', 'normalization': True, 'range': 'flexible'},\n",
    "    'left_2': {'shape': 'line', 'mode': 'standalone', 'normalization': True, 'range': 'flexible'},\n",
    "}\n",
    "fig = plot_tweak(df_ticker[0], data, options)\n",
    "# figs[company]['others'][title] = fig\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs = save_figs(figs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_decorator(func):\n",
    "    print(\"Code outside the wrapper, this is run once during decoration\")\n",
    "    \n",
    "    def wrapper(*args, **kwargs):\n",
    "        print(\"Code inside the wrapper, this is run every time the decorated function is called\")\n",
    "        return func(*args, **kwargs)\n",
    "    \n",
    "    return wrapper\n",
    "\n",
    "@my_decorator\n",
    "def my_function():\n",
    "    print(\"This is the decorated function\")\n",
    "\n",
    "print(\"Calling my_function\")\n",
    "my_function()\n",
    "print(\"Calling my_function again\")\n",
    "my_function()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DASHBOARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyter_dash import JupyterDash\n",
    "import dash\n",
    "from dash import dcc\n",
    "from dash import html\n",
    "from dash.dependencies import Input, Output\n",
    "import dash_bootstrap_components as dbc\n",
    "from dash_bootstrap_templates import ThemeSwitchAIO\n",
    "from dash import dash_table\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = run.load_pkl('dash_df_merged')\n",
    "df = run.load_pkl('dash_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = run.load_pkl(f'{b3.app_folder}quotes')\n",
    "fund = run.load_pkl(f'{b3.app_folder}fund')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes.keys(), fund.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fund = pd.concat(fund.values(), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = run.load_pkl(f'{b3.app_folder}quotes')\n",
    "fund = run.load_pkl(f'{b3.app_folder}fund')\n",
    "df_fund = pd.concat(fund.values(), ignore_index=True)\n",
    "df_fund = run.save_pkl(df_fund, f'{b3.app_folder}df_fund')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_fund = run.load_pkl(f'{b3.app_folder}df_fund')\n",
    "df_fund = run.load_pkl(f'df_fund')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "companies\n",
      "AERIS 0.16% 1+639, 1.283613s per item, Remaining: 0h 13m 40s\n",
      "ESTAPAR 0.31% 2+638, 0.977543s per item, Remaining: 0h 10m 23s\n",
      "ARMAC 0.47% 3+637, 0.877847s per item, Remaining: 0h 09m 19s\n",
      "ARTERIS 0.62% 4+636, 0.843149s per item, Remaining: 0h 08m 56s\n",
      "ATMASA 0.78% 5+635, 0.830543s per item, Remaining: 0h 08m 47s\n",
      "AZEVEDO 0.94% 6+634, 0.818111s per item, Remaining: 0h 08m 38s\n",
      "AZUL 1.09% 7+633, 0.798194s per item, Remaining: 0h 08m 25s\n",
      "BARDELLA 1.25% 8+632, 0.795790s per item, Remaining: 0h 08m 22s\n",
      "BBMLOGISTICA 1.41% 9+631, 0.791130s per item, Remaining: 0h 08m 19s\n",
      "CCR SA 1.56% 10+630, 0.789015s per item, Remaining: 0h 08m 17s\n",
      "METRO-SP 1.72% 11+629, 0.779547s per item, Remaining: 0h 08m 10s\n",
      "CONC RAPOSO 1.88% 12+628, 0.775792s per item, Remaining: 0h 08m 07s\n",
      "GRUAIRPORT 2.03% 13+627, 0.780681s per item, Remaining: 0h 08m 09s\n",
      "ECOVIAS 2.19% 14+626, 0.777043s per item, Remaining: 0h 08m 06s\n",
      "CONC RIO TER 2.34% 15+625, 0.776394s per item, Remaining: 0h 08m 05s\n",
      "ECOPISTAS 2.50% 16+624, 0.785482s per item, Remaining: 0h 08m 10s\n",
      "VIAOESTE 2.66% 17+623, 0.784238s per item, Remaining: 0h 08m 08s\n",
      "ROD TIETE 2.81% 18+622, 0.779192s per item, Remaining: 0h 08m 04s\n",
      "RT BANDEIRAS 2.97% 19+621, 0.778980s per item, Remaining: 0h 08m 03s\n",
      "AUTOBAN 3.12% 20+620, 0.780677s per item, Remaining: 0h 08m 04s\n",
      "DTCOM-DIRECT 3.28% 21+619, 0.782734s per item, Remaining: 0h 08m 04s\n",
      "ECON 3.44% 22+618, 0.780853s per item, Remaining: 0h 08m 02s\n",
      "ECORODOVIAS 3.59% 23+617, 0.777715s per item, Remaining: 0h 07m 59s\n",
      "ACO ALTONA 3.75% 24+616, 0.778696s per item, Remaining: 0h 07m 59s\n",
      "EMBPAR S/A [Errno 2] No such file or directory: 'datasets/company/EMBPAR S/A.pkl'\n",
      "EMBRAER 4.06% 26+614, 0.773757s per item, Remaining: 0h 07m 55s\n",
      "ETERNIT 4.22% 27+613, 0.773482s per item, Remaining: 0h 07m 54s\n",
      "FER C ATLANT 4.38% 28+612, 0.773110s per item, Remaining: 0h 07m 53s\n",
      "FLEX S/A [Errno 2] No such file or directory: 'datasets/company/FLEX S/A.pkl'\n",
      "FRAS-LE 4.69% 30+610, 0.771216s per item, Remaining: 0h 07m 50s\n",
      "GOL 4.84% 31+609, 0.772410s per item, Remaining: 0h 07m 50s\n",
      "GPS 5.00% 32+608, 0.769452s per item, Remaining: 0h 07m 47s\n",
      "HAGA S/A [Errno 2] No such file or directory: 'datasets/company/HAGA S/A.pkl'\n",
      "HIDROVIAS 5.31% 34+606, 0.766763s per item, Remaining: 0h 07m 44s\n",
      "HMOBI S.A 5.47% 35+605, 0.765260s per item, Remaining: 0h 07m 42s\n",
      "ROMI 5.62% 36+604, 0.763711s per item, Remaining: 0h 07m 41s\n",
      "INEPAR 5.78% 37+603, 0.765031s per item, Remaining: 0h 07m 41s\n",
      "INVEPAR 5.94% 38+602, 0.766902s per item, Remaining: 0h 07m 41s\n",
      "JSL 6.09% 39+601, 0.767214s per item, Remaining: 0h 07m 41s\n",
      "KEPLER WEBER 6.25% 40+600, 0.769573s per item, Remaining: 0h 07m 41s\n",
      "LOG-IN 6.41% 41+599, 0.773690s per item, Remaining: 0h 07m 43s\n",
      "MARCOPOLO 6.56% 42+598, 0.773949s per item, Remaining: 0h 07m 42s\n",
      "METALFRIO 6.72% 43+597, 0.776867s per item, Remaining: 0h 07m 43s\n",
      "RIOSULENSE 6.88% 44+596, 0.782421s per item, Remaining: 0h 07m 46s\n",
      "METISA 7.03% 45+595, 0.782800s per item, Remaining: 0h 07m 45s\n",
      "MILLS 7.19% 46+594, 0.783823s per item, Remaining: 0h 07m 45s\n",
      "MINASMAQUINA 7.34% 47+593, 0.783428s per item, Remaining: 0h 07m 44s\n",
      "MRS LOGIST 7.50% 48+592, 0.784626s per item, Remaining: 0h 07m 44s\n",
      "NORDON MET 7.66% 49+591, 0.782670s per item, Remaining: 0h 07m 42s\n",
      "PORTOBELLO 7.81% 50+590, 0.783309s per item, Remaining: 0h 07m 42s\n",
      "PORTO VM 7.97% 51+589, 0.781614s per item, Remaining: 0h 07m 40s\n",
      "PRATICA 8.12% 52+588, 0.780692s per item, Remaining: 0h 07m 39s\n",
      "PRINER 8.28% 53+587, 0.780252s per item, Remaining: 0h 07m 38s\n",
      "RANDON PART 8.44% 54+586, 0.779901s per item, Remaining: 0h 07m 37s\n",
      "RECRUSUL 8.59% 55+585, 0.779320s per item, Remaining: 0h 07m 35s\n",
      "ROD COLINAS 8.75% 56+584, 0.779016s per item, Remaining: 0h 07m 34s\n",
      "ALL NORTE 8.91% 57+583, 0.778342s per item, Remaining: 0h 07m 33s\n",
      "ALL PAULISTA 9.06% 58+582, 0.777156s per item, Remaining: 0h 07m 32s\n",
      "RUMO S.A. 9.22% 59+581, 0.776582s per item, Remaining: 0h 07m 31s\n",
      "SALUS INFRA 9.38% 60+580, 0.775490s per item, Remaining: 0h 07m 29s\n",
      "SANTOS BRP 9.53% 61+579, 0.774182s per item, Remaining: 0h 07m 28s\n",
      "SCHULZ 9.69% 62+578, 0.774636s per item, Remaining: 0h 07m 27s\n",
      "SEQUOIA LOG 9.84% 63+577, 0.777099s per item, Remaining: 0h 07m 28s\n",
      "SONDOTECNICA 10.00% 64+576, 0.783059s per item, Remaining: 0h 07m 31s\n",
      "TAURUS ARMAS 10.16% 65+575, 0.787542s per item, Remaining: 0h 07m 32s\n",
      "TEGMA 10.31% 66+574, 0.789465s per item, Remaining: 0h 07m 33s\n",
      "TRIUNFO PART 10.47% 67+573, 0.792111s per item, Remaining: 0h 07m 33s\n",
      "TREVISA 10.62% 68+572, 0.793112s per item, Remaining: 0h 07m 33s\n",
      "VALID 10.78% 69+571, 0.792766s per item, Remaining: 0h 07m 32s\n",
      "WEG 10.94% 70+570, 0.791820s per item, Remaining: 0h 07m 31s\n",
      "WETZEL S/A [Errno 2] No such file or directory: 'datasets/company/WETZEL S/A.pkl'\n",
      "WILSON SONS 11.25% 72+568, 0.789429s per item, Remaining: 0h 07m 28s\n",
      "WLM IND COM 11.41% 73+567, 0.788912s per item, Remaining: 0h 07m 27s\n",
      "ALGAR TELEC 11.56% 74+566, 0.788137s per item, Remaining: 0h 07m 26s\n",
      "BRISANET 11.72% 75+565, 0.787456s per item, Remaining: 0h 07m 24s\n",
      "BRITANIA 11.88% 76+564, 0.787550s per item, Remaining: 0h 07m 24s\n",
      "DESKTOP 12.03% 77+563, 0.787053s per item, Remaining: 0h 07m 23s\n",
      "TELEBRAS 12.19% 78+562, 0.787160s per item, Remaining: 0h 07m 22s\n",
      "TELEF BRASIL 12.34% 79+561, 0.786198s per item, Remaining: 0h 07m 21s\n",
      "UNIFIQUE 12.50% 80+560, 0.785303s per item, Remaining: 0h 07m 19s\n",
      "ALLIED 12.66% 81+559, 0.785301s per item, Remaining: 0h 07m 18s\n",
      "ALPARGATAS 12.81% 82+558, 0.784770s per item, Remaining: 0h 07m 17s\n",
      "ALPHAVILLE 12.97% 83+557, 0.783896s per item, Remaining: 0h 07m 16s\n",
      "AMERICANAS 13.12% 84+556, 0.782861s per item, Remaining: 0h 07m 15s\n",
      "ANIMA 13.28% 85+555, 0.782362s per item, Remaining: 0h 07m 14s\n",
      "AREZZO CO 13.44% 86+554, 0.782499s per item, Remaining: 0h 07m 13s\n",
      "BAHEMA 13.59% 87+553, 0.782182s per item, Remaining: 0h 07m 12s\n",
      "BAHIAPCH 13.75% 88+552, 0.781999s per item, Remaining: 0h 07m 11s\n",
      "BIC MONARK 13.91% 89+551, 0.781403s per item, Remaining: 0h 07m 10s\n",
      "ZAMP S.A. 14.06% 90+550, 0.782803s per item, Remaining: 0h 07m 10s\n",
      "CEA MODAS 14.22% 91+549, 0.781588s per item, Remaining: 0h 07m 09s\n",
      "CEABS 14.37% 92+548, 0.781820s per item, Remaining: 0h 07m 08s\n",
      "CAMBUCI 14.53% 93+547, 0.783167s per item, Remaining: 0h 07m 08s\n",
      "CEDRO 14.69% 94+546, 0.783238s per item, Remaining: 0h 07m 07s\n",
      "IND CATAGUAS 14.84% 95+545, 0.785159s per item, Remaining: 0h 07m 07s\n",
      "LOCAMERICA 15.00% 96+544, 0.785704s per item, Remaining: 0h 07m 07s\n",
      "COTEMINAS 15.16% 97+543, 0.785257s per item, Remaining: 0h 07m 06s\n",
      "SANTANENSE 15.31% 98+542, 0.785869s per item, Remaining: 0h 07m 05s\n",
      "COGNA ON 15.47% 99+541, 0.786825s per item, Remaining: 0h 07m 05s\n",
      "CONST A LIND 15.62% 100+540, 0.786351s per item, Remaining: 0h 07m 04s\n",
      "TENDA 15.78% 101+539, 0.786184s per item, Remaining: 0h 07m 03s\n",
      "TENDA ATACAD 15.94% 102+538, 0.786587s per item, Remaining: 0h 07m 03s\n",
      "FICA 16.09% 103+537, 0.786430s per item, Remaining: 0h 07m 02s\n",
      "CRUZEIRO EDU 16.25% 104+536, 0.786395s per item, Remaining: 0h 07m 01s\n",
      "CURY S/A [Errno 2] No such file or directory: 'datasets/company/CURY S/A.pkl'\n",
      "CVC BRASIL 16.56% 106+534, 0.788415s per item, Remaining: 0h 07m 01s\n",
      "LE BISCUIT 16.72% 107+533, 0.788786s per item, Remaining: 0h 07m 00s\n",
      "CYRELA REALT 16.88% 108+532, 0.790503s per item, Remaining: 0h 07m 00s\n",
      "DIRECIONAL 17.03% 109+531, 0.791685s per item, Remaining: 0h 07m 00s\n",
      "DOHLER 17.19% 110+530, 0.792257s per item, Remaining: 0h 06m 59s\n",
      "DOTZ SA 17.34% 111+529, 0.792070s per item, Remaining: 0h 06m 59s\n",
      "EVEN 17.50% 112+528, 0.791330s per item, Remaining: 0h 06m 57s\n",
      "EZTEC 17.66% 113+527, 0.792185s per item, Remaining: 0h 06m 57s\n",
      "GAFISA 17.81% 114+526, 0.792375s per item, Remaining: 0h 06m 56s\n",
      "GRAZZIOTIN 17.97% 115+525, 0.791996s per item, Remaining: 0h 06m 55s\n",
      "GRENDENE 18.12% 116+524, 0.793970s per item, Remaining: 0h 06m 56s\n",
      "GRUPO SOMA 18.28% 117+523, 0.793907s per item, Remaining: 0h 06m 55s\n",
      "GRUPO SBF 18.44% 118+522, 0.794693s per item, Remaining: 0h 06m 54s\n",
      "GUARARAPES 18.59% 119+521, 0.794874s per item, Remaining: 0h 06m 54s\n",
      "GUARUPART 18.75% 120+520, 0.794649s per item, Remaining: 0h 06m 53s\n",
      "HELBOR 18.91% 121+519, 0.795808s per item, Remaining: 0h 06m 53s\n",
      "HERCULES 19.06% 122+518, 0.795539s per item, Remaining: 0h 06m 52s\n",
      "HOTEIS OTHON 19.22% 123+517, 0.795393s per item, Remaining: 0h 06m 51s\n",
      "INTER SA 19.38% 124+516, 0.795388s per item, Remaining: 0h 06m 50s\n",
      "IMC S/A [Errno 2] No such file or directory: 'datasets/company/IMC S/A.pkl'\n",
      "IOCHP-MAXION 19.69% 126+514, 0.795066s per item, Remaining: 0h 06m 48s\n",
      "JHSF PART 19.84% 127+513, 0.794283s per item, Remaining: 0h 06m 47s\n",
      "JOAO FORTES 20.00% 128+512, 0.793575s per item, Remaining: 0h 06m 46s\n",
      "KALLAS 20.16% 129+511, 0.792810s per item, Remaining: 0h 06m 45s\n",
      "KARSTEN 20.31% 130+510, 0.792077s per item, Remaining: 0h 06m 43s\n",
      "LAVVI 20.47% 131+509, 0.791847s per item, Remaining: 0h 06m 43s\n",
      "LOCALIZA 20.62% 132+508, 0.791494s per item, Remaining: 0h 06m 42s\n",
      "UNIDAS 20.78% 133+507, 0.792171s per item, Remaining: 0h 06m 41s\n",
      "OURO VERDE 20.94% 134+506, 0.792468s per item, Remaining: 0h 06m 40s\n",
      "UNIDAS LOCAD 21.09% 135+505, 0.793665s per item, Remaining: 0h 06m 40s\n",
      "QUERO-QUERO 21.25% 136+504, 0.795918s per item, Remaining: 0h 06m 41s\n",
      "LOJAS RENNER 21.41% 137+503, 0.795851s per item, Remaining: 0h 06m 40s\n",
      "MAESTROLOC 21.56% 138+502, 0.795206s per item, Remaining: 0h 06m 39s\n",
      "MAGAZ LUIZA 21.72% 139+501, 0.795098s per item, Remaining: 0h 06m 38s\n",
      "METAL LEVE 21.88% 140+500, 0.794600s per item, Remaining: 0h 06m 37s\n",
      "ESTRELA 22.03% 141+499, 0.794460s per item, Remaining: 0h 06m 36s\n",
      "LOJAS MARISA 22.19% 142+498, 0.794208s per item, Remaining: 0h 06m 35s\n",
      "MELNICK 22.34% 143+497, 0.793426s per item, Remaining: 0h 06m 34s\n",
      "MITRE REALTY 22.50% 144+496, 0.793020s per item, Remaining: 0h 06m 33s\n",
      "MOBLY 22.66% 145+495, 0.792166s per item, Remaining: 0h 06m 32s\n",
      "MOURA DUBEUX 22.81% 146+494, 0.791847s per item, Remaining: 0h 06m 31s\n",
      "MOVIDA 22.97% 147+493, 0.791298s per item, Remaining: 0h 06m 30s\n",
      "ESPACOLASER 23.12% 148+492, 0.790924s per item, Remaining: 0h 06m 29s\n",
      "MRV 23.28% 149+491, 0.790658s per item, Remaining: 0h 06m 28s\n",
      "MUNDIAL 23.44% 150+490, 0.790309s per item, Remaining: 0h 06m 27s\n",
      "PDG REALT 23.59% 151+489, 0.790142s per item, Remaining: 0h 06m 26s\n",
      "PETZ 23.75% 152+488, 0.789471s per item, Remaining: 0h 06m 25s\n",
      "PETTENATI 23.91% 153+487, 0.789357s per item, Remaining: 0h 06m 24s\n",
      "PLANOEPLANO 24.06% 154+486, 0.789326s per item, Remaining: 0h 06m 23s\n",
      "PLASCAR PART 24.22% 155+485, 0.789011s per item, Remaining: 0h 06m 22s\n",
      "VESTE 24.38% 156+484, 0.789246s per item, Remaining: 0h 06m 21s\n",
      "RNI 24.53% 157+483, 0.788869s per item, Remaining: 0h 06m 21s\n",
      "ROSSI RESID 24.69% 158+482, 0.789242s per item, Remaining: 0h 06m 20s\n",
      "SPTURIS 24.84% 159+481, 0.789437s per item, Remaining: 0h 06m 19s\n",
      "SARAIVA LIVR 25.00% 160+480, 0.789252s per item, Remaining: 0h 06m 18s\n",
      "SER EDUCA 25.16% 161+479, 0.789333s per item, Remaining: 0h 06m 18s\n",
      "SMART FIT 25.31% 162+478, 0.788834s per item, Remaining: 0h 06m 17s\n",
      "SPRINGS 25.47% 163+477, 0.789026s per item, Remaining: 0h 06m 16s\n",
      "TIME FOR FUN 25.62% 164+476, 0.789751s per item, Remaining: 0h 06m 15s\n",
      "TECHNOS 25.78% 165+475, 0.789321s per item, Remaining: 0h 06m 14s\n",
      "TECNISA 25.94% 166+474, 0.789021s per item, Remaining: 0h 06m 13s\n",
      "TEGRA INCORP 26.09% 167+473, 0.788893s per item, Remaining: 0h 06m 13s\n",
      "TEKA 26.25% 168+472, 0.788626s per item, Remaining: 0h 06m 12s\n",
      "TEX RENAUX 26.41% 169+471, 0.789459s per item, Remaining: 0h 06m 11s\n",
      "TRACK FIELD 26.56% 170+470, 0.789052s per item, Remaining: 0h 06m 10s\n",
      "TRISUL 26.72% 171+469, 0.788921s per item, Remaining: 0h 06m 10s\n",
      "UNICASA 26.88% 172+468, 0.789200s per item, Remaining: 0h 06m 09s\n",
      "VAMOS 27.03% 173+467, 0.789294s per item, Remaining: 0h 06m 08s\n",
      "VIA 27.19% 174+466, 0.789205s per item, Remaining: 0h 06m 07s\n",
      "VIVARA S.A. 27.34% 175+465, 0.789014s per item, Remaining: 0h 06m 06s\n",
      "VIVER 27.50% 176+464, 0.788770s per item, Remaining: 0h 06m 05s\n",
      "VULCABRAS 27.66% 177+463, 0.788616s per item, Remaining: 0h 06m 05s\n",
      "WHIRLPOOL 27.81% 178+462, 0.788356s per item, Remaining: 0h 06m 04s\n",
      "YDUQS PART 27.97% 179+461, 0.788005s per item, Remaining: 0h 06m 03s\n",
      "AGROGALAXY 28.12% 180+460, 0.787476s per item, Remaining: 0h 06m 02s\n",
      "EXITO 28.28% 181+459, 0.787237s per item, Remaining: 0h 06m 01s\n",
      "AMBEV S/A [Errno 2] No such file or directory: 'datasets/company/AMBEV S/A.pkl'\n",
      "CARREFOUR BR 28.59% 183+457, 0.788983s per item, Remaining: 0h 06m 00s\n",
      "BOA SAFRA 28.75% 184+456, 0.788820s per item, Remaining: 0h 05m 59s\n",
      "BOMBRIL 28.91% 185+455, 0.788599s per item, Remaining: 0h 05m 58s\n",
      "BRASILAGRO 29.06% 186+454, 0.788676s per item, Remaining: 0h 05m 58s\n",
      "BRF SA 29.22% 187+453, 0.788527s per item, Remaining: 0h 05m 57s\n",
      "CAMIL 29.38% 188+452, 0.788165s per item, Remaining: 0h 05m 56s\n",
      "P.ACUCAR-CBD 29.53% 189+451, 0.789062s per item, Remaining: 0h 05m 55s\n",
      "ODERICH 29.69% 190+450, 0.789836s per item, Remaining: 0h 05m 55s\n",
      "CTC S.A. 29.84% 191+449, 0.790796s per item, Remaining: 0h 05m 55s\n",
      "TC 30.00% 192+448, 0.791327s per item, Remaining: 0h 05m 54s\n",
      "EXCELSIOR 30.16% 193+447, 0.791923s per item, Remaining: 0h 05m 53s\n",
      "GRUPO MATEUS 30.31% 194+446, 0.791574s per item, Remaining: 0h 05m 53s\n",
      "AGRIBRASIL 30.47% 195+445, 0.792086s per item, Remaining: 0h 05m 52s\n",
      "J.MACEDO 30.63% 196+444, 0.792043s per item, Remaining: 0h 05m 51s\n",
      "JALLESMACHAD 30.78% 197+443, 0.792829s per item, Remaining: 0h 05m 51s\n",
      "JBS 30.94% 198+442, 0.793069s per item, Remaining: 0h 05m 50s\n",
      "JOSAPAR 31.09% 199+441, 0.793448s per item, Remaining: 0h 05m 49s\n",
      "MARFRIG 31.25% 200+440, 0.793691s per item, Remaining: 0h 05m 49s\n",
      "M.DIASBRANCO 31.41% 201+439, 0.793957s per item, Remaining: 0h 05m 48s\n",
      "MINERVA 31.56% 202+438, 0.794252s per item, Remaining: 0h 05m 47s\n",
      "MINUPAR 31.72% 203+437, 0.794660s per item, Remaining: 0h 05m 47s\n",
      "GRUPO NATURA 31.87% 204+436, 0.794594s per item, Remaining: 0h 05m 46s\n",
      "NATURA 32.03% 205+435, 0.794831s per item, Remaining: 0h 05m 45s\n",
      "NATURALONE 32.19% 206+434, 0.794778s per item, Remaining: 0h 05m 44s\n",
      "POMIFRUTAS 32.34% 207+433, 0.795114s per item, Remaining: 0h 05m 44s\n",
      "RAIZEN ENERG 32.50% 208+432, 0.794862s per item, Remaining: 0h 05m 43s\n",
      "RAIZEN 32.66% 209+431, 0.794978s per item, Remaining: 0h 05m 42s\n",
      "SAO MARTINHO 32.81% 210+430, 0.794829s per item, Remaining: 0h 05m 41s\n",
      "ASSAI 32.97% 211+429, 0.794520s per item, Remaining: 0h 05m 40s\n",
      "ALIPERTI 33.12% 212+428, 0.794596s per item, Remaining: 0h 05m 40s\n",
      "SLC AGRICOLA 33.28% 213+427, 0.794720s per item, Remaining: 0h 05m 39s\n",
      "TERRASANTAPA 33.44% 214+426, 0.794530s per item, Remaining: 0h 05m 38s\n",
      "3TENTOS 33.59% 215+425, 0.794918s per item, Remaining: 0h 05m 37s\n",
      "ALFA HOLDING 33.75% 216+424, 0.794930s per item, Remaining: 0h 05m 37s\n",
      "ALIANSCSONAE 33.91% 217+423, 0.795287s per item, Remaining: 0h 05m 36s\n",
      "ALSOL 34.06% 218+422, 0.795456s per item, Remaining: 0h 05m 35s\n",
      "ALPER S.A. 34.22% 219+421, 0.796140s per item, Remaining: 0h 05m 35s\n",
      "APERAM 34.38% 220+420, 0.795988s per item, Remaining: 0h 05m 34s\n",
      "ALTERE SEC 34.53% 221+419, 0.795739s per item, Remaining: 0h 05m 33s\n",
      "B3 34.69% 222+418, 0.795449s per item, Remaining: 0h 05m 32s\n",
      "BANCO BMG 34.84% 223+417, 0.795449s per item, Remaining: 0h 05m 31s\n",
      "BANESTES 35.00% 224+416, 0.795416s per item, Remaining: 0h 05m 30s\n",
      "BBSEGURIDADE 35.16% 225+415, 0.796280s per item, Remaining: 0h 05m 30s\n",
      "ABC BRASIL 35.31% 226+414, 0.796120s per item, Remaining: 0h 05m 29s\n",
      "ALFA INVEST 35.47% 227+413, 0.796201s per item, Remaining: 0h 05m 28s\n",
      "AMAZONIA 35.62% 228+412, 0.796287s per item, Remaining: 0h 05m 28s\n",
      "BRADESCO 35.78% 229+411, 0.797045s per item, Remaining: 0h 05m 27s\n",
      "BRASIL 35.94% 230+410, 0.797316s per item, Remaining: 0h 05m 26s\n",
      "BTGP BANCO 36.09% 231+409, 0.798264s per item, Remaining: 0h 05m 26s\n",
      "BANESE 36.25% 232+408, 0.798158s per item, Remaining: 0h 05m 25s\n",
      "BANPARA 36.41% 233+407, 0.798317s per item, Remaining: 0h 05m 24s\n",
      "BANRISUL 36.56% 234+406, 0.798423s per item, Remaining: 0h 05m 24s\n",
      "MERC INVEST 36.72% 235+405, 0.798345s per item, Remaining: 0h 05m 23s\n",
      "MERCANTIL 36.88% 236+404, 0.798086s per item, Remaining: 0h 05m 22s\n",
      "NORD BRASIL 37.03% 237+403, 0.797930s per item, Remaining: 0h 05m 21s\n",
      "BANCO PAN 37.19% 238+402, 0.797724s per item, Remaining: 0h 05m 20s\n",
      "PINE 37.34% 239+401, 0.798043s per item, Remaining: 0h 05m 20s\n",
      "SANTANDER BR 37.50% 240+400, 0.798006s per item, Remaining: 0h 05m 19s\n",
      "BNDESPAR 37.66% 241+399, 0.798017s per item, Remaining: 0h 05m 18s\n",
      "BR PARTNERS 37.81% 242+398, 0.798139s per item, Remaining: 0h 05m 17s\n",
      "BR MALLS PAR 37.97% 243+397, 0.798475s per item, Remaining: 0h 05m 16s\n",
      "BR PROPERT 38.12% 244+396, 0.798761s per item, Remaining: 0h 05m 16s\n",
      "BRADESCO LSG 38.28% 245+395, 0.799397s per item, Remaining: 0h 05m 15s\n",
      "NEXPE 38.44% 246+394, 0.799684s per item, Remaining: 0h 05m 15s\n",
      "BRAZIL REALT 38.59% 247+393, 0.800953s per item, Remaining: 0h 05m 14s\n",
      "BRAZILIAN FR 38.75% 248+392, 0.802002s per item, Remaining: 0h 05m 14s\n",
      "BRAZILIAN SC 38.91% 249+391, 0.802617s per item, Remaining: 0h 05m 13s\n",
      "BRB BANCO 39.06% 250+390, 0.802642s per item, Remaining: 0h 05m 13s\n",
      "CAIXA SEGURI 39.22% 251+389, 0.803436s per item, Remaining: 0h 05m 12s\n",
      "HABITASUL 39.38% 252+388, 0.803205s per item, Remaining: 0h 05m 11s\n",
      "PAR AL BAHIA 39.53% 253+387, 0.803752s per item, Remaining: 0h 05m 11s\n",
      "SEG AL BAHIA 39.69% 254+386, 0.804890s per item, Remaining: 0h 05m 10s\n",
      "CIBRASEC 39.84% 255+385, 0.805521s per item, Remaining: 0h 05m 10s\n",
      "CIELO 40.00% 256+384, 0.805200s per item, Remaining: 0h 05m 09s\n",
      "CLEARSALE 40.16% 257+383, 0.804784s per item, Remaining: 0h 05m 08s\n",
      "ALFA CONSORC 40.31% 258+382, 0.804715s per item, Remaining: 0h 05m 07s\n",
      "COR RIBEIRO 40.47% 259+381, 0.804653s per item, Remaining: 0h 05m 06s\n",
      "CORREDOR LOG 40.62% 260+380, 0.804532s per item, Remaining: 0h 05m 05s\n",
      "MERC FINANC 40.78% 261+379, 0.804254s per item, Remaining: 0h 05m 04s\n",
      "MERCANTII 40.94% 262+378, 0.803909s per item, Remaining: 0h 05m 03s\n",
      "MERCATO EXPR 41.09% 263+377, 0.803908s per item, Remaining: 0h 05m 03s\n",
      "MERCEDESBENZ 41.25% 264+376, 0.803507s per item, Remaining: 0h 05m 02s\n",
      "CSU DIGITAL 41.41% 265+375, 0.803406s per item, Remaining: 0h 05m 01s\n",
      "SYN PROP TEC 41.56% 266+374, 0.803163s per item, Remaining: 0h 05m 00s\n",
      "DIBENS LSG 41.72% 267+373, 0.803415s per item, Remaining: 0h 04m 59s\n",
      "DMFINANCEIRA 41.88% 268+372, 0.803236s per item, Remaining: 0h 04m 58s\n",
      "ECO SEC AGRO 42.03% 269+371, 0.803151s per item, Remaining: 0h 04m 57s\n",
      "ALFA FINANC 42.19% 270+370, 0.803199s per item, Remaining: 0h 04m 57s\n",
      "G2D INVEST 42.34% 271+369, 0.802898s per item, Remaining: 0h 04m 56s\n",
      "GAIA AGRO 42.50% 272+368, 0.802971s per item, Remaining: 0h 04m 55s\n",
      "GENERALSHOPP 42.66% 273+367, 0.802712s per item, Remaining: 0h 04m 54s\n",
      "GP INVEST 42.81% 274+366, 0.803058s per item, Remaining: 0h 04m 53s\n",
      "HBR REALTY 42.97% 275+365, 0.802668s per item, Remaining: 0h 04m 52s\n",
      "IGUATEMI 43.12% 276+364, 0.802327s per item, Remaining: 0h 04m 52s\n",
      "IGUATEMI S.A 43.28% 277+363, 0.802130s per item, Remaining: 0h 04m 51s\n",
      "INTER CO 43.44% 278+362, 0.802456s per item, Remaining: 0h 04m 50s\n",
      "IRBBRASIL RE 43.59% 279+361, 0.802672s per item, Remaining: 0h 04m 49s\n",
      "ITAUUNIBANCO 43.75% 280+360, 0.802899s per item, Remaining: 0h 04m 49s\n",
      "ITAUSA 43.91% 281+359, 0.802745s per item, Remaining: 0h 04m 48s\n",
      "LOG COM PROP 44.06% 282+358, 0.802410s per item, Remaining: 0h 04m 47s\n",
      "LOPES BRASIL 44.22% 283+357, 0.802501s per item, Remaining: 0h 04m 46s\n",
      "MONT ARANHA 44.38% 284+356, 0.802392s per item, Remaining: 0h 04m 45s\n",
      "MULTIPLAN 44.53% 285+355, 0.802394s per item, Remaining: 0h 04m 44s\n",
      "MULTITERMINA 44.69% 286+354, 0.802510s per item, Remaining: 0h 04m 44s\n",
      "OCTANTE SEC 44.84% 287+353, 0.802387s per item, Remaining: 0h 04m 43s\n",
      "OPEA 45.00% 288+352, 0.802378s per item, Remaining: 0h 04m 42s\n",
      "PARANA 45.16% 289+351, 0.802100s per item, Remaining: 0h 04m 41s\n",
      "PDG SECURIT 45.31% 290+350, 0.801944s per item, Remaining: 0h 04m 40s\n",
      "GAIA SECURIT 45.47% 291+349, 0.802164s per item, Remaining: 0h 04m 39s\n",
      "POLO CAP SEC 45.62% 292+348, 0.801962s per item, Remaining: 0h 04m 39s\n",
      "PORTO SEGURO 45.78% 293+347, 0.802756s per item, Remaining: 0h 04m 38s\n",
      "PPLA 45.94% 294+346, 0.802592s per item, Remaining: 0h 04m 37s\n",
      "WTORRE PIC 46.09% 295+345, 0.802312s per item, Remaining: 0h 04m 36s\n",
      "SAO CARLOS 46.25% 296+344, 0.802099s per item, Remaining: 0h 04m 35s\n",
      "SIMPAR 46.41% 297+343, 0.801907s per item, Remaining: 0h 04m 35s\n",
      "MENEZES CORT 46.56% 298+342, 0.802190s per item, Remaining: 0h 04m 34s\n",
      "TRUESEC 46.72% 299+341, 0.802679s per item, Remaining: 0h 04m 33s\n",
      "VERTCIASEC 46.88% 300+340, 0.802432s per item, Remaining: 0h 04m 32s\n",
      "VERT-11 47.03% 301+339, 0.802328s per item, Remaining: 0h 04m 31s\n",
      "VERT-9CIASEC 47.19% 302+338, 0.802649s per item, Remaining: 0h 04m 31s\n",
      "VERTADIANTEC 47.34% 303+337, 0.802607s per item, Remaining: 0h 04m 30s\n",
      "VERT-ADIANTE 47.50% 304+336, 0.802455s per item, Remaining: 0h 04m 29s\n",
      "VERTCAPCOM 47.66% 305+335, 0.802890s per item, Remaining: 0h 04m 28s\n",
      "VERT-KOINCOM 47.81% 306+334, 0.803104s per item, Remaining: 0h 04m 28s\n",
      "VERTMAGALU 47.97% 307+333, 0.803193s per item, Remaining: 0h 04m 27s\n",
      "VERTMONEYFIN 48.12% 308+332, 0.803460s per item, Remaining: 0h 04m 26s\n",
      "WIZ CO 48.28% 309+331, 0.803434s per item, Remaining: 0h 04m 25s\n",
      "AURA 360 48.44% 310+330, 0.803749s per item, Remaining: 0h 04m 25s\n",
      "AURATUS 48.59% 311+329, 0.803469s per item, Remaining: 0h 04m 24s\n",
      "BRADESPAR 48.75% 312+328, 0.803698s per item, Remaining: 0h 04m 23s\n",
      "BRASKEM 48.91% 313+327, 0.803686s per item, Remaining: 0h 04m 22s\n",
      "FERBASA 49.06% 314+326, 0.804341s per item, Remaining: 0h 04m 22s\n",
      "MELHOR SP 49.22% 315+325, 0.804670s per item, Remaining: 0h 04m 21s\n",
      "SID NACIONAL 49.38% 316+324, 0.804658s per item, Remaining: 0h 04m 20s\n",
      "CBA 49.53% 317+323, 0.804328s per item, Remaining: 0h 04m 19s\n",
      "CSNMINERACAO 49.69% 318+322, 0.804160s per item, Remaining: 0h 04m 18s\n",
      "DEXCO 49.84% 319+321, 0.804491s per item, Remaining: 0h 04m 18s\n",
      "DEXXOS PAR 50.00% 320+320, 0.804159s per item, Remaining: 0h 04m 17s\n",
      "EUCATEX 50.16% 321+319, 0.804053s per item, Remaining: 0h 04m 16s\n",
      "FER HERINGER 50.31% 322+318, 0.804571s per item, Remaining: 0h 04m 15s\n",
      "GERDAU 50.47% 323+317, 0.804714s per item, Remaining: 0h 04m 15s\n",
      "IRANI 50.62% 324+316, 0.804670s per item, Remaining: 0h 04m 14s\n",
      "KLABIN S/A [Errno 2] No such file or directory: 'datasets/company/KLABIN S/A.pkl'\n",
      "LITEL 50.94% 326+314, 0.804728s per item, Remaining: 0h 04m 12s\n",
      "LITELA 51.09% 327+313, 0.804748s per item, Remaining: 0h 04m 11s\n",
      "MANGELS INDL 51.25% 328+312, 0.804962s per item, Remaining: 0h 04m 11s\n",
      "GERDAU MET 51.41% 329+311, 0.804970s per item, Remaining: 0h 04m 10s\n",
      "NUTRIPLANT 51.56% 330+310, 0.804897s per item, Remaining: 0h 04m 09s\n",
      "PANATLANTICA 51.72% 331+309, 0.805630s per item, Remaining: 0h 04m 08s\n",
      "PARANAPANEMA 51.88% 332+308, 0.805518s per item, Remaining: 0h 04m 08s\n",
      "SANSUY 52.03% 333+307, 0.805257s per item, Remaining: 0h 04m 07s\n",
      "SUZANO HOLD 52.19% 334+306, 0.805278s per item, Remaining: 0h 04m 06s\n",
      "SUZANO S.A. 52.34% 335+305, 0.805181s per item, Remaining: 0h 04m 05s\n",
      "TEKNO 52.50% 336+304, 0.804863s per item, Remaining: 0h 04m 04s\n",
      "CRISTAL 52.66% 337+303, 0.804957s per item, Remaining: 0h 04m 03s\n",
      "UNIPAR 52.81% 338+302, 0.805232s per item, Remaining: 0h 04m 03s\n",
      "USIMINAS 52.97% 339+301, 0.805647s per item, Remaining: 0h 04m 02s\n",
      "VALE 53.12% 340+300, 0.805474s per item, Remaining: 0h 04m 01s\n",
      "VALEPAR 53.28% 341+299, 0.805092s per item, Remaining: 0h 04m 00s\n",
      "VITTIA 53.44% 342+298, 0.804734s per item, Remaining: 0h 03m 59s\n",
      "ACO VERDE 53.59% 343+297, 0.805128s per item, Remaining: 0h 03m 59s\n",
      "AEGEA 53.75% 344+296, 0.805219s per item, Remaining: 0h 03m 58s\n",
      "AGUASTERESIN 53.91% 345+295, 0.804812s per item, Remaining: 0h 03m 57s\n",
      "ÁGUAS RIO 1 54.06% 346+294, 0.804601s per item, Remaining: 0h 03m 56s\n",
      "AGUAS RIO 4 54.22% 347+293, 0.804295s per item, Remaining: 0h 03m 55s\n",
      "GUARIROBA 54.37% 348+292, 0.804310s per item, Remaining: 0h 03m 54s\n",
      "ARGO ENERGIA 54.53% 349+291, 0.804362s per item, Remaining: 0h 03m 54s\n",
      "ARGO 54.69% 350+290, 0.804358s per item, Remaining: 0h 03m 53s\n",
      "AUTOFERDIAS 54.84% 351+289, 0.804952s per item, Remaining: 0h 03m 52s\n",
      "AUTOLITSUL 55.00% 352+288, 0.805740s per item, Remaining: 0h 03m 52s\n",
      "AUTOPLANSUL 55.16% 353+287, 0.805917s per item, Remaining: 0h 03m 51s\n",
      "AUTOREGIS 55.31% 354+286, 0.805880s per item, Remaining: 0h 03m 50s\n",
      "BLUEFIT 55.47% 355+285, 0.805653s per item, Remaining: 0h 03m 49s\n",
      "BORRACHAS 55.62% 356+284, 0.805460s per item, Remaining: 0h 03m 48s\n",
      "CAGECE 55.78% 357+283, 0.805202s per item, Remaining: 0h 03m 47s\n",
      "CELEO 55.94% 358+282, 0.804837s per item, Remaining: 0h 03m 46s\n",
      "CENCOSUD BR 56.09% 359+281, 0.804863s per item, Remaining: 0h 03m 46s\n",
      "CERRADINHO 56.25% 360+280, 0.804799s per item, Remaining: 0h 03m 45s\n",
      "CESP 56.41% 361+279, 0.804525s per item, Remaining: 0h 03m 44s\n",
      "CHESF 56.56% 362+278, 0.804857s per item, Remaining: 0h 03m 43s\n",
      "CORSAN 56.72% 363+277, 0.804928s per item, Remaining: 0h 03m 42s\n",
      "CIA SEC BMG 56.88% 364+276, 0.804931s per item, Remaining: 0h 03m 42s\n",
      "GASMIG 57.03% 365+275, 0.804954s per item, Remaining: 0h 03m 41s\n",
      "JAGUARA 57.19% 366+274, 0.804863s per item, Remaining: 0h 03m 40s\n",
      "MIRANDA 57.34% 367+273, 0.804641s per item, Remaining: 0h 03m 39s\n",
      "SINOPENERG 57.50% 368+272, 0.804398s per item, Remaining: 0h 03m 38s\n",
      "RODOV MG-050 57.66% 369+271, 0.804318s per item, Remaining: 0h 03m 37s\n",
      "RODPAULISTA 57.81% 370+270, 0.804247s per item, Remaining: 0h 03m 37s\n",
      "ECAR 57.97% 371+269, 0.804187s per item, Remaining: 0h 03m 36s\n",
      "CONCECOVIAS 58.13% 372+268, 0.803855s per item, Remaining: 0h 03m 35s\n",
      "ECOPONTE 58.28% 373+267, 0.803710s per item, Remaining: 0h 03m 34s\n",
      "COPEL G T SA 58.44% 374+266, 0.803777s per item, Remaining: 0h 03m 33s\n",
      "ECO050RODO 58.59% 375+265, 0.803691s per item, Remaining: 0h 03m 32s\n",
      "EMCCAMP 58.75% 376+264, 0.803435s per item, Remaining: 0h 03m 32s\n",
      "EBEC 58.91% 377+263, 0.803440s per item, Remaining: 0h 03m 31s\n",
      "ENTREVIAS 59.06% 378+262, 0.803396s per item, Remaining: 0h 03m 30s\n",
      "EQTL GOIAS 59.22% 379+261, 0.803890s per item, Remaining: 0h 03m 29s\n",
      "NISSEI FARMA 59.38% 380+260, 0.803947s per item, Remaining: 0h 03m 29s\n",
      "FERROVNS 59.53% 381+259, 0.803979s per item, Remaining: 0h 03m 28s\n",
      "OBAHORTIFRUT 59.69% 382+258, 0.804104s per item, Remaining: 0h 03m 27s\n",
      "HAUSCENTER 59.84% 383+257, 0.803989s per item, Remaining: 0h 03m 26s\n",
      "ANCHIETA 60.00% 384+256, 0.803653s per item, Remaining: 0h 03m 25s\n",
      "HOSPITALCARE 60.16% 385+255, 0.803627s per item, Remaining: 0h 03m 24s\n",
      "IGUARIO 60.31% 386+254, 0.803678s per item, Remaining: 0h 03m 24s\n",
      "INBRANDS 60.47% 387+253, 0.803571s per item, Remaining: 0h 03m 23s\n",
      "LIGHTENERG 60.62% 388+252, 0.803545s per item, Remaining: 0h 03m 22s\n",
      "LM TRANSPORT 60.78% 389+251, 0.803536s per item, Remaining: 0h 03m 21s\n",
      "LOCALFLEET 60.94% 390+250, 0.803850s per item, Remaining: 0h 03m 20s\n",
      "MOTTU I S.A 61.09% 391+249, 0.803813s per item, Remaining: 0h 03m 20s\n",
      "NCF PARTICIP 61.25% 392+248, 0.803727s per item, Remaining: 0h 03m 19s\n",
      "NEUMARKTRADE 61.41% 393+247, 0.803798s per item, Remaining: 0h 03m 18s\n",
      "PATRIMAR 61.56% 394+246, 0.804088s per item, Remaining: 0h 03m 17s\n",
      "PORTOVIT 61.72% 395+245, 0.804221s per item, Remaining: 0h 03m 17s\n",
      "PROLAGOS 61.88% 396+244, 0.804696s per item, Remaining: 0h 03m 16s\n",
      "RIO ALTO 62.03% 397+243, 0.804365s per item, Remaining: 0h 03m 15s\n",
      "RIO ALTO STL 62.19% 398+242, 0.804353s per item, Remaining: 0h 03m 14s\n",
      "RIO PARANA 62.34% 399+241, 0.804277s per item, Remaining: 0h 03m 13s\n",
      "SANEAMENTOGO 62.50% 400+240, 0.804182s per item, Remaining: 0h 03m 13s\n",
      "SNB PARTCIP 62.66% 401+239, 0.804231s per item, Remaining: 0h 03m 12s\n",
      "SOLVI ESSENC 62.81% 402+238, 0.804396s per item, Remaining: 0h 03m 11s\n",
      "TCP TERMINAL 62.97% 403+237, 0.804394s per item, Remaining: 0h 03m 10s\n",
      "TRANSBRASIL 63.12% 404+236, 0.804518s per item, Remaining: 0h 03m 09s\n",
      "TRAVSECVISA 63.28% 405+235, 0.804459s per item, Remaining: 0h 03m 09s\n",
      "TRAVSEC 63.44% 406+234, 0.804859s per item, Remaining: 0h 03m 08s\n",
      "TRIPLE PLAY 63.59% 407+233, 0.805169s per item, Remaining: 0h 03m 07s\n",
      "UNIGEL PART 63.75% 408+232, 0.804901s per item, Remaining: 0h 03m 06s\n",
      "USIPAMPASUL 63.91% 409+231, 0.804822s per item, Remaining: 0h 03m 05s\n",
      "BR TELECMULT 64.06% 410+230, 0.804683s per item, Remaining: 0h 03m 05s\n",
      "VENTOSSUL 64.22% 411+229, 0.804377s per item, Remaining: 0h 03m 04s\n",
      "VERO S.A. 64.38% 412+228, 0.804152s per item, Remaining: 0h 03m 03s\n",
      "VIABRASIL163 64.53% 413+227, 0.803996s per item, Remaining: 0h 03m 02s\n",
      "VIAPAULISTA 64.69% 414+226, 0.803990s per item, Remaining: 0h 03m 01s\n",
      "VIARONDON 64.84% 415+225, 0.804074s per item, Remaining: 0h 03m 00s\n",
      "VITRUBREPCOM 65.00% 416+224, 0.804176s per item, Remaining: 0h 03m 00s\n",
      "VIXLOGISTICA 65.16% 417+223, 0.804780s per item, Remaining: 0h 02m 59s\n",
      "VRENTAL 65.31% 418+222, 0.804719s per item, Remaining: 0h 02m 58s\n",
      "WINE 65.47% 419+221, 0.804581s per item, Remaining: 0h 02m 57s\n",
      "ALMEIDA 65.62% 420+220, 0.804238s per item, Remaining: 0h 02m 56s\n",
      "AGPART 65.78% 421+219, 0.804031s per item, Remaining: 0h 02m 56s\n",
      "CANTAGERACAO 65.94% 422+218, 0.804032s per item, Remaining: 0h 02m 55s\n",
      "CANTAREIRA 66.09% 423+217, 0.803882s per item, Remaining: 0h 02m 54s\n",
      "ANEMUS WIND 66.25% 424+216, 0.803601s per item, Remaining: 0h 02m 53s\n",
      "ODOYAENERGIA 66.41% 425+215, 0.803315s per item, Remaining: 0h 02m 52s\n",
      "ESPERANZA 66.56% 426+214, 0.803009s per item, Remaining: 0h 02m 51s\n",
      "TJMM 66.72% 427+213, 0.802764s per item, Remaining: 0h 02m 50s\n",
      "ASABRANCAH 66.88% 428+212, 0.802550s per item, Remaining: 0h 02m 50s\n",
      "AURAALMASMIN 67.03% 429+211, 0.802264s per item, Remaining: 0h 02m 49s\n",
      "AGIBANKBC 67.19% 430+210, 0.801950s per item, Remaining: 0h 02m 48s\n",
      "CCBBM 67.34% 431+209, 0.801692s per item, Remaining: 0h 02m 47s\n",
      "SOFISABM 67.50% 432+208, 0.801584s per item, Remaining: 0h 02m 46s\n",
      "BHGSA 67.66% 433+207, 0.802023s per item, Remaining: 0h 02m 46s\n",
      "BRK AMBIENTA 67.81% 434+206, 0.802256s per item, Remaining: 0h 02m 45s\n",
      "RECIFEGOIANA 67.97% 435+205, 0.802311s per item, Remaining: 0h 02m 44s\n",
      "BRKDISPEN 68.12% 436+204, 0.802157s per item, Remaining: 0h 02m 43s\n",
      "BSBENERGETIC 68.28% 437+203, 0.802134s per item, Remaining: 0h 02m 42s\n",
      "CC DES IMOB 68.44% 438+202, 0.802414s per item, Remaining: 0h 02m 42s\n",
      "CIASECURIT 68.59% 439+201, 0.802554s per item, Remaining: 0h 02m 41s\n",
      "VERTGYRA 68.75% 440+200, 0.802799s per item, Remaining: 0h 02m 40s\n",
      "VERT PROVI 68.91% 441+199, 0.802901s per item, Remaining: 0h 02m 39s\n",
      "RECARGAPAYVE 69.06% 442+198, 0.803243s per item, Remaining: 0h 02m 39s\n",
      "CMTRJ 69.22% 443+197, 0.803490s per item, Remaining: 0h 02m 38s\n",
      "CONSIGNADOS 69.38% 444+196, 0.804145s per item, Remaining: 0h 02m 37s\n",
      "COPELSA 69.53% 445+195, 0.804610s per item, Remaining: 0h 02m 36s\n",
      "CS BR PARTIC 69.69% 446+194, 0.804492s per item, Remaining: 0h 02m 36s\n",
      "RODPIRA-PANO 69.84% 447+193, 0.804648s per item, Remaining: 0h 02m 35s\n",
      "DRAMMENRJINF 70.00% 448+192, 0.804681s per item, Remaining: 0h 02m 34s\n",
      "ELFAMED 70.16% 449+191, 0.804899s per item, Remaining: 0h 02m 33s\n",
      "ENVIRONMENT 70.31% 450+190, 0.805317s per item, Remaining: 0h 02m 33s\n",
      "CONTOUR 70.47% 451+189, 0.805686s per item, Remaining: 0h 02m 32s\n",
      "FORNODEMINAS 70.62% 452+188, 0.806082s per item, Remaining: 0h 02m 31s\n",
      "FOZDORIOCLAR 70.78% 453+187, 0.806533s per item, Remaining: 0h 02m 30s\n",
      "GRANJA FARIA 70.94% 454+186, 0.806661s per item, Remaining: 0h 02m 30s\n",
      "HOLDING DO A 71.09% 455+185, 0.806611s per item, Remaining: 0h 02m 29s\n",
      "IFIN PARTICI 71.25% 456+184, 0.806747s per item, Remaining: 0h 02m 28s\n",
      "LABTEUTOBR 71.41% 457+183, 0.806612s per item, Remaining: 0h 02m 27s\n",
      "AMARELA 71.56% 458+182, 0.806524s per item, Remaining: 0h 02m 26s\n",
      "MADERO IND 71.72% 459+181, 0.806490s per item, Remaining: 0h 02m 25s\n",
      "MANAUS TRANS 71.88% 460+180, 0.806634s per item, Remaining: 0h 02m 25s\n",
      "MANTIQUEIRA 72.03% 461+179, 0.806561s per item, Remaining: 0h 02m 24s\n",
      "MONTE RODOVI 72.19% 462+178, 0.806583s per item, Remaining: 0h 02m 23s\n",
      "MOVIDALOC 72.34% 463+177, 0.807025s per item, Remaining: 0h 02m 22s\n",
      "NORTEBR 72.50% 464+176, 0.807026s per item, Remaining: 0h 02m 22s\n",
      "NORTEENERGIA 72.66% 465+175, 0.807249s per item, Remaining: 0h 02m 21s\n",
      "NOVANTS 72.81% 466+174, 0.807082s per item, Remaining: 0h 02m 20s\n",
      "OCEANICAENGE 72.97% 467+173, 0.806980s per item, Remaining: 0h 02m 19s\n",
      "HAZTEC 73.12% 468+172, 0.806980s per item, Remaining: 0h 02m 18s\n",
      "ORIZON MA 73.28% 469+171, 0.806804s per item, Remaining: 0h 02m 17s\n",
      "PRIVALIA 73.44% 470+170, 0.806740s per item, Remaining: 0h 02m 17s\n",
      "RIO ENERGY P 73.59% 471+169, 0.806562s per item, Remaining: 0h 02m 16s\n",
      "RODOVIAS DO 73.75% 472+168, 0.806372s per item, Remaining: 0h 02m 15s\n",
      "SBF COM PROD 73.91% 473+167, 0.806282s per item, Remaining: 0h 02m 14s\n",
      "SELF IT HOLD 74.06% 474+166, 0.806087s per item, Remaining: 0h 02m 13s\n",
      "SUGOI S/A [Errno 2] No such file or directory: 'datasets/company/SUGOI S/A.pkl'\n",
      "TELEMARNORTE 74.38% 476+164, 0.805794s per item, Remaining: 0h 02m 12s\n",
      "UNIAOQUIMICA 74.53% 477+163, 0.805709s per item, Remaining: 0h 02m 11s\n",
      "URBAMAIS 74.69% 478+162, 0.805654s per item, Remaining: 0h 02m 10s\n",
      "VIGOR FOOD 74.84% 479+161, 0.805521s per item, Remaining: 0h 02m 09s\n",
      "VOTCIMENTOS 75.00% 480+160, 0.805254s per item, Remaining: 0h 02m 08s\n",
      "XPINVESTIMEN 75.16% 481+159, 0.805165s per item, Remaining: 0h 02m 08s\n",
      "524 PARTICIP 75.31% 482+158, 0.805207s per item, Remaining: 0h 02m 07s\n",
      "ATOMPAR 75.47% 483+157, 0.805041s per item, Remaining: 0h 02m 06s\n",
      "BETAPART 75.62% 484+156, 0.805190s per item, Remaining: 0h 02m 05s\n",
      "CABINDA PART 75.78% 485+155, 0.805305s per item, Remaining: 0h 02m 04s\n",
      "CEMEPE 75.94% 486+154, 0.805264s per item, Remaining: 0h 02m 04s\n",
      "CIMS 76.09% 487+153, 0.805249s per item, Remaining: 0h 02m 03s\n",
      "GAMA PART 76.25% 488+152, 0.805188s per item, Remaining: 0h 02m 02s\n",
      "INVEST BEMGE 76.41% 489+151, 0.805172s per item, Remaining: 0h 02m 01s\n",
      "POLPAR 76.56% 490+150, 0.805244s per item, Remaining: 0h 02m 00s\n",
      "PROMPT PART 76.72% 491+149, 0.805200s per item, Remaining: 0h 01m 59s\n",
      "SUL 116 PART 76.88% 492+148, 0.805655s per item, Remaining: 0h 01m 59s\n",
      "YBYRA S/A [Errno 2] No such file or directory: 'datasets/company/YBYRA S/A.pkl'\n",
      "3R PETROLEUM 77.19% 494+146, 0.805532s per item, Remaining: 0h 01m 57s\n",
      "COSAN 77.34% 495+145, 0.805557s per item, Remaining: 0h 01m 56s\n",
      "ENAUTA PART 77.50% 496+144, 0.805602s per item, Remaining: 0h 01m 56s\n",
      "LUPATECH 77.66% 497+143, 0.805532s per item, Remaining: 0h 01m 55s\n",
      "OCEANPACT 77.81% 498+142, 0.805596s per item, Remaining: 0h 01m 54s\n",
      "OSX BRASIL 77.97% 499+141, 0.805959s per item, Remaining: 0h 01m 53s\n",
      "PETRORIO 78.12% 500+140, 0.806368s per item, Remaining: 0h 01m 52s\n",
      "VIBRA 78.28% 501+139, 0.806386s per item, Remaining: 0h 01m 52s\n",
      "PETROBRAS 78.44% 502+138, 0.806189s per item, Remaining: 0h 01m 51s\n",
      "PETRORECSA 78.59% 503+137, 0.806204s per item, Remaining: 0h 01m 50s\n",
      "PET MANGUINH 78.75% 504+136, 0.806319s per item, Remaining: 0h 01m 49s\n",
      "ULTRAPAR 78.91% 505+135, 0.806179s per item, Remaining: 0h 01m 48s\n",
      "ALLIAR 79.06% 506+134, 0.806243s per item, Remaining: 0h 01m 48s\n",
      "BAUMER 79.22% 507+133, 0.806335s per item, Remaining: 0h 01m 47s\n",
      "BIOMM 79.38% 508+132, 0.806265s per item, Remaining: 0h 01m 46s\n",
      "BLAU 79.53% 509+131, 0.806088s per item, Remaining: 0h 01m 45s\n",
      "VIVEO 79.69% 510+130, 0.805844s per item, Remaining: 0h 01m 44s\n",
      "D1000VFARMA 79.84% 511+129, 0.805675s per item, Remaining: 0h 01m 43s\n",
      "DASA 80.00% 512+128, 0.805509s per item, Remaining: 0h 01m 43s\n",
      "DIMED 80.16% 513+127, 0.805314s per item, Remaining: 0h 01m 42s\n",
      "PAGUE MENOS 80.31% 514+126, 0.805296s per item, Remaining: 0h 01m 41s\n",
      "FLEURY 80.47% 515+125, 0.805088s per item, Remaining: 0h 01m 40s\n",
      "HAPVIDA 80.62% 516+124, 0.804915s per item, Remaining: 0h 01m 39s\n",
      "MATER DEI 80.78% 517+123, 0.804709s per item, Remaining: 0h 01m 38s\n",
      "HYPERA 80.94% 518+122, 0.804707s per item, Remaining: 0h 01m 38s\n",
      "KORA SAUDE 81.09% 519+121, 0.804603s per item, Remaining: 0h 01m 37s\n",
      "LIFEMED 81.25% 520+120, 0.804650s per item, Remaining: 0h 01m 36s\n",
      "NORTCQUIMICA 81.41% 521+119, 0.804805s per item, Remaining: 0h 01m 35s\n",
      "ODONTOPREV 81.56% 522+118, 0.804718s per item, Remaining: 0h 01m 34s\n",
      "ONCOCLINICAS 81.72% 523+117, 0.804491s per item, Remaining: 0h 01m 34s\n",
      "ONCOMED 81.88% 524+116, 0.804319s per item, Remaining: 0h 01m 33s\n",
      "OUROFINO S/A [Errno 2] No such file or directory: 'datasets/company/OUROFINO S/A.pkl'\n",
      "PROFARMA 82.19% 526+114, 0.804001s per item, Remaining: 0h 01m 31s\n",
      "QUALICORP 82.34% 527+113, 0.804303s per item, Remaining: 0h 01m 30s\n",
      "QUALICORSEG 82.50% 528+112, 0.804241s per item, Remaining: 0h 01m 30s\n",
      "QUALITY SOFT 82.66% 529+111, 0.804140s per item, Remaining: 0h 01m 29s\n",
      "RAIADROGASIL 82.81% 530+110, 0.803927s per item, Remaining: 0h 01m 28s\n",
      "REDE D OR 82.97% 531+109, 0.803670s per item, Remaining: 0h 01m 27s\n",
      "BEMOBI TECH 83.12% 532+108, 0.803457s per item, Remaining: 0h 01m 26s\n",
      "BRQ 83.28% 533+107, 0.803186s per item, Remaining: 0h 01m 25s\n",
      "ENJOEI 83.44% 534+106, 0.802959s per item, Remaining: 0h 01m 25s\n",
      "GETNINJAS 83.59% 535+105, 0.802699s per item, Remaining: 0h 01m 24s\n",
      "INFRACOMM 83.75% 536+104, 0.802389s per item, Remaining: 0h 01m 23s\n",
      "INTELBRAS 83.91% 537+103, 0.802189s per item, Remaining: 0h 01m 22s\n",
      "WDC NETWORKS 84.06% 538+102, 0.801947s per item, Remaining: 0h 01m 21s\n",
      "LOCAWEB 84.22% 539+101, 0.801772s per item, Remaining: 0h 01m 20s\n",
      "MELIUZ 84.38% 540+100, 0.801609s per item, Remaining: 0h 01m 20s\n",
      "MULTILASER 84.53% 541+99, 0.801478s per item, Remaining: 0h 01m 19s\n",
      "NEOGRID 84.69% 542+98, 0.801378s per item, Remaining: 0h 01m 18s\n",
      "PADTEC 84.84% 543+97, 0.801421s per item, Remaining: 0h 01m 17s\n",
      "POSITIVO TEC 85.00% 544+96, 0.801718s per item, Remaining: 0h 01m 16s\n",
      "SINQIA 85.16% 545+95, 0.801730s per item, Remaining: 0h 01m 16s\n",
      "TRADEMASTER 85.31% 546+94, 0.801525s per item, Remaining: 0h 01m 15s\n",
      "TRADIMAQ 85.47% 547+93, 0.801535s per item, Remaining: 0h 01m 14s\n",
      "TOTVS 85.62% 548+92, 0.801877s per item, Remaining: 0h 01m 13s\n",
      "WESTWING 85.78% 549+91, 0.801905s per item, Remaining: 0h 01m 12s\n",
      "AES BRASIL 85.94% 550+90, 0.801758s per item, Remaining: 0h 01m 12s\n",
      "AESOPERACOES 86.09% 551+89, 0.801499s per item, Remaining: 0h 01m 11s\n",
      "AFLUENTE T 86.25% 552+88, 0.801397s per item, Remaining: 0h 01m 10s\n",
      "ALUPAR 86.41% 553+87, 0.801237s per item, Remaining: 0h 01m 09s\n",
      "AMBIPAR 86.56% 554+86, 0.801162s per item, Remaining: 0h 01m 08s\n",
      "AMPLA ENERG 86.72% 555+85, 0.801053s per item, Remaining: 0h 01m 08s\n",
      "AUREN 86.88% 556+84, 0.801106s per item, Remaining: 0h 01m 07s\n",
      "CACHOEIRA 87.03% 557+83, 0.801226s per item, Remaining: 0h 01m 06s\n",
      "CEMIG DIST 87.19% 558+82, 0.801612s per item, Remaining: 0h 01m 05s\n",
      "CEMIG GT 87.34% 559+81, 0.801616s per item, Remaining: 0h 01m 04s\n",
      "ELETROBRAS 87.50% 560+80, 0.801754s per item, Remaining: 0h 01m 04s\n",
      "EBRASIL 87.66% 561+79, 0.801701s per item, Remaining: 0h 01m 03s\n",
      "ELETROPAR 87.81% 562+78, 0.801735s per item, Remaining: 0h 01m 02s\n",
      "ELETROMIDIA 87.97% 563+77, 0.801846s per item, Remaining: 0h 01m 01s\n",
      "ELETROPAULO 88.12% 564+76, 0.802029s per item, Remaining: 0h 01m 00s\n",
      "ELETRORIVERS 88.28% 565+75, 0.802066s per item, Remaining: 0h 01m 00s\n",
      "ELETROZEMA 88.44% 566+74, 0.801932s per item, Remaining: 0h 00m 59s\n",
      "CELESC 88.59% 567+73, 0.802259s per item, Remaining: 0h 00m 58s\n",
      "CASAN 88.75% 568+72, 0.802379s per item, Remaining: 0h 00m 57s\n",
      "CELGPAR 88.91% 569+71, 0.802632s per item, Remaining: 0h 00m 56s\n",
      "CEG 89.06% 570+70, 0.802635s per item, Remaining: 0h 00m 56s\n",
      "COELBA 89.22% 571+69, 0.802922s per item, Remaining: 0h 00m 55s\n",
      "CEB 89.38% 572+68, 0.802823s per item, Remaining: 0h 00m 54s\n",
      "CEMIG 89.53% 573+67, 0.802908s per item, Remaining: 0h 00m 53s\n",
      "CELPE 89.69% 574+66, 0.803332s per item, Remaining: 0h 00m 53s\n",
      "COELCE 89.84% 575+65, 0.803524s per item, Remaining: 0h 00m 52s\n",
      "COSERN 90.00% 576+64, 0.803591s per item, Remaining: 0h 00m 51s\n",
      "CEEE-D 90.16% 577+63, 0.803656s per item, Remaining: 0h 00m 50s\n",
      "CEEE-T 90.31% 578+62, 0.803843s per item, Remaining: 0h 00m 49s\n",
      "COMGAS 90.47% 579+61, 0.803979s per item, Remaining: 0h 00m 49s\n",
      "COPEL 90.62% 580+60, 0.804014s per item, Remaining: 0h 00m 48s\n",
      "PAUL F LUZ 90.78% 581+59, 0.804298s per item, Remaining: 0h 00m 47s\n",
      "CPFL PIRATIN 90.94% 582+58, 0.804401s per item, Remaining: 0h 00m 46s\n",
      "SABESP 91.09% 583+57, 0.804472s per item, Remaining: 0h 00m 45s\n",
      "COPASA 91.25% 584+56, 0.804330s per item, Remaining: 0h 00m 45s\n",
      "SANEPAR 91.41% 585+55, 0.804538s per item, Remaining: 0h 00m 44s\n",
      "CICLUS AMBIE 91.56% 586+54, 0.804463s per item, Remaining: 0h 00m 43s\n",
      "COMERC PAR 91.72% 587+53, 0.804496s per item, Remaining: 0h 00m 42s\n",
      "CEEE-G 91.88% 588+52, 0.804561s per item, Remaining: 0h 00m 41s\n",
      "COMPASS 92.03% 589+51, 0.804874s per item, Remaining: 0h 00m 41s\n",
      "CPFL ENERGIA 92.19% 590+50, 0.805142s per item, Remaining: 0h 00m 40s\n",
      "CPFL RENOVAV 92.34% 591+49, 0.805552s per item, Remaining: 0h 00m 39s\n",
      "CPFL GERACAO 92.50% 592+48, 0.805756s per item, Remaining: 0h 00m 38s\n",
      "TRAN PAULIST 92.66% 593+47, 0.805755s per item, Remaining: 0h 00m 37s\n",
      "ENERGIAS BR 92.81% 594+46, 0.805703s per item, Remaining: 0h 00m 37s\n",
      "ESCELSA 92.97% 595+45, 0.805734s per item, Remaining: 0h 00m 36s\n",
      "EBE 93.12% 596+44, 0.805764s per item, Remaining: 0h 00m 35s\n",
      "ELEKTRO 93.28% 597+43, 0.805661s per item, Remaining: 0h 00m 34s\n",
      "EMAE 93.44% 598+42, 0.805469s per item, Remaining: 0h 00m 33s\n",
      "ENERSUL 93.59% 599+41, 0.805428s per item, Remaining: 0h 00m 33s\n",
      "ENERGISA MT 93.75% 600+40, 0.805335s per item, Remaining: 0h 00m 32s\n",
      "ENERGISAMRIO 93.91% 601+39, 0.805243s per item, Remaining: 0h 00m 31s\n",
      "ENERGISA NF 94.06% 602+38, 0.805241s per item, Remaining: 0h 00m 30s\n",
      "ENERGISA PB 94.22% 603+37, 0.805202s per item, Remaining: 0h 00m 29s\n",
      "ELE RONDONIA 94.38% 604+36, 0.805095s per item, Remaining: 0h 00m 28s\n",
      "ENERGISA 94.53% 605+35, 0.805160s per item, Remaining: 0h 00m 28s\n",
      "ENERGIPE 94.69% 606+34, 0.805178s per item, Remaining: 0h 00m 27s\n",
      "ENERG SUL SU 94.84% 607+33, 0.805129s per item, Remaining: 0h 00m 26s\n",
      "ENERTOCANTIN 95.00% 608+32, 0.804958s per item, Remaining: 0h 00m 25s\n",
      "ENERGISATRAN 95.16% 609+31, 0.804861s per item, Remaining: 0h 00m 24s\n",
      "ENERPEIXE 95.31% 610+30, 0.804688s per item, Remaining: 0h 00m 24s\n",
      "ENGIE BRASIL 95.47% 611+29, 0.804702s per item, Remaining: 0h 00m 23s\n",
      "ENGIEUBERLAN 95.62% 612+28, 0.804804s per item, Remaining: 0h 00m 22s\n",
      "ENGIE TRANSM 95.78% 613+27, 0.804752s per item, Remaining: 0h 00m 21s\n",
      "ENSEADA DO S 95.94% 614+26, 0.804641s per item, Remaining: 0h 00m 20s\n",
      "ENEVA 96.09% 615+25, 0.804472s per item, Remaining: 0h 00m 20s\n",
      "EQUATORIAL 96.25% 616+24, 0.804539s per item, Remaining: 0h 00m 19s\n",
      "EQTLMARANHAO 96.41% 617+23, 0.804554s per item, Remaining: 0h 00m 18s\n",
      "EQTL PARA 96.56% 618+22, 0.804396s per item, Remaining: 0h 00m 17s\n",
      "FGENERGIA 96.72% 619+21, 0.804253s per item, Remaining: 0h 00m 16s\n",
      "IGUA SA 96.88% 620+20, 0.804145s per item, Remaining: 0h 00m 16s\n",
      "ITAPEBI 97.03% 621+19, 0.804011s per item, Remaining: 0h 00m 15s\n",
      "LIGHT S/A [Errno 2] No such file or directory: 'datasets/company/LIGHT S/A.pkl'\n",
      "LIGHT 97.34% 623+17, 0.803819s per item, Remaining: 0h 00m 13s\n",
      "NEOENERGIA 97.50% 624+16, 0.804002s per item, Remaining: 0h 00m 12s\n",
      "OMEGAENERGIA 97.66% 625+15, 0.804009s per item, Remaining: 0h 00m 12s\n",
      "ORIZON 97.81% 626+14, 0.803948s per item, Remaining: 0h 00m 11s\n",
      "PROMAN 97.97% 627+13, 0.803973s per item, Remaining: 0h 00m 10s\n",
      "REDE ENERGIA 98.12% 628+12, 0.803940s per item, Remaining: 0h 00m 09s\n",
      "REDE INTEGRA 98.28% 629+11, 0.803787s per item, Remaining: 0h 00m 08s\n",
      "RENOVA 98.44% 630+10, 0.803664s per item, Remaining: 0h 00m 08s\n",
      "AES SUL 98.59% 631+9, 0.803472s per item, Remaining: 0h 00m 07s\n",
      "GER PARANAP 98.75% 632+8, 0.803422s per item, Remaining: 0h 00m 06s\n",
      "SAFIRA ENERG 98.91% 633+7, 0.803221s per item, Remaining: 0h 00m 05s\n",
      "SANESALTO 99.06% 634+6, 0.803269s per item, Remaining: 0h 00m 04s\n",
      "STO ANTONIO 99.22% 635+5, 0.803472s per item, Remaining: 0h 00m 04s\n",
      "STATKRAFT 99.38% 636+4, 0.803789s per item, Remaining: 0h 00m 03s\n",
      "TERM. PE III 99.53% 637+3, 0.803746s per item, Remaining: 0h 00m 02s\n",
      "TERMOPE 99.69% 638+2, 0.803642s per item, Remaining: 0h 00m 01s\n",
      "TAESA 99.84% 639+1, 0.803582s per item, Remaining: 0h 00m 00s\n",
      "UPTICK 100.00% 640+0, 0.803513s per item, Remaining: 0h 00m 00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['EMBPAR S/A',\n",
       " 'FLEX S/A',\n",
       " 'HAGA S/A',\n",
       " 'WETZEL S/A',\n",
       " 'CURY S/A',\n",
       " 'IMC S/A',\n",
       " 'AMBEV S/A',\n",
       " 'KLABIN S/A',\n",
       " 'SUGOI S/A',\n",
       " 'YBYRA S/A',\n",
       " 'OUROFINO S/A',\n",
       " 'LIGHT S/A']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create small datasets\n",
    "\n",
    "# dashboard\n",
    "\n",
    "# setor\n",
    "\n",
    "# subsetor\n",
    "\n",
    "# companies\n",
    "print('companies')\n",
    "failed = []\n",
    "folder = 'company'\n",
    "folder_path = os.path.join(b3.app_folder, folder)\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "start_time = run.time.time()\n",
    "companies = df_fund['PREGAO'].unique()\n",
    "for i, company in enumerate(companies):\n",
    "    try:\n",
    "        mask = df_fund['PREGAO'] == company\n",
    "        df = run.save_pkl(df_fund[mask], f'{b3.app_folder}{folder}/{company}')\n",
    "        print(company, run.remaining_time(start_time, len(companies), i))\n",
    "    except Exception as e:\n",
    "        print(company, e)\n",
    "        failed.append(company)\n",
    "failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fund.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fund['SETOR'].unique()\n",
    "mask_setor = df_fund['SETOR'] == 'BENS INDUSTRIAIS'\n",
    "df_fund[mask_setor]['SUBSETOR'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company = df_merged['PREGAO'].iloc[0]\n",
    "company = 'WEG'\n",
    "setor, subsetor, segmento = df[['SETOR', 'SUBSETOR', 'SEGMENTO']].iloc[0]\n",
    "\n",
    "m_cia = df_merged['PREGAO'] != company\n",
    "m_segmento = df_merged['SEGMENTO'] == segmento\n",
    "m_subsetor = df_merged['SUBSETOR'] == subsetor\n",
    "m_setor = df_merged['SETOR'] == setor\n",
    "\n",
    "cias_segmento = [cia for cia in df_merged[m_cia & m_segmento]['PREGAO'].unique().tolist()]\n",
    "cias_subsetor = [cia for cia in df_merged[m_cia & m_subsetor]['PREGAO'].unique().tolist() if cia not in cias_segmento]\n",
    "cias_setor = [cia for cia in df_merged[m_cia & m_setor]['PREGAO'].unique().tolist() if cia not in cias_subsetor and cia not in cias_segmento]\n",
    "\n",
    "setor, subsetor, segmento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['SETOR'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "awsome = [\"https://use.fontawesome.com/releases/v5.10.2/css/all.css\"]\n",
    "# app = dash.Dash(__name__, external_stylesheets=awsome)\n",
    "app = JupyterDash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP, awsome])\n",
    "app2 = JupyterDash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP, awsome])\n",
    "\n",
    "# Initialize setup\n",
    "tab_card = {'height': '100%'}\n",
    "main_config = {\n",
    "    'hover_mode': 'x unified', \n",
    "    'legend': \n",
    "        {\n",
    "        'yanchor': 'top',\n",
    "        'y': 0.9, \n",
    "        'xanchor': 'left', \n",
    "        'x': 0.1, \n",
    "        'title': {'text': None, }, \n",
    "        'font': {'color': 'white', }, \n",
    "        'bgcolor': 'rgba(0,0,0,0.5)', \n",
    "        }, \n",
    "    'margin': {'l':10, 'r':10, 't':10, 'b':10}, \n",
    "}\n",
    "graph_config = {\n",
    "    'displayModeBar': False, \n",
    "    'showTips': False, \n",
    "}\n",
    "template_theme_1 = 'flatly'\n",
    "template_theme_2 = 'darkly'\n",
    "url_theme_1 = dbc.themes.FLATLY\n",
    "url_theme_2 = dbc.themes.DARKLY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the layout of the app\n",
    "app.layout = dbc.Container(children=[\n",
    "    dbc.Row([ # Row 1\n",
    "        dbc.Col([ # Row 1, Col 1\n",
    "            dbc.Card([\n",
    "                dbc.CardBody([\n",
    "                    dbc.Row([ # Row 1, Col 1, Card 1 / Row 1\n",
    "                        dbc.Col([ # Row 1, Col 1, Card 1 / Row 1, Col 1\n",
    "                            html.Legend('Sobre')\n",
    "                        ], sm=8), \n",
    "                        dbc.Col([ # Row 1, Col 1, Card 1 / Row 1, Col 2\n",
    "                            html.I(className='fa fa-balance-scale', style={'font-size': '300%'})\n",
    "                        ] , sm=4, align='center'), \n",
    "                    ], style={'margin-top': '10px', }), \n",
    "                    dbc.Row([ # Row 1, Col 1, Card 1 / Row 2\n",
    "                        dbc.Col([ # Row 1, Col 1, Card 1 / Row 2, Col 1\n",
    "                            ThemeSwitchAIO(aio_id='theme', themes=[url_theme_1, url_theme_2]), \n",
    "                            html.Legend('MLGS'), \n",
    "                        ]), \n",
    "                    ], style={'margin-top': '10px', }), \n",
    "                    dbc.Row([\n",
    "                        dbc.Button('Site da B3', href='https://www.google.com', target='b3')\n",
    "                    ]), \n",
    "                ], style=tab_card), \n",
    "            ]), \n",
    "        ], sm=12, lg=3), \n",
    "        dbc.Col([ # Row 1, Col 2\n",
    "            dbc.Card([\n",
    "                dbc.CardBody([\n",
    "                    dbc.Row([ # Row 1, Col 1, Card 2 / Row 2\n",
    "                        html.Legend(f'Companhia {company}'), \n",
    "                    ]), \n",
    "                    dbc.Row([ # Row 1, Col 1, Card 2 / Row 1\n",
    "                        dbc.Col([# Row 1, Col 1, Card 2 / Row 1, Col 1\n",
    "                            html.Legend(f'Setor {setor}: Companhias {\", \".join(cias_setor)}'), \n",
    "                        ]), \n",
    "                        dbc.Col([# Row 1, Col 1, Card 2 / Row 1, Col 2\n",
    "                            html.Legend(f'SubSetor {subsetor}: Companhias {\", \".join(cias_subsetor)}'), \n",
    "                        ]), \n",
    "                        dbc.Col([# Row 1, Col 1, Card 2 / Row 1, Col 3\n",
    "                            html.Legend(f'Segmento {segmento}: Companhias {\", \".join(cias_segmento)}'), \n",
    "                        ]), \n",
    "                    ]), \n",
    "                ]), \n",
    "            ]), \n",
    "        ]), \n",
    "    ], className='g-2 my-auto', style={'matgin-top': '7px'}, ), \n",
    "], fluid=True, style={'height': '100vh'})\n",
    "\n",
    "# Run the app\n",
    "app.run_server(mode='external')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# App layout\n",
    "app.layout = dbc.Container([\n",
    "    # Row 1\n",
    "    dbc.Row([\n",
    "        # Row 1, Col 1\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    dbc.Row([ # Card Row 1\n",
    "                        dbc.Row(html.H2('Análise Fundamentalista')),\n",
    "                        dbc.Col(html.I(className='fa fa-balance-scale', style={'font-size': '300%'}), width=4, align='center'),\n",
    "                    ], style={'margin-top': '10px'}),\n",
    "                    dbc.Row([ # Card Row 2\n",
    "                        dbc.Col([\n",
    "                            ThemeSwitchAIO(aio_id='theme', themes=[url_theme_1, url_theme_2]), \n",
    "                        ]),\n",
    "                    ], style={'margin-top': '10px'}),\n",
    "                    dbc.Row([\n",
    "                        dbc.Col([\n",
    "                            dcc.Dropdown(\n",
    "                                id='setor-dropdown',\n",
    "                                options=[{'label': i, 'value': i} for i in df_fund['SETOR'].unique()],\n",
    "                                value=None,  # No default value\n",
    "                                multi=False,\n",
    "                                placeholder=\"Select a SETOR\"\n",
    "                            ),\n",
    "                        ]),\n",
    "                        dbc.Col([\n",
    "                            dcc.Dropdown(\n",
    "                                id='subsetor-dropdown',\n",
    "                                multi=False,\n",
    "                                placeholder=\"Select a SUBSETOR\"\n",
    "                            ),\n",
    "                        ]),\n",
    "                        dbc.Col([\n",
    "                            dcc.Dropdown(\n",
    "                                id='segmento-dropdown',\n",
    "                                multi=False,\n",
    "                                placeholder=\"Select a SEGMENTO\"\n",
    "                            ),\n",
    "                        ]),\n",
    "                    ]),\n",
    "                ]),\n",
    "            ),\n",
    "            width=3  # 1/4 of the width\n",
    "        ),\n",
    "        # Row 1, Col 2\n",
    "        dbc.Col(\n",
    "            [\n",
    "                # Row 1, Col 2 / Row 1\n",
    "                dbc.Row(html.H2(f'{company} {df[\"LISTAGEM\"].iloc[0]}')),\n",
    "                # Row 1, Col 2 / Row 2\n",
    "                dbc.Row([\n",
    "                    html.P([\n",
    "                        f\"{df['ATIVIDADE'].iloc[0]}\",\n",
    "                    ]), \n",
    "                    html.P([\n",
    "                        f\"{df['ESCRITURADOR'].iloc[0]}\", \" / \", \n",
    "                        html.A(f\"{df['CNPJ'].iloc[0]}\", href=f\"https://www.google.com/search?q={df['CNPJ'].iloc[0]}\", target='_blank'), \n",
    "                    ]), \n",
    "                ]),\n",
    "                # Row 2\n",
    "                dbc.Row([\n",
    "                    dbc.Col([\n",
    "                        html.Span('Setor'), html.Br(),\n",
    "                        html.Strong(f'{setor}'), html.Br(),\n",
    "                        html.P(f'{\", \".join(cias_setor)}')\n",
    "                    ]),\n",
    "                    dbc.Col([\n",
    "                        html.Span('SubSetor'), html.Br(),\n",
    "                        html.Strong(f'{subsetor}'), html.Br(),\n",
    "                        html.P(f'{\", \".join(cias_subsetor)}')\n",
    "                    ]),\n",
    "                    dbc.Col([\n",
    "                        html.Span('Segmento'), html.Br(),\n",
    "                        html.Strong(f'{segmento}'), html.Br(),\n",
    "                        html.P(f'{\", \".join(cias_segmento)}')\n",
    "                    ]),\n",
    "                ]),\n",
    "            ],\n",
    "            width=9  # 3/4 of the width\n",
    "        ),\n",
    "    ]),\n",
    "\n",
    "    # Row with 1 column\n",
    "    dbc.Row([\n",
    "        # Column 1\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    # Table to display companies\n",
    "                    dbc.Row([\n",
    "                        dbc.Col([\n",
    "                            dash_table.DataTable(\n",
    "                                id='company-table',\n",
    "                                columns=[\n",
    "                                    {\"name\": \"PREGAO\", \"id\": \"PREGAO\"},\n",
    "                                    {\"name\": \"TICKER\", \"id\": \"TICKER\"}\n",
    "                                ]\n",
    "                            )\n",
    "                        ])\n",
    "                    ])\n",
    "                ])\n",
    "            ),\n",
    "            width=12  # Full width\n",
    "        ),\n",
    "    ], style={'margin-top': '20px'}),\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Row with 1 column\n",
    "    dbc.Row([\n",
    "        # Column 1\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 1', className='card-title'),\n",
    "                    html.P('Content for column 1...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=12  # Full width\n",
    "        ),\n",
    "    ], style={'margin-top': '20px'}),\n",
    "\n",
    "    # Row with 2 columns\n",
    "    dbc.Row([\n",
    "        # Column 1\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 1', className='card-title'),\n",
    "                    html.P('Content for column 1...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=6  # Half of the width\n",
    "        ),\n",
    "        # Column 2\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 2', className='card-title'),\n",
    "                    html.P('Content for column 2...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=6  # Half of the width\n",
    "        ),\n",
    "    ], style={'margin-top': '20px'}),\n",
    "\n",
    "    # Row with 3 columns\n",
    "    dbc.Row([\n",
    "        # Row 2, Col 1\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 1', className='card-title'),\n",
    "                    html.P('Content for column 1...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=4  # 1/3 of the width\n",
    "        ),\n",
    "        # Row 2, Col 2\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 2', className='card-title'),\n",
    "                    html.P('Content for column 2...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=4  # 1/3 of the width\n",
    "        ),\n",
    "        # Row 2, Col 3\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 3', className='card-title'),\n",
    "                    html.P('Content for column 3...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=4  # 1/3 of the width\n",
    "        ),\n",
    "    ], style={'margin-top': '20px'}),  # Added margin for better visual separation of the rows\n",
    "\n",
    "    # Row with 4 columns\n",
    "    dbc.Row([\n",
    "        # Column 1\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 1', className='card-title'),\n",
    "                    html.P('Content for column 1...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=3  # 1/4 of the width\n",
    "        ),\n",
    "        # Column 2\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 2', className='card-title'),\n",
    "                    html.P('Content for column 2...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=3  # 1/4 of the width\n",
    "        ),\n",
    "        # Column 3\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 3', className='card-title'),\n",
    "                    html.P('Content for column 3...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=3  # 1/4 of the width\n",
    "        ),\n",
    "        # Column 4\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 4', className='card-title'),\n",
    "                    html.P('Content for column 4...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=3  # 1/4 of the width\n",
    "        ),\n",
    "    ], style={'margin-top': '20px'}),\n",
    "\n",
    "    # Row with 5 columns\n",
    "    dbc.Row([\n",
    "        # Column 1\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 1', className='card-title'),\n",
    "                    html.P('Content for column 1...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "        ),\n",
    "        # Column 2\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 2', className='card-title'),\n",
    "                    html.P('Content for column 2...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "        ),\n",
    "        # Column 3\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 3', className='card-title'),\n",
    "                    html.P('Content for column 3...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "        ),\n",
    "        # Column 4\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 4', className='card-title'),\n",
    "                    html.P('Content for column 4...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "        ),\n",
    "        # Column 5\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 5', className='card-title'),\n",
    "                    html.P('Content for column 5...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "        ),\n",
    "    ], style={'margin-top': '20px'}),\n",
    "\n",
    "    # Row with 6 columns\n",
    "    dbc.Row([\n",
    "        # Column 1\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 1', className='card-title'),\n",
    "                    html.P('Content for column 1...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=2  # 1/6 of the width\n",
    "        ),\n",
    "        # Column 2\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 2', className='card-title'),\n",
    "                    html.P('Content for column 2...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=2  # 1/6 of the width\n",
    "        ),\n",
    "        # Column 3\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 3', className='card-title'),\n",
    "                    html.P('Content for column 3...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=2  # 1/6 of the width\n",
    "        ),\n",
    "        # Column 4\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 4', className='card-title'),\n",
    "                    html.P('Content for column 4...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=2  # 1/6 of the width\n",
    "        ),\n",
    "        # Column 5\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 5', className='card-title'),\n",
    "                    html.P('Content for column 5...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=2  # 1/6 of the width\n",
    "        ),\n",
    "        # Column 6\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 6', className='card-title'),\n",
    "                    html.P('Content for column 6...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=2  # 1/6 of the width\n",
    "        ),\n",
    "    ], style={'margin-top': '20px'}),\n",
    "\n",
    "], fluid=True)\n",
    "\n",
    "\n",
    "# Update SUBSETOR options based on SETOR\n",
    "@app.callback(\n",
    "    Output('subsetor-dropdown', 'options'),\n",
    "    Input('setor-dropdown', 'value')\n",
    ")\n",
    "def update_subsetor_options(selected_setor):\n",
    "    try:  # Add error handling\n",
    "        if selected_setor:\n",
    "            mask = df_fund['SETOR'] == selected_setor\n",
    "            options = [{'label': i, 'value': i} for i in df_fund[mask]['SUBSETOR'].unique()]\n",
    "        else:\n",
    "            options = []\n",
    "        return options\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")  # Log error\n",
    "        return []  # Return empty options in case of error\n",
    "\n",
    "\n",
    "# Update SEGMENTO options based on SUBSETOR\n",
    "@app.callback(\n",
    "    Output('segmento-dropdown', 'options'),\n",
    "    Input('subsetor-dropdown', 'value')\n",
    ")\n",
    "def update_segmento_options(selected_subsetor):\n",
    "    try:\n",
    "        if selected_subsetor:\n",
    "            mask = df_fund['SUBSETOR'] == selected_subsetor\n",
    "            options = [{'label': i, 'value': i} for i in df_fund[mask]['SEGMENTO'].unique()]\n",
    "        else:\n",
    "            options = []\n",
    "        return options\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "# Update company table based on SETOR, SUBSETOR, and SEGMENTO\n",
    "@app.callback(\n",
    "    Output('company-table', 'data'),\n",
    "    [\n",
    "        Input('setor-dropdown', 'value'),\n",
    "        Input('subsetor-dropdown', 'value'),\n",
    "        Input('segmento-dropdown', 'value'),\n",
    "    ]\n",
    ")\n",
    "def update_table(selected_setor, selected_subsetor, selected_segmento):\n",
    "    try:\n",
    "        mask = ((df_fund['SETOR'] == selected_setor) if selected_setor else True) & \\\n",
    "               ((df_fund['SUBSETOR'] == selected_subsetor) if selected_subsetor else True) & \\\n",
    "               ((df_fund['SEGMENTO'] == selected_segmento) if selected_segmento else True)\n",
    "        data = df_fund[mask][[\"PREGAO\", \"TICKER\"]].to_dict('records')  # Only show specified columns\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "# Run the app\n",
    "app.run_server(mode='external')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create the fundamental analysis card\n",
    "def fundamental_analysis_card():\n",
    "    return dbc.Card(\n",
    "        dbc.CardBody([\n",
    "            dbc.Row([ \n",
    "                dbc.Col(html.H2('Análise Fundamentalista'), width=8),\n",
    "                dbc.Col(html.I(className='fa fa-balance-scale', style={'font-size': '300%'}), width=4, align='center'),\n",
    "            ], style={'margin-top': '10px'}),\n",
    "            dbc.Row([\n",
    "                dbc.Col([\n",
    "                    ThemeSwitchAIO(aio_id='theme', themes=[\"url_theme_1\", \"url_theme_2\"]), \n",
    "                ]),\n",
    "            ], style={'margin-top': '10px'}),\n",
    "            dbc.Row([\n",
    "                dbc.Col([\n",
    "                    dbc.Button(f'MAIS INFO SOBRE', href=f\"#\", target='_blank'), \n",
    "                ]),\n",
    "            ], style={'margin-top': '10px'}),\n",
    "        ])\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create the setor and subsetor dropdown selectors\n",
    "def selectors():\n",
    "    return dbc.Row([\n",
    "        dbc.Col([\n",
    "            dcc.Dropdown(\n",
    "                id='setor-dropdown',\n",
    "                options=[{'label': i, 'value': i} for i in df_fund['SETOR'].unique()],\n",
    "                value=None,  \n",
    "                multi=False,\n",
    "                placeholder=\"Select a SETOR\"\n",
    "            ),\n",
    "        ]),\n",
    "        dbc.Col([\n",
    "            dcc.Dropdown(\n",
    "                id='subsetor-dropdown',\n",
    "                multi=False,\n",
    "                placeholder=\"Select a SUBSETOR\"\n",
    "            ),\n",
    "        ]),\n",
    "        dbc.Col([\n",
    "            dcc.Dropdown(\n",
    "                id='segmento-dropdown',\n",
    "                multi=False,\n",
    "                placeholder=\"Select a SEGMENTO\"\n",
    "            ),\n",
    "        ]),\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_creator(content_dict):\n",
    "    \"\"\"\n",
    "    Create a list of Dash HTML components.\n",
    "\n",
    "    Parameters:\n",
    "        content_dict (dict): A dictionary containing 'title' and 'content' keys.\n",
    "        'content' can be a string or a list of strings, each of which is rendered as a new paragraph.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list containing Dash HTML components.\n",
    "    \"\"\"\n",
    "    # Ensure content is a list using a ternary expression\n",
    "    content = content_dict['content'] if isinstance(content_dict['content'], list) else [content_dict['content']]\n",
    "    \n",
    "    # Create a paragraph for each item in content\n",
    "    paragraphs = [html.P(item, className='card-text') for item in content]\n",
    "    \n",
    "    # Concatenate title and paragraphs and return\n",
    "    return [html.H5(content_dict['title'], className='card-title')] + paragraphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_2_left(col1_content, col2_content):\n",
    "    return dbc.Row([\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody(col1_content)\n",
    "            ),\n",
    "            width=3\n",
    "        ),\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody(col2_content)\n",
    "            ),\n",
    "            width=9\n",
    "        ),\n",
    "    ], style={'margin-top': '20px'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create the company information card\n",
    "def company_info_card(company, df, setor, cias_setor, subsetor, cias_subsetor, segmento, cias_segmento):\n",
    "    return dbc.Card(\n",
    "        dbc.CardBody([\n",
    "            dbc.Row(html.H2(f'{company} {df[\"LISTAGEM\"].iloc[0]}')),\n",
    "            dbc.Row([\n",
    "                html.P([\n",
    "                    f\"{df['ATIVIDADE'].iloc[0]}\",\n",
    "                ]), \n",
    "                html.P([\n",
    "                    f\"{df['ESCRITURADOR'].iloc[0]}\", \" / \", \n",
    "                    html.A(f\"{df['CNPJ'].iloc[0]}\", href=f\"https://www.google.com/search?q={df['CNPJ'].iloc[0]}\", target='_blank'), \n",
    "                ]), \n",
    "            ]),\n",
    "            dbc.Row([\n",
    "                dbc.Col([\n",
    "                    html.Span('Setor'), html.Br(),\n",
    "                    html.Strong(f'{setor}'), html.Br(),\n",
    "                    html.P(f'{\", \".join(cias_setor)}')\n",
    "                ]),\n",
    "                dbc.Col([\n",
    "                    html.Span('SubSetor'), html.Br(),\n",
    "                    html.Strong(f'{subsetor}'), html.Br(),\n",
    "                    html.P(f'{\", \".join(cias_subsetor)}')\n",
    "                ]),\n",
    "                dbc.Col([\n",
    "                    html.Span('Segmento'), html.Br(),\n",
    "                    html.Strong(f'{segmento}'), html.Br(),\n",
    "                    html.P(f'{\", \".join(cias_segmento)}')\n",
    "                ]),\n",
    "            ]),\n",
    "        ])\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "content_1_1 = {\n",
    "    'title': 'Análise Fundamentalista',\n",
    "    'content': [\n",
    "        'Dark/Light Theme', \n",
    "        'Select 1', \n",
    "        'Select 2', \n",
    "        'Select 3', \n",
    "        ]\n",
    "}\n",
    "\n",
    "content_1_2 = {\n",
    "    'title': f'{company}',\n",
    "    'content': [\n",
    "    f\"{df['ATIVIDADE'].iloc[0]}\", \n",
    "    f\"{setor} > {subsetor} > {segmento}\", \n",
    "\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def card(content):\n",
    "    # Check if header exists and create CardHeader if it does\n",
    "    header = dbc.CardHeader(content['header']) if 'header' in content else None\n",
    "    \n",
    "    # Check if body exists and create CardBody if it does\n",
    "    body = dbc.CardBody(content['body']) if 'body' in content else None\n",
    "    \n",
    "    # Check if footer exists and create CardFooter if it does\n",
    "    footer = dbc.CardFooter(content['footer']) if 'footer' in content else None\n",
    "    \n",
    "    # Return dbc.Card with available components\n",
    "    return dbc.Card([component for component in [header, body, footer] if component is not None])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = {\n",
    "    'header': [\n",
    "        html.H2('Header', className='card-title'),\n",
    "    ], \n",
    "    'body': [\n",
    "        html.H5('Subheader', className='card-title'),\n",
    "        html.P('Some paragraph text'),\n",
    "        html.P('Another paragraph'),\n",
    "        dbc.Button('Click me', color='primary'),\n",
    "    ], \n",
    "    'footer': [\n",
    "        html.A('Go to Google', href='https://www.google.com', target='_blank'), \n",
    "    ], \n",
    "}\n",
    "example_2 = {\n",
    "    # 'header': [\n",
    "    #     html.H2('Header', className='card-title'),\n",
    "    # ], \n",
    "    'body': [\n",
    "        html.H5('Subheader', className='card-title'),\n",
    "        html.P('Some paragraph text'),\n",
    "        html.P('Another paragraph'),\n",
    "        dbc.Button('Click me', color='primary'),\n",
    "    ], \n",
    "    # 'footer': [\n",
    "    #     html.A('Go to Google', href='https://www.google.com', target='_blank'), \n",
    "    # ], \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# App layout\n",
    "app.layout = dbc.Container([\n",
    "    card(example), \n",
    "    card(example), \n",
    "], fluid=True)\n",
    "\n",
    "# Run the app\n",
    "app.run_server(mode='external')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# App layout\n",
    "app2.layout = dbc.Container([\n",
    "    # Example Row 1 with 1 column\n",
    "    dbc.Row([\n",
    "        dbc.Col(card(example), width=12)\n",
    "    ], style={'margin-top': '20px'}),\n",
    "    \n",
    "    # Example Row 2 with 2 columns\n",
    "    dbc.Row([\n",
    "        dbc.Col(card(example), width=6),\n",
    "        dbc.Col(card(example_2), width=6),\n",
    "    ], style={'margin-top': '20px'}),\n",
    "    \n",
    "    # Example Row 3 with 3 columns\n",
    "    dbc.Row([\n",
    "        dbc.Col(card(example), width=4),\n",
    "        dbc.Col(card(example), width=4),\n",
    "        dbc.Col(card(example_2), width=4),\n",
    "    ], style={'margin-top': '20px'}),\n",
    "    \n",
    "    # Example Row 4 with 4 columns\n",
    "    dbc.Row([\n",
    "        dbc.Col(card(example), width=3),\n",
    "        dbc.Col(card(example), width=3),\n",
    "        dbc.Col(card(example), width=3),\n",
    "        dbc.Col(card(example_2), width=3),\n",
    "    ], style={'margin-top': '20px'}),\n",
    "    \n",
    "    # Example Row 5 with 5 columns\n",
    "    dbc.Row([\n",
    "        dbc.Col(card(example),),\n",
    "        dbc.Col(card(example),),\n",
    "        dbc.Col(card(example),),\n",
    "        dbc.Col(card(example),),\n",
    "        dbc.Col(card(example_2),),\n",
    "    ], style={'margin-top': '20px'}),\n",
    "\n",
    "    # Example Row 6 with 6 columns\n",
    "    dbc.Row([\n",
    "        dbc.Col(card(example), width=2),\n",
    "        dbc.Col(card(example), width=2),\n",
    "        dbc.Col(card(example), width=2),\n",
    "        dbc.Col(card(example), width=2),\n",
    "        dbc.Col(card(example), width=2),\n",
    "        dbc.Col(card(example_2), width=2),\n",
    "    ], style={'margin-top': '20px'}),\n",
    "], fluid=True)\n",
    "\n",
    "# Run the app\n",
    "app2.run_server(mode='external')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.layout = dbc.Container([\n",
    "   # Row with 1 column\n",
    "    dbc.Row([\n",
    "        # Column 1\n",
    "        dbc.Col(\n",
    "            card(example), \n",
    "            width=12  # Full width\n",
    "        ),\n",
    "    ], style={'margin-top': '20px'}),\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Row with 1 column\n",
    "    dbc.Row([\n",
    "        # Column 1\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 1', className='card-title'),\n",
    "                    html.P('Content for column 1...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=12  # Full width\n",
    "        ),\n",
    "    ], style={'margin-top': '20px'}),\n",
    "\n",
    "    # Row with 2 columns\n",
    "    dbc.Row([\n",
    "        # Column 1\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 1', className='card-title'),\n",
    "                    html.P('Content for column 1...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=6  # Half of the width\n",
    "        ),\n",
    "        # Column 2\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 2', className='card-title'),\n",
    "                    html.P('Content for column 2...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=6  # Half of the width\n",
    "        ),\n",
    "    ], style={'margin-top': '20px'}),\n",
    "\n",
    "    # Row with 3 columns\n",
    "    dbc.Row([\n",
    "        # Row 2, Col 1\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 1', className='card-title'),\n",
    "                    html.P('Content for column 1...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=4  # 1/3 of the width\n",
    "        ),\n",
    "        # Row 2, Col 2\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 2', className='card-title'),\n",
    "                    html.P('Content for column 2...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=4  # 1/3 of the width\n",
    "        ),\n",
    "        # Row 2, Col 3\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 3', className='card-title'),\n",
    "                    html.P('Content for column 3...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=4  # 1/3 of the width\n",
    "        ),\n",
    "    ], style={'margin-top': '20px'}),  # Added margin for better visual separation of the rows\n",
    "\n",
    "    # Row with 4 columns\n",
    "    dbc.Row([\n",
    "        # Column 1\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 1', className='card-title'),\n",
    "                    html.P('Content for column 1...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=3  # 1/4 of the width\n",
    "        ),\n",
    "        # Column 2\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 2', className='card-title'),\n",
    "                    html.P('Content for column 2...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=3  # 1/4 of the width\n",
    "        ),\n",
    "        # Column 3\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 3', className='card-title'),\n",
    "                    html.P('Content for column 3...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=3  # 1/4 of the width\n",
    "        ),\n",
    "        # Column 4\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 4', className='card-title'),\n",
    "                    html.P('Content for column 4...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=3  # 1/4 of the width\n",
    "        ),\n",
    "    ], style={'margin-top': '20px'}),\n",
    "\n",
    "    # Row with 5 columns\n",
    "    dbc.Row([\n",
    "        # Column 1\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 1', className='card-title'),\n",
    "                    html.P('Content for column 1...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "        ),\n",
    "        # Column 2\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 2', className='card-title'),\n",
    "                    html.P('Content for column 2...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "        ),\n",
    "        # Column 3\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 3', className='card-title'),\n",
    "                    html.P('Content for column 3...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "        ),\n",
    "        # Column 4\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 4', className='card-title'),\n",
    "                    html.P('Content for column 4...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "        ),\n",
    "        # Column 5\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 5', className='card-title'),\n",
    "                    html.P('Content for column 5...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "        ),\n",
    "    ], style={'margin-top': '20px'}),\n",
    "\n",
    "    # Row with 6 columns\n",
    "    dbc.Row([\n",
    "        # Column 1\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 1', className='card-title'),\n",
    "                    html.P('Content for column 1...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=2  # 1/6 of the width\n",
    "        ),\n",
    "        # Column 2\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 2', className='card-title'),\n",
    "                    html.P('Content for column 2...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=2  # 1/6 of the width\n",
    "        ),\n",
    "        # Column 3\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 3', className='card-title'),\n",
    "                    html.P('Content for column 3...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=2  # 1/6 of the width\n",
    "        ),\n",
    "        # Column 4\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 4', className='card-title'),\n",
    "                    html.P('Content for column 4...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=2  # 1/6 of the width\n",
    "        ),\n",
    "        # Column 5\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 5', className='card-title'),\n",
    "                    html.P('Content for column 5...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=2  # 1/6 of the width\n",
    "        ),\n",
    "        # Column 6\n",
    "        dbc.Col(\n",
    "            dbc.Card(\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Title Col 6', className='card-title'),\n",
    "                    html.P('Content for column 6...', className='card-text')\n",
    "                ])\n",
    "            ),\n",
    "            width=2  # 1/6 of the width\n",
    "        ),\n",
    "    ], style={'margin-top': '20px'}),\n",
    "\n",
    "], fluid=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
