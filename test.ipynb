{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import assets.helper as b3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'datasets/nsd_links.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsd = pd.read_pickle(file_path)  # Try to read the file as a pickle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['company', 'dri', 'dri2', 'dre', 'data', 'versao', 'auditor',\n",
       "       'auditor_rt', 'protocolo', 'envio', 'url', 'nsd'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b3_companies.fillna('', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b3_companies.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b3_companies.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b3_companies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## alpha vantage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL: 0D6Q4J59U8XVBS7F success\n",
      "GOOGL: 0D6Q4J59U8XVBS7F success\n",
      "PETR4.SAO: 0D6Q4J59U8XVBS7F success\n",
      "\n",
      "AAPL Data:\n",
      "            1. open  2. high  3. low  4. close  5. adjusted close   6. volume  \\\n",
      "date                                                                            \n",
      "2023-04-14   164.59   166.32  163.82    165.21         165.210000  49386480.0   \n",
      "2023-04-13   161.63   165.80  161.42    165.56         165.560000  68445649.0   \n",
      "2023-04-12   161.22   162.06  159.78    160.10         160.100000  50133062.0   \n",
      "2023-04-11   162.35   162.36  160.51    160.80         160.800000  47644217.0   \n",
      "2023-04-10   161.42   162.03  160.08    162.03         162.030000  47716882.0   \n",
      "...             ...      ...     ...       ...                ...         ...   \n",
      "1999-11-05    84.62    88.37   84.00     88.31           0.671012   3721500.0   \n",
      "1999-11-04    82.06    85.37   80.62     83.62           0.635376   3384700.0   \n",
      "1999-11-03    81.62    83.25   81.00     81.50           0.619267   2932700.0   \n",
      "1999-11-02    78.00    81.69   77.31     80.25           0.609769   3564600.0   \n",
      "1999-11-01    80.00    80.69   77.37     77.62           0.589786   2487300.0   \n",
      "\n",
      "            7. dividend amount  8. split coefficient  \n",
      "date                                                  \n",
      "2023-04-14                 0.0                   1.0  \n",
      "2023-04-13                 0.0                   1.0  \n",
      "2023-04-12                 0.0                   1.0  \n",
      "2023-04-11                 0.0                   1.0  \n",
      "2023-04-10                 0.0                   1.0  \n",
      "...                        ...                   ...  \n",
      "1999-11-05                 0.0                   1.0  \n",
      "1999-11-04                 0.0                   1.0  \n",
      "1999-11-03                 0.0                   1.0  \n",
      "1999-11-02                 0.0                   1.0  \n",
      "1999-11-01                 0.0                   1.0  \n",
      "\n",
      "[5901 rows x 8 columns]\n",
      "\n",
      "GOOGL Data:\n",
      "            1. open  2. high  3. low  4. close  5. adjusted close   6. volume  \\\n",
      "date                                                                            \n",
      "2023-04-14   106.89   108.94  106.84   108.870         108.870000  26578002.0   \n",
      "2023-04-13   105.84   107.49  105.84   107.430         107.430000  24843579.0   \n",
      "2023-04-12   106.58   106.75  104.34   104.640         104.640000  24370274.0   \n",
      "2023-04-11   106.55   106.73  104.68   105.350         105.350000  26311803.0   \n",
      "2023-04-10   106.98   107.59  105.12   106.440         106.440000  27067355.0   \n",
      "...             ...      ...     ...       ...                ...         ...   \n",
      "2004-08-25   104.76   108.00  103.88   106.000           2.658206   9188600.0   \n",
      "2004-08-24   111.24   111.60  103.57   104.870           2.629868  15247300.0   \n",
      "2004-08-23   110.76   113.48  109.05   109.400           2.743469  18256100.0   \n",
      "2004-08-20   101.01   109.08  100.50   108.310           2.716134  22834300.0   \n",
      "2004-08-19   100.01   104.06   95.96   100.335           2.516142  44659000.0   \n",
      "\n",
      "            7. dividend amount  8. split coefficient  \n",
      "date                                                  \n",
      "2023-04-14                 0.0                   1.0  \n",
      "2023-04-13                 0.0                   1.0  \n",
      "2023-04-12                 0.0                   1.0  \n",
      "2023-04-11                 0.0                   1.0  \n",
      "2023-04-10                 0.0                   1.0  \n",
      "...                        ...                   ...  \n",
      "2004-08-25                 0.0                   1.0  \n",
      "2004-08-24                 0.0                   1.0  \n",
      "2004-08-23                 0.0                   1.0  \n",
      "2004-08-20                 0.0                   1.0  \n",
      "2004-08-19                 0.0                   1.0  \n",
      "\n",
      "[4696 rows x 8 columns]\n",
      "\n",
      "PETR4.SAO Data:\n",
      "            1. open  2. high  3. low  4. close  5. adjusted close   6. volume  \\\n",
      "date                                                                            \n",
      "2023-04-14    25.80    26.40   25.72     26.30            26.3000  38421100.0   \n",
      "2023-04-13    25.85    26.09   25.80     26.03            26.0300  38852800.0   \n",
      "2023-04-12    25.98    26.15   25.18     25.85            25.8500  71563400.0   \n",
      "2023-04-11    24.70    25.70   24.63     25.66            25.6600  80565000.0   \n",
      "2023-04-10    24.03    24.66   24.03     24.51            24.5100  41455900.0   \n",
      "...             ...      ...     ...       ...                ...         ...   \n",
      "2005-01-07    93.19    94.30   92.51     93.41             3.7529   3287780.0   \n",
      "2005-01-06    93.22    93.50   91.90     93.00             3.7364   3562220.0   \n",
      "2005-01-05    93.30    94.18   91.80     92.72             3.7251   3891044.0   \n",
      "2005-01-04    94.99    95.60   93.00     93.08             3.7396   4741740.0   \n",
      "2005-01-03    97.25    97.90   94.19     94.20             3.7846   3781800.0   \n",
      "\n",
      "            7. dividend amount  8. split coefficient  \n",
      "date                                                  \n",
      "2023-04-14                 0.0                   1.0  \n",
      "2023-04-13                 0.0                   1.0  \n",
      "2023-04-12                 0.0                   1.0  \n",
      "2023-04-11                 0.0                   1.0  \n",
      "2023-04-10                 0.0                   1.0  \n",
      "...                        ...                   ...  \n",
      "2005-01-07                 0.0                   1.0  \n",
      "2005-01-06                 0.0                   1.0  \n",
      "2005-01-05                 0.0                   1.0  \n",
      "2005-01-04                 0.0                   1.0  \n",
      "2005-01-03                 0.0                   1.0  \n",
      "\n",
      "[4522 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "import credentials.keys\n",
    "\n",
    "# Create an API key rotator\n",
    "alpha_vantage = credentials.keys.alpha_vantage\n",
    "api_key_rotator = itertools.cycle(alpha_vantage)\n",
    "\n",
    "def get_api_key():\n",
    "    return next(api_key_rotator)\n",
    "\n",
    "# Get the first API key to initialize the TimeSeries object\n",
    "api_key = get_api_key()\n",
    "\n",
    "# Create a TimeSeries object with the current API key\n",
    "ts = TimeSeries(key=api_key, output_format='pandas')\n",
    "\n",
    "symbols = ['AAPL', 'GOOGL', 'PETR4.SAO']\n",
    "data_dict = {}\n",
    "\n",
    "for symbol in symbols:\n",
    "    while True:\n",
    "        try:\n",
    "            data, metadata = ts.get_daily_adjusted(symbol=symbol, outputsize='full')\n",
    "            data_dict[symbol] = data\n",
    "            print(f\"{symbol}: {api_key} success\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            # Update the API key and TimeSeries object\n",
    "            print(f\"{symbol}: {api_key} error {e}\")\n",
    "            api_key = get_api_key()\n",
    "            ts = TimeSeries(key=api_key, output_format='pandas')\n",
    "\n",
    "# Print the historical quotes for each symbol\n",
    "for symbol, data in data_dict.items():\n",
    "    print(f\"\\n{symbol} Data:\\n{data}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1043146\n",
      "1043147\n"
     ]
    }
   ],
   "source": [
    "import assets.helper as b3\n",
    "import requests\n",
    "import json\n",
    "import base64\n",
    "from google.cloud import storage\n",
    "from io import BytesIO\n",
    "\n",
    "# Set the required properties\n",
    "codigoInstituicao = 2\n",
    "numeroProtocolo = 1043145\n",
    "token = '6LdVyiwaAAAAABobBnLknCD5VGGkmH9snlJBxCyr'\n",
    "versaoCaptcha = 'V3'\n",
    "\n",
    "\n",
    "# Send the request\n",
    "base_url = 'https://www.rad.cvm.gov.br/ENET/'\n",
    "url = base_url + \"frmExibirArquivoIPEExterno.aspx/ExibirPDF\"\n",
    "headers = {\"Content-Type\": \"application/json; charset=utf-8\"}\n",
    "\n",
    "for numeroProtocolo in range (1043146, 1043146+2):\n",
    "    # # Define the JSON payload\n",
    "    # data = {\n",
    "    #     \"codigoInstituicao\": codigoInstituicao,\n",
    "    #     \"numeroProtocolo\": numeroProtocolo,\n",
    "    #     \"token\": token,\n",
    "    #     \"versaoCaptcha\": versaoCaptcha, \n",
    "    # }\n",
    "    # response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "    # # Get the base64-encoded PDF data from the response\n",
    "    # pdf_data = response.json()['d']\n",
    "\n",
    "    # # Decode base64-encoded PDF data\n",
    "    # pdf_bytes = base64.b64decode(pdf_data)\n",
    "\n",
    "    # # Save PDF data to file\n",
    "    # with open(f\"{numeroProtocolo}.pdf\", \"wb\") as f:\n",
    "    #     f.write(pdf_bytes)\n",
    "\n",
    "    \n",
    "    url = f\"https://www.rad.cvm.gov.br/ENET/frmDownloadDocumento.aspx?Tela=ext&numSequencia=567876&numVersao=1&numProtocolo={numeroProtocolo}&descTipo=IPE&CodigoInstituicao=1\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Save PDF file to Google Cloud Service\n",
    "    # GCS configuration\n",
    "    destination_blob_name = f'{numeroProtocolo}.pdf'\n",
    "\n",
    "    # Initialize GCS client\n",
    "    client = storage.Client.from_service_account_json(b3.json_key_file)\n",
    "    bucket = client.get_bucket(b3.bucket_name)\n",
    "\n",
    "    # Upload the PDF file to GCS\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "    blob.upload_from_string(response.content, content_type='application/pdf')\n",
    "    # blob.upload_from_string(pdf_bytes, content_type='application/pdf')\n",
    "\n",
    "\n",
    "    print(numeroProtocolo)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BS4 NSD Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 ['MARFRIG GLOBAL FOODS S.A.', 'Ricardo Florence dos Santos', 'FCA V2', 'Formulário Cadastral', '2010', 'V1', 'BDO Trevisan Auditores Independentes', 'José Luiz Sanches', '', '020788FCA000020100100000045-80', '17/03/2010 17:03:28', 'https://www.rad.cvm.gov.br/ENET/frmGerenciaPaginaFRE.aspx?NumeroSequencialDocumento=45&CodigoTipoInstituicao=1', 45]\n",
      "1 empty line list index out of range\n",
      "partial save\n",
      "2 empty line list index out of range\n",
      "48 ['RENOVA ENERGIA S.A. - EM RECUPERAÇÃO JUDICIAL', 'Vasco de Freitas Barcellos Neto', 'FCA V1', 'Formulário Cadastral', '2010', 'V1', '', '', '', '021636FCA000020100100000048-86', '18/03/2010 13:21:56', 'https://www.rad.cvm.gov.br/ENET/frmGerenciaPaginaFRE.aspx?NumeroSequencialDocumento=48&CodigoTipoInstituicao=1', 48]\n",
      "partial save\n",
      "1 empty line list index out of range\n",
      "2 empty line list index out of range\n",
      "partial save\n",
      "3 empty line list index out of range\n",
      "4 empty line list index out of range\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 70\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m n \u001b[39m%\u001b[39m \u001b[39m2\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 70\u001b[0m         nsd\u001b[39m.\u001b[39;49mto_pickle(nsd_file)\n\u001b[0;32m     71\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mpartial save\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     73\u001b[0m nsd\u001b[39m.\u001b[39mto_pickle(nsd_file)\n",
      "File \u001b[1;32md:\\Fausto Stangler\\Documentos\\Python\\DSH\\.venv\\lib\\site-packages\\pandas\\core\\generic.py:3064\u001b[0m, in \u001b[0;36mNDFrame.to_pickle\u001b[1;34m(self, path, compression, protocol, storage_options)\u001b[0m\n\u001b[0;32m   3012\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   3013\u001b[0m \u001b[39mPickle (serialize) object to file.\u001b[39;00m\n\u001b[0;32m   3014\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3060\u001b[0m \u001b[39m4    4    9\u001b[39;00m\n\u001b[0;32m   3061\u001b[0m \u001b[39m\"\"\"\u001b[39;00m  \u001b[39m# noqa: E501\u001b[39;00m\n\u001b[0;32m   3062\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpickle\u001b[39;00m \u001b[39mimport\u001b[39;00m to_pickle\n\u001b[1;32m-> 3064\u001b[0m to_pickle(\n\u001b[0;32m   3065\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   3066\u001b[0m     path,\n\u001b[0;32m   3067\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m   3068\u001b[0m     protocol\u001b[39m=\u001b[39;49mprotocol,\n\u001b[0;32m   3069\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m   3070\u001b[0m )\n",
      "File \u001b[1;32md:\\Fausto Stangler\\Documentos\\Python\\DSH\\.venv\\lib\\site-packages\\pandas\\io\\pickle.py:97\u001b[0m, in \u001b[0;36mto_pickle\u001b[1;34m(obj, filepath_or_buffer, compression, protocol, storage_options)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[39mif\u001b[39;00m protocol \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     95\u001b[0m     protocol \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mHIGHEST_PROTOCOL\n\u001b[1;32m---> 97\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[0;32m     98\u001b[0m     filepath_or_buffer,\n\u001b[0;32m     99\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mwb\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    100\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m    101\u001b[0m     is_text\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    102\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m    103\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[0;32m    104\u001b[0m     \u001b[39mif\u001b[39;00m handles\u001b[39m.\u001b[39mcompression[\u001b[39m\"\u001b[39m\u001b[39mmethod\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mbz2\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mxz\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m protocol \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m5\u001b[39m:\n\u001b[0;32m    105\u001b[0m         \u001b[39m# some weird TypeError GH#39002 with pickle 5: fallback to letting\u001b[39;00m\n\u001b[0;32m    106\u001b[0m         \u001b[39m# pickle create the entire object and then write it to the buffer.\u001b[39;00m\n\u001b[0;32m    107\u001b[0m         \u001b[39m# \"zip\" would also be here if pandas.io.common._BytesZipFile\u001b[39;00m\n\u001b[0;32m    108\u001b[0m         \u001b[39m# wouldn't buffer write calls\u001b[39;00m\n\u001b[0;32m    109\u001b[0m         handles\u001b[39m.\u001b[39mhandle\u001b[39m.\u001b[39mwrite(pickle\u001b[39m.\u001b[39mdumps(obj, protocol\u001b[39m=\u001b[39mprotocol))\n",
      "File \u001b[1;32md:\\Fausto Stangler\\Documentos\\Python\\DSH\\.venv\\lib\\site-packages\\pandas\\io\\common.py:779\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    774\u001b[0m \u001b[39m# ZIP Compression\u001b[39;00m\n\u001b[0;32m    775\u001b[0m \u001b[39melif\u001b[39;00m compression \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mzip\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    776\u001b[0m     \u001b[39m# error: Argument 1 to \"_BytesZipFile\" has incompatible type\u001b[39;00m\n\u001b[0;32m    777\u001b[0m     \u001b[39m# \"Union[str, BaseBuffer]\"; expected \"Union[Union[str, PathLike[str]],\u001b[39;00m\n\u001b[0;32m    778\u001b[0m     \u001b[39m# ReadBuffer[bytes], WriteBuffer[bytes]]\"\u001b[39;00m\n\u001b[1;32m--> 779\u001b[0m     handle \u001b[39m=\u001b[39m _BytesZipFile(\n\u001b[0;32m    780\u001b[0m         handle, ioargs\u001b[39m.\u001b[39mmode, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcompression_args  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     )\n\u001b[0;32m    782\u001b[0m     \u001b[39mif\u001b[39;00m handle\u001b[39m.\u001b[39mbuffer\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    783\u001b[0m         handles\u001b[39m.\u001b[39mappend(handle)\n",
      "File \u001b[1;32md:\\Fausto Stangler\\Documentos\\Python\\DSH\\.venv\\lib\\site-packages\\pandas\\io\\common.py:1022\u001b[0m, in \u001b[0;36m_BytesZipFile.__init__\u001b[1;34m(self, file, mode, archive_name, **kwargs)\u001b[0m\n\u001b[0;32m   1018\u001b[0m kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m\"\u001b[39m\u001b[39mcompression\u001b[39m\u001b[39m\"\u001b[39m, zipfile\u001b[39m.\u001b[39mZIP_DEFLATED)\n\u001b[0;32m   1019\u001b[0m \u001b[39m# error: Argument 1 to \"ZipFile\" has incompatible type \"Union[\u001b[39;00m\n\u001b[0;32m   1020\u001b[0m \u001b[39m# Union[str, PathLike[str]], ReadBuffer[bytes], WriteBuffer[bytes]]\";\u001b[39;00m\n\u001b[0;32m   1021\u001b[0m \u001b[39m# expected \"Union[Union[str, PathLike[str]], IO[bytes]]\"\u001b[39;00m\n\u001b[1;32m-> 1022\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer \u001b[39m=\u001b[39m zipfile\u001b[39m.\u001b[39mZipFile(file, mode, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\zipfile.py:1249\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[0;32m   1247\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m   1248\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1249\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39;49mopen(file, filemode)\n\u001b[0;32m   1250\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[0;32m   1251\u001b[0m         \u001b[39mif\u001b[39;00m filemode \u001b[39min\u001b[39;00m modeDict:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "empty = 0\n",
    "nsd_file = 'datasets/nsd_links.zip'\n",
    "cols_nsd = ['company', 'dri', 'dri2', 'dre', 'data', 'versao', 'auditor', 'auditor_rt', 'cancelamento', 'protocolo', 'envio', 'url', 'nsd']\n",
    "try:\n",
    "    nsd = pd.read_pickle(nsd_file)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    nsd = pd.DataFrame(columns=cols_nsd)\n",
    "\n",
    "try:\n",
    "    start = int(max(nsd['nsd'])) + 1\n",
    "except:\n",
    "    start = 1\n",
    "\n",
    "for n in range(start, 10000):\n",
    "    try:\n",
    "        nsd_url = f'https://www.rad.cvm.gov.br/ENET/frmGerenciaPaginaFRE.aspx?NumeroSequencialDocumento={n}&CodigoTipoInstituicao=1'\n",
    "\n",
    "        # Getting the HTML content from the URL\n",
    "        response = requests.get(nsd_url)\n",
    "        html_content = response.text\n",
    "\n",
    "        # Parsing the HTML content with BeautifulSoup\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # Extracting company\n",
    "        nomeCompanhia_tag = soup.find('span', {'id': 'lblNomeCompanhia'})\n",
    "        company = nomeCompanhia_tag.text.strip()\n",
    "\n",
    "        # Extracting dri and dri2\n",
    "        nomeDRI_tag = soup.find('span', {'id': 'lblNomeDRI'})\n",
    "        dri = nomeDRI_tag.text.strip().split(' - ')[0]\n",
    "        dri2 = nomeDRI_tag.text.strip().split(' - ')[-1].replace('(', '').replace(')', '')\n",
    "\n",
    "        # Extracting 'FCA', data and versao\n",
    "        descricaoCategoria_tag = soup.find('span', {'id': 'lblDescricaoCategoria'})\n",
    "        descricaoCategoria = descricaoCategoria_tag.text.strip()\n",
    "        versao = descricaoCategoria.split(' - ')[-1]\n",
    "        data = descricaoCategoria.split(' - ')[1]\n",
    "        dre = descricaoCategoria.split(' - ')[0]\n",
    "\n",
    "        # Extracting auditor\n",
    "        lblAuditor_tag = soup.find('span', {'id': 'lblAuditor'})\n",
    "        auditor = lblAuditor_tag.text.strip().split(' - ')[0]\n",
    "\n",
    "        # Extracting auditor_rt\n",
    "        lblResponsavelTecnico_tag = soup.find('span', {'id': 'lblResponsavelTecnico'})\n",
    "        auditor_rt = lblResponsavelTecnico_tag.text.strip()\n",
    "\n",
    "        # Extracting protocolo\n",
    "        lblProtocolo_tag = soup.find('span', {'id': 'lblProtocolo'})\n",
    "        protocolo = lblProtocolo_tag.text.strip()\n",
    "\n",
    "        # Extracting '2010' and envio\n",
    "        lblDataDocumento_tag = soup.find('span', {'id': 'lblDataDocumento'})\n",
    "        lblDataDocumento = lblDataDocumento_tag.text.strip()\n",
    "\n",
    "        lblDataEnvio_tag = soup.find('span', {'id': 'lblDataEnvio'})\n",
    "        envio = lblDataEnvio_tag.text.strip()\n",
    "\n",
    "        # cancelamento\n",
    "        cancelamento_tag = soup.find('span', {'id': 'lblMotivoCancelamentoReapresentacao'})\n",
    "        cancelamento = cancelamento_tag.text.strip()\n",
    "\n",
    "        # url\n",
    "        url = nsd_url\n",
    "\n",
    "        # company\n",
    "        company_line = [company, dri, dri2, dre, data, versao, auditor, auditor_rt, cancelamento, protocolo, envio, url, n]\n",
    "        df = pd.DataFrame([company_line], columns=cols_nsd)\n",
    "        nsd = pd.concat([nsd, df])\n",
    "        print(n, company_line)\n",
    "        empty = 0\n",
    "\n",
    "    except Exception as e:\n",
    "        empty += 1\n",
    "        print(empty, 'empty line', e)\n",
    "\n",
    "        if empty == 2000:\n",
    "            print('too much empty lines, aborting...')\n",
    "            break\n",
    "\n",
    "    if n % 2 == 0:\n",
    "        nsd.to_pickle(nsd_file)\n",
    "        print('partial save')\n",
    "\n",
    "nsd.to_pickle(nsd_file)\n",
    "print('final save')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>dri</th>\n",
       "      <th>dri2</th>\n",
       "      <th>dre</th>\n",
       "      <th>data</th>\n",
       "      <th>versao</th>\n",
       "      <th>auditor</th>\n",
       "      <th>auditor_rt</th>\n",
       "      <th>cancelamento</th>\n",
       "      <th>protocolo</th>\n",
       "      <th>...</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Formulário Cadastral</td>\n",
       "      <td>2010</td>\n",
       "      <td>V1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>021636FCA000020100100000048-86</td>\n",
       "      <td>18/03/2010 13:21:56</td>\n",
       "      <td>https://www.rad.cvm.gov.br/ENET/frmGerenciaPag...</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MARFRIG GLOBAL FOODS S.A.</td>\n",
       "      <td>Ricardo Florence dos Santos</td>\n",
       "      <td>FCA V2</td>\n",
       "      <td>Formulário Cadastral</td>\n",
       "      <td>2010</td>\n",
       "      <td>V1</td>\n",
       "      <td>BDO Trevisan Auditores Independentes</td>\n",
       "      <td>José Luiz Sanches</td>\n",
       "      <td></td>\n",
       "      <td>020788FCA000020100100000045-80</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RENOVA ENERGIA S.A. - EM RECUPERAÇÃO JUDICIAL</td>\n",
       "      <td>Vasco de Freitas Barcellos Neto</td>\n",
       "      <td>FCA V1</td>\n",
       "      <td>Formulário Cadastral</td>\n",
       "      <td>2010</td>\n",
       "      <td>V1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>021636FCA000020100100000048-86</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         company  \\\n",
       "0                                            NaN   \n",
       "0                      MARFRIG GLOBAL FOODS S.A.   \n",
       "0  RENOVA ENERGIA S.A. - EM RECUPERAÇÃO JUDICIAL   \n",
       "\n",
       "                               dri    dri2                   dre  data versao  \\\n",
       "0                              NaN     NaN                   NaN   NaN    NaN   \n",
       "0      Ricardo Florence dos Santos  FCA V2  Formulário Cadastral  2010     V1   \n",
       "0  Vasco de Freitas Barcellos Neto  FCA V1  Formulário Cadastral  2010     V1   \n",
       "\n",
       "                                auditor         auditor_rt cancelamento  \\\n",
       "0                                   NaN                NaN          NaN   \n",
       "0  BDO Trevisan Auditores Independentes  José Luiz Sanches                \n",
       "0                                                                         \n",
       "\n",
       "                        protocolo  ...                     3     4    5    6  \\\n",
       "0                             NaN  ...  Formulário Cadastral  2010   V1        \n",
       "0  020788FCA000020100100000045-80  ...                   NaN   NaN  NaN  NaN   \n",
       "0  021636FCA000020100100000048-86  ...                   NaN   NaN  NaN  NaN   \n",
       "\n",
       "     7    8                               9                   10  \\\n",
       "0            021636FCA000020100100000048-86  18/03/2010 13:21:56   \n",
       "0  NaN  NaN                             NaN                  NaN   \n",
       "0  NaN  NaN                             NaN                  NaN   \n",
       "\n",
       "                                                  11   12  \n",
       "0  https://www.rad.cvm.gov.br/ENET/frmGerenciaPag...   48  \n",
       "0                                                NaN  NaN  \n",
       "0                                                NaN  NaN  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nsd = pd.concat([nsd, df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsd = pd.DataFrame(columns=cols_nsd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>dri</th>\n",
       "      <th>dri2</th>\n",
       "      <th>dre</th>\n",
       "      <th>data</th>\n",
       "      <th>versao</th>\n",
       "      <th>auditor</th>\n",
       "      <th>auditor_rt</th>\n",
       "      <th>cancelamento</th>\n",
       "      <th>protocolo</th>\n",
       "      <th>envio</th>\n",
       "      <th>url</th>\n",
       "      <th>nsd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RENOVA ENERGIA S.A. - EM RECUPERAÇÃO JUDICIAL</td>\n",
       "      <td>Vasco de Freitas Barcellos Neto</td>\n",
       "      <td>FCA V1</td>\n",
       "      <td>Formulário Cadastral</td>\n",
       "      <td>2010</td>\n",
       "      <td>V1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>021636FCA000020100100000048-86</td>\n",
       "      <td>18/03/2010 13:21:56</td>\n",
       "      <td>https://www.rad.cvm.gov.br/ENET/frmGerenciaPag...</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         company  \\\n",
       "0  RENOVA ENERGIA S.A. - EM RECUPERAÇÃO JUDICIAL   \n",
       "\n",
       "                               dri    dri2                   dre  data versao  \\\n",
       "0  Vasco de Freitas Barcellos Neto  FCA V1  Formulário Cadastral  2010     V1   \n",
       "\n",
       "  auditor auditor_rt cancelamento                       protocolo  \\\n",
       "0                                  021636FCA000020100100000048-86   \n",
       "\n",
       "                 envio                                                url  nsd  \n",
       "0  18/03/2010 13:21:56  https://www.rad.cvm.gov.br/ENET/frmGerenciaPag...   48  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>dri</th>\n",
       "      <th>dri2</th>\n",
       "      <th>dre</th>\n",
       "      <th>data</th>\n",
       "      <th>versao</th>\n",
       "      <th>auditor</th>\n",
       "      <th>auditor_rt</th>\n",
       "      <th>cancelamento</th>\n",
       "      <th>protocolo</th>\n",
       "      <th>...</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Formulário Cadastral</td>\n",
       "      <td>2010</td>\n",
       "      <td>V1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>021636FCA000020100100000048-86</td>\n",
       "      <td>18/03/2010 13:21:56</td>\n",
       "      <td>https://www.rad.cvm.gov.br/ENET/frmGerenciaPag...</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  company  dri dri2  dre data versao auditor auditor_rt cancelamento  \\\n",
       "0     NaN  NaN  NaN  NaN  NaN    NaN     NaN        NaN          NaN   \n",
       "\n",
       "  protocolo  ...                     3     4   5 6 7 8  \\\n",
       "0       NaN  ...  Formulário Cadastral  2010  V1         \n",
       "\n",
       "                                9                   10  \\\n",
       "0  021636FCA000020100100000048-86  18/03/2010 13:21:56   \n",
       "\n",
       "                                                  11  12  \n",
       "0  https://www.rad.cvm.gov.br/ENET/frmGerenciaPag...  48  \n",
       "\n",
       "[1 rows x 26 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsd = pd.concat([nsd, df.T])\n",
    "nsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsd = pd.read_pickle('datasets/nsd_links.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['company', 'dri', 'dri2', 'dre', 'data', 'versao', 'auditor',\n",
       "       'auditor_rt', 'cancelamento', 'protocolo', 'envio', 'url', 'nsd'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsd.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
